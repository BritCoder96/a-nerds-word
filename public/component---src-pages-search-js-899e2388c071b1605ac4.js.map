{"version":3,"sources":["webpack:///component---src-pages-search-js-899e2388c071b1605ac4.js","webpack:///./~/elasticlunr/elasticlunr.js?35ed","webpack:///./src/pages/search.js?b648"],"names":["webpackJsonp","114","module","exports","__webpack_require__","__WEBPACK_AMD_DEFINE_FACTORY__","__WEBPACK_AMD_DEFINE_RESULT__","clone","obj","copy","constructor","attr","hasOwnProperty","elasticlunr","config","idx","Index","pipeline","add","trimmer","stopWordFilter","stemmer","call","version","lunr","utils","warn","global","message","console","this","toString","EventEmitter","events","prototype","addListener","args","Array","slice","arguments","fn","pop","names","TypeError","forEach","name","hasHandler","push","removeListener","fnIndex","indexOf","splice","length","emit","apply","undefined","tokenizer","str","isArray","arr","filter","token","map","t","toLowerCase","out","item","tokens","split","seperator","concat","trim","defaultSeperator","setSeperator","sep","resetSeperator","getSeperator","Pipeline","_queue","registeredFunctions","registerFunction","label","getRegisteredFunction","warnIfFunctionNotRegistered","isRegistered","load","serialised","fnName","Error","fns","after","existingFn","newFn","pos","before","remove","run","tokenLength","pipelineLength","i","j","reset","get","toJSON","_fields","_ref","documentStore","DocumentStore","index","eventEmitter","_idfCache","on","bind","off","serialisedData","fields","ref","field","InvertedIndex","addField","fieldName","setRef","refName","saveDocument","save","addDoc","doc","emitEvent","docRef","fieldTokens","addFieldLength","tokenCount","termFrequency","Math","sqrt","addToken","tf","removeDocByRef","isDocStored","hasDoc","getDoc","removeDoc","removeToken","updateDoc","idf","term","cacheKey","Object","df","getDocFreq","log","getFields","search","query","userConfig","configStr","JSON","stringify","Configuration","queryTokens","queryResults","fieldSearchResults","fieldSearch","fieldBoost","boost","results","score","sort","a","b","booleanType","bool","expand","scores","docTokens","expandToken","queryTokenScores","key","docs","getDocs","filteredDocs","fieldSearchStats","getTermFrequency","fieldLength","getFieldLength","fieldLengthNorm","penality","mergeScores","coordNorm","accumScores","op","intersection","n","indexJson","use","plugin","unshift","_save","docInfo","store","updateFieldLength","step2list","ational","tional","enci","anci","izer","bli","alli","entli","eli","ousli","ization","ation","ator","alism","iveness","fulness","ousness","aliti","iviti","biliti","logi","step3list","icate","ative","alize","iciti","ical","ful","ness","c","v","C","V","mgr0","meq1","mgr1","s_v","re_mgr0","RegExp","re_mgr1","re_meq1","re_s_v","re_1a","re2_1a","re_1b","re2_1b","re_1b_2","re2_1b_2","re3_1b_2","re4_1b_2","re_1c","re_2","re_3","re_4","re2_4","re_5","re_5_1","re3_5","porterStemmer","w","stem","suffix","firstch","re","re2","re3","re4","substr","toUpperCase","test","replace","fp","exec","stopWords","clearStopWords","addStopWords","words","word","resetStopWords","defaultStopWords","","able","about","across","all","almost","also","am","among","an","and","any","are","as","at","be","because","been","but","by","can","cannot","could","dear","did","do","does","either","else","ever","every","for","from","got","had","has","have","he","her","hers","him","his","how","however","if","in","into","is","it","its","just","least","let","like","likely","may","me","might","most","must","my","neither","no","nor","not","of","often","only","or","other","our","own","rather","said","say","says","she","should","since","so","some","than","that","the","their","them","then","there","these","they","tis","to","too","twas","us","wants","was","we","were","what","when","where","which","while","who","whom","why","will","with","would","yet","you","your","root","tokenInfo","hasToken","node","getNode","memo","parse","buildUserConfig","error","buildDefaultConfig","global_bool","global_expand","field_config","field_expand","addAllFields2UserConfig","SortedSet","elements","set","element","locationFor","toArray","ctx","elem","start","end","sectionLength","pivot","floor","pivotElem","intersect","otherSet","intersectSet","a_len","b_len","union","longSet","shortSet","unionSet","shortSetElements","factory","86","_interopRequireDefault","__esModule","default","_classCallCheck","instance","Constructor","_possibleConstructorReturn","self","ReferenceError","_inherits","subClass","superClass","create","value","enumerable","writable","configurable","setPrototypeOf","__proto__","_react","_react2","_elasticlunr","Search","_Component","props","_this","getOrCreateIndex","data","siteSearchIndex","evt","target","setState","state","render","createElement","type","className","onChange","page","title","keywords","join","Component"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,EAASC,GCHjC,GAAAC,GAAAC,GAUA,WAmzCA,QAAAC,GAAAC,GACA,UAAAA,GAAA,gBAAAA,GAAA,MAAAA,EAEA,IAAAC,GAAAD,EAAAE,aAEA,QAAAC,KAAAH,GACAA,EAAAI,eAAAD,KAAAF,EAAAE,GAAAH,EAAAG,GAGA,OAAAF,GA/vCA,GAAAI,GAAA,SAAAC,GACA,GAAAC,GAAA,GAAAF,GAAAG,KAUA,OARAD,GAAAE,SAAAC,IACAL,EAAAM,QACAN,EAAAO,eACAP,EAAAQ,SAGAP,KAAAQ,KAAAP,KAEAA,EAGAF,GAAAU,QAAA,QAIAC,KAAAX,EAWAA,EAAAY,SAQAZ,EAAAY,MAAAC,KAAA,SAAAC,GACA,gBAAAC,GACAD,EAAAE,iBAAAH,MACAG,QAAAH,KAAAE,KAGCE,MAaDjB,EAAAY,MAAAM,SAAA,SAAAvB,GACA,gBAAAA,GAAA,OAAAA,EACA,GAGAA,EAAAuB,YAiBAlB,EAAAmB,aAAA,WACAF,KAAAG,WAYApB,EAAAmB,aAAAE,UAAAC,YAAA,WACA,GAAAC,GAAAC,MAAAH,UAAAI,MAAAhB,KAAAiB,WACAC,EAAAJ,EAAAK,MACAC,EAAAN,CAEA,sBAAAI,GAAA,SAAAG,WAAA,mCAEAD,GAAAE,QAAA,SAAAC,GACAf,KAAAgB,WAAAD,KAAAf,KAAAG,OAAAY,OACAf,KAAAG,OAAAY,GAAAE,KAAAP,IACGV,OAUHjB,EAAAmB,aAAAE,UAAAc,eAAA,SAAAH,EAAAL,GACA,GAAAV,KAAAgB,WAAAD,GAAA,CAEA,GAAAI,GAAAnB,KAAAG,OAAAY,GAAAK,QAAAV,EACAS,MAAA,IAEAnB,KAAAG,OAAAY,GAAAM,OAAAF,EAAA,GAEA,GAAAnB,KAAAG,OAAAY,GAAAO,cAAAtB,MAAAG,OAAAY,MAYAhC,EAAAmB,aAAAE,UAAAmB,KAAA,SAAAR,GACA,GAAAf,KAAAgB,WAAAD,GAAA,CAEA,GAAAT,GAAAC,MAAAH,UAAAI,MAAAhB,KAAAiB,UAAA,EAEAT,MAAAG,OAAAY,GAAAD,QAAA,SAAAJ,GACAA,EAAAc,MAAAC,OAAAnB,IACGN,QAUHjB,EAAAmB,aAAAE,UAAAY,WAAA,SAAAD,GACA,MAAAA,KAAAf,MAAAG,QAqBApB,EAAA2C,UAAA,SAAAC,GACA,IAAAlB,UAAAa,QAAA,OAAAK,GAAAF,SAAAE,EAAA,QACA,IAAApB,MAAAqB,QAAAD,GAAA,CACA,GAAAE,GAAAF,EAAAG,OAAA,SAAAC,GACA,cAAAA,GAAAN,SAAAM,GAOAF,KAAAG,IAAA,SAAAC,GACA,MAAAlD,GAAAY,MAAAM,SAAAgC,GAAAC,eAGA,IAAAC,KAMA,OALAN,GAAAf,QAAA,SAAAsB,GACA,GAAAC,GAAAD,EAAAE,MAAAvD,EAAA2C,UAAAa,UACAJ,KAAAK,OAAAH,IACKrC,MAELmC,EAGA,MAAAR,GAAA1B,WAAAwC,OAAAP,cAAAI,MAAAvD,EAAA2C,UAAAa,YAMAxD,EAAA2C,UAAAgB,iBAAA,UASA3D,EAAA2C,UAAAa,UAAAxD,EAAA2C,UAAAgB,iBAOA3D,EAAA2C,UAAAiB,aAAA,SAAAC,GACA,OAAAA,GAAAnB,SAAAmB,GAAA,qBACA7D,EAAA2C,UAAAa,UAAAK,IAQA7D,EAAA2C,UAAAmB,eAAA,WACA9D,EAAA2C,UAAAa,UAAAxD,EAAA2C,UAAAgB,kBAOA3D,EAAA2C,UAAAoB,aAAA,WACA,MAAA/D,GAAA2C,UAAAa,WAkCAxD,EAAAgE,SAAA,WACA/C,KAAAgD,WAGAjE,EAAAgE,SAAAE,uBAeAlE,EAAAgE,SAAAG,iBAAA,SAAAxC,EAAAyC,GACAA,IAAApE,GAAAgE,SAAAE,qBACAlE,EAAAY,MAAAC,KAAA,6CAAAuD,GAGAzC,EAAAyC,QACApE,EAAAgE,SAAAE,oBAAAE,GAAAzC,GAUA3B,EAAAgE,SAAAK,sBAAA,SAAAD,GACA,MAAAA,KAAApE,GAAAgE,SAAAE,sBAAA,EACA,KAGAlE,EAAAgE,SAAAE,oBAAAE,IAUApE,EAAAgE,SAAAM,4BAAA,SAAA3C,GACA,GAAA4C,GAAA5C,EAAAyC,OAAAzC,EAAAyC,QAAAnD,MAAAiD,mBAEAK,IACAvE,EAAAY,MAAAC,KAAA,kGAAAc,IAeA3B,EAAAgE,SAAAQ,KAAA,SAAAC,GACA,GAAArE,GAAA,GAAAJ,GAAAgE,QAYA,OAVAS,GAAA1C,QAAA,SAAA2C,GACA,GAAA/C,GAAA3B,EAAAgE,SAAAK,sBAAAK,EAEA,KAAA/C,EAGA,SAAAgD,OAAA,uCAAAD,EAFAtE,GAAAC,IAAAsB,KAMAvB,GAWAJ,EAAAgE,SAAA3C,UAAAhB,IAAA,WACA,GAAAuE,GAAApD,MAAAH,UAAAI,MAAAhB,KAAAiB,UAEAkD,GAAA7C,QAAA,SAAAJ,GACA3B,EAAAgE,SAAAM,4BAAA3C,GACAV,KAAAgD,OAAA/B,KAAAP,IACGV,OAcHjB,EAAAgE,SAAA3C,UAAAwD,MAAA,SAAAC,EAAAC,GACA/E,EAAAgE,SAAAM,4BAAAS,EAEA,IAAAC,GAAA/D,KAAAgD,OAAA5B,QAAAyC,EACA,IAAAE,KAAA,EACA,SAAAL,OAAA,yBAGA1D,MAAAgD,OAAA3B,OAAA0C,EAAA,IAAAD,IAcA/E,EAAAgE,SAAA3C,UAAA4D,OAAA,SAAAH,EAAAC,GACA/E,EAAAgE,SAAAM,4BAAAS,EAEA,IAAAC,GAAA/D,KAAAgD,OAAA5B,QAAAyC,EACA,IAAAE,KAAA,EACA,SAAAL,OAAA,yBAGA1D,MAAAgD,OAAA3B,OAAA0C,EAAA,EAAAD,IASA/E,EAAAgE,SAAA3C,UAAA6D,OAAA,SAAAvD,GACA,GAAAqD,GAAA/D,KAAAgD,OAAA5B,QAAAV,EACAqD,MAAA,GAIA/D,KAAAgD,OAAA3B,OAAA0C,EAAA,IAWAhF,EAAAgE,SAAA3C,UAAA8D,IAAA,SAAA7B,GAKA,OAJAF,MACAgC,EAAA9B,EAAAf,OACA8C,EAAApE,KAAAgD,OAAA1B,OAEA+C,EAAA,EAAiBA,EAAAF,EAAiBE,IAAA,CAGlC,OAFAtC,GAAAM,EAAAgC,GAEAC,EAAA,EAAmBA,EAAAF,IACnBrC,EAAA/B,KAAAgD,OAAAsB,GAAAvC,EAAAsC,EAAAhC,GACA,SAAAN,GAAA,OAAAA,GAFuCuC,KAKvC,SAAAvC,GAAA,OAAAA,GAAAI,EAAAlB,KAAAc,GAGA,MAAAI,IAQApD,EAAAgE,SAAA3C,UAAAmE,MAAA,WACAvE,KAAAgD,WAQAjE,EAAAgE,SAAA3C,UAAAoE,IAAA,WACA,MAAAxE,MAAAgD,QAcAjE,EAAAgE,SAAA3C,UAAAqE,OAAA,WACA,MAAAzE,MAAAgD,OAAAhB,IAAA,SAAAtB,GAEA,MADA3B,GAAAgE,SAAAM,4BAAA3C,GACAA,EAAAyC,SAgBApE,EAAAG,MAAA,WACAc,KAAA0E,WACA1E,KAAA2E,KAAA,KACA3E,KAAAb,SAAA,GAAAJ,GAAAgE,SACA/C,KAAA4E,cAAA,GAAA7F,GAAA8F,cACA7E,KAAA8E,SACA9E,KAAA+E,aAAA,GAAAhG,GAAAmB,aACAF,KAAAgF,aAEAhF,KAAAiF,GAAA,mCACAjF,KAAAgF,cACGE,KAAAlF,QAYHjB,EAAAG,MAAAkB,UAAA6E,GAAA,WACA,GAAA3E,GAAAC,MAAAH,UAAAI,MAAAhB,KAAAiB,UACA,OAAAT,MAAA+E,aAAA1E,YAAAmB,MAAAxB,KAAA+E,aAAAzE,IAUAvB,EAAAG,MAAAkB,UAAA+E,IAAA,SAAApE,EAAAL,GACA,MAAAV,MAAA+E,aAAA7D,eAAAH,EAAAL,IAaA3B,EAAAG,MAAAqE,KAAA,SAAA6B,GACAA,EAAA3F,UAAAV,EAAAU,SACAV,EAAAY,MAAAC,KAAA,6BACAb,EAAAU,QAAA,cAAA2F,EAAA3F,QAGA,IAAAR,GAAA,GAAAe,KAEAf,GAAAyF,QAAAU,EAAAC,OACApG,EAAA0F,KAAAS,EAAAE,IACArG,EAAA2F,cAAA7F,EAAA8F,cAAAtB,KAAA6B,EAAAR,eACA3F,EAAAE,SAAAJ,EAAAgE,SAAAQ,KAAA6B,EAAAjG,UACAF,EAAA6F,QACA,QAAAS,KAAAH,GAAAN,MACA7F,EAAA6F,MAAAS,GAAAxG,EAAAyG,cAAAjC,KAAA6B,EAAAN,MAAAS,GAGA,OAAAtG,IAgBAF,EAAAG,MAAAkB,UAAAqF,SAAA,SAAAC,GAGA,MAFA1F,MAAA0E,QAAAzD,KAAAyE,GACA1F,KAAA8E,MAAAY,GAAA,GAAA3G,GAAAyG,cACAxF,MAgBAjB,EAAAG,MAAAkB,UAAAuF,OAAA,SAAAC,GAEA,MADA5F,MAAA2E,KAAAiB,EACA5F,MAaAjB,EAAAG,MAAAkB,UAAAyF,aAAA,SAAAC,GAEA,MADA9F,MAAA4E,cAAA,GAAA7F,GAAA8F,cAAAiB,GACA9F,MAkBAjB,EAAAG,MAAAkB,UAAA2F,OAAA,SAAAC,EAAAC,GACA,GAAAD,EAAA,CACA,GAAAC,GAAAxE,SAAAwE,KAEAC,EAAAF,EAAAhG,KAAA2E,KAEA3E,MAAA4E,cAAAmB,OAAAG,EAAAF,GACAhG,KAAA0E,QAAA5D,QAAA,SAAAyE,GACA,GAAAY,GAAAnG,KAAAb,SAAA+E,IAAAnF,EAAA2C,UAAAsE,EAAAT,IACAvF,MAAA4E,cAAAwB,eAAAF,EAAAX,EAAAY,EAAA7E,OAEA,IAAA+E,KACAF,GAAArF,QAAA,SAAAiB,GACAA,IAAAsE,KAAAtE,IAAA,EACAsE,EAAAtE,GAAA,GACK/B,KAEL,QAAA+B,KAAAsE,GAAA,CACA,GAAAC,GAAAD,EAAAtE,EACAuE,GAAAC,KAAAC,KAAAF,GACAtG,KAAA8E,MAAAS,GAAAkB,SAAA1E,GAAyCuD,IAAAY,EAAAQ,GAAAJ,MAEtCtG,MAEHiG,GAAAjG,KAAA+E,aAAAxD,KAAA,MAAAyE,EAAAhG,QAmBAjB,EAAAG,MAAAkB,UAAAuG,eAAA,SAAAT,EAAAD,GACA,GAAAC,GACAlG,KAAA4E,cAAAgC,iBAAA,GAIA5G,KAAA4E,cAAAiC,OAAAX,GAAA,CACA,GAAAF,GAAAhG,KAAA4E,cAAAkC,OAAAZ,EACAlG,MAAA+G,UAAAf,GAAA,KAmBAjH,EAAAG,MAAAkB,UAAA2G,UAAA,SAAAf,EAAAC,GACA,GAAAD,EAAA,CAEA,GAAAC,GAAAxE,SAAAwE,KAEAC,EAAAF,EAAAhG,KAAA2E,KACA3E,MAAA4E,cAAAiC,OAAAX,KAEAlG,KAAA4E,cAAAmC,UAAAb,GAEAlG,KAAA0E,QAAA5D,QAAA,SAAAyE,GACA,GAAAY,GAAAnG,KAAAb,SAAA+E,IAAAnF,EAAA2C,UAAAsE,EAAAT,IACAY,GAAArF,QAAA,SAAAiB,GACA/B,KAAA8E,MAAAS,GAAAyB,YAAAjF,EAAAmE,IACKlG,OACFA,MAEHiG,GAAAjG,KAAA+E,aAAAxD,KAAA,SAAAyE,EAAAhG,SAuBAjB,EAAAG,MAAAkB,UAAA6G,UAAA,SAAAjB,EAAAC,GACA,GAAAA,GAAAxE,SAAAwE,IAEAjG,MAAA2G,eAAAX,EAAAhG,KAAA2E,OAAA,GACA3E,KAAA+F,OAAAC,GAAA,GAEAC,GAAAjG,KAAA+E,aAAAxD,KAAA,SAAAyE,EAAAhG,OAYAjB,EAAAG,MAAAkB,UAAA8G,IAAA,SAAAC,EAAA5B,GACA,GAAA6B,GAAA,IAAA7B,EAAA,IAAA4B,CACA,IAAAE,OAAAjH,UAAAtB,eAAAU,KAAAQ,KAAAgF,UAAAoC,GAAA,MAAApH,MAAAgF,UAAAoC,EAEA,IAAAE,GAAAtH,KAAA8E,MAAAS,GAAAgC,WAAAJ,GACAD,EAAA,EAAAX,KAAAiB,IAAAxH,KAAA4E,cAAAtD,QAAAgG,EAAA,GAGA,OAFAtH,MAAAgF,UAAAoC,GAAAF,EAEAA,GAQAnI,EAAAG,MAAAkB,UAAAqH,UAAA,WACA,MAAAzH,MAAA0E,QAAAlE,SA4BAzB,EAAAG,MAAAkB,UAAAsH,OAAA,SAAAC,EAAAC,GACA,IAAAD,EAAA,QAEA,IAAAE,GAAA,IACA,OAAAD,IACAC,EAAAC,KAAAC,UAAAH,GAGA,IAAA5I,GAAA,GAAAD,GAAAiJ,cAAAH,EAAA7H,KAAAyH,aAAAjD,MAEAyD,EAAAjI,KAAAb,SAAA+E,IAAAnF,EAAA2C,UAAAiG,IAEAO,IAEA,QAAA3C,KAAAvG,GAAA,CACA,GAAAmJ,GAAAnI,KAAAoI,YAAAH,EAAA1C,EAAAvG,GACAqJ,EAAArJ,EAAAuG,GAAA+C,KAEA,QAAApC,KAAAiC,GACAA,EAAAjC,GAAAiC,EAAAjC,GAAAmC,CAGA,QAAAnC,KAAAiC,GACAjC,IAAAgC,GACAA,EAAAhC,IAAAiC,EAAAjC,GAEAgC,EAAAhC,GAAAiC,EAAAjC,GAKA,GAAAqC,KACA,QAAArC,KAAAgC,GACAK,EAAAtH,MAAkBqE,IAAAY,EAAAsC,MAAAN,EAAAhC,IAIlB,OADAqC,GAAAE,KAAA,SAAAC,EAAAC,GAAgC,MAAAA,GAAAH,MAAAE,EAAAF,QAChCD,GAWAxJ,EAAAG,MAAAkB,UAAAgI,YAAA,SAAAH,EAAAvC,EAAA1G,GACA,GAAA4J,GAAA5J,EAAA0G,GAAAmD,KACAC,EAAA9J,EAAA0G,GAAAoD,OACAR,EAAAtJ,EAAA0G,GAAA4C,MACAS,EAAA,KACAC,IAGA,QAAAV,EAmFA,MA/EAL,GAAAnH,QAAA,SAAAiB,GACA,GAAAM,IAAAN,EACA,IAAA+G,IACAzG,EAAArC,KAAA8E,MAAAY,GAAAuD,YAAAlH,GAoBA,IAAAmH,KACA7G,GAAAvB,QAAA,SAAAqI,GACA,GAAAC,GAAApJ,KAAA8E,MAAAY,GAAA2D,QAAAF,GACAjC,EAAAlH,KAAAkH,IAAAiC,EAAAzD,EAEA,IAAAqD,GAAA,OAAAH,EAAA,CAIA,GAAAU,KACA,QAAApD,KAAA6C,GACA7C,IAAAkD,KACAE,EAAApD,GAAAkD,EAAAlD,GAGAkD,GAAAE,EAQAH,GAAApH,GACA/B,KAAAuJ,iBAAAP,EAAAG,EAAAC,EAGA,QAAAlD,KAAAkD,GAAA,CACA,GAAA1C,GAAA1G,KAAA8E,MAAAY,GAAA8D,iBAAAL,EAAAjD,GACAuD,EAAAzJ,KAAA4E,cAAA8E,eAAAxD,EAAAR,GACAiE,EAAA,CACA,IAAAF,IACAE,EAAA,EAAApD,KAAAC,KAAAiD,GAGA,IAAAG,GAAA,CACAT,IAAApH,IAGA6H,EAAA,QAAAT,EAAA7H,OAAAS,EAAAT,QAAA6H,EAAA7H,QAGA,IAAAkH,GAAA9B,EAAAQ,EAAAyC,EAAAC,CAEA1D,KAAAgD,GACAA,EAAAhD,IAAAsC,EAEAU,EAAAhD,GAAAsC,IAGKxI,MAEL+I,EAAA/I,KAAA6J,YAAAd,EAAAG,EAAAN,IACG5I,MAEH+I,EAAA/I,KAAA8J,UAAAf,EAAAC,EAAAf,EAAA3G,SAgBAvC,EAAAG,MAAAkB,UAAAyJ,YAAA,SAAAE,EAAAhB,EAAAiB,GACA,IAAAD,EACA,MAAAhB,EAEA,WAAAiB,EAAA,CACA,GAAAC,KACA,QAAA/D,KAAA6C,GACA7C,IAAA6D,KACAE,EAAA/D,GAAA6D,EAAA7D,GAAA6C,EAAA7C,GAGA,OAAA+D,GAEA,OAAA/D,KAAA6C,GACA7C,IAAA6D,GACAA,EAAA7D,IAAA6C,EAAA7C,GAEA6D,EAAA7D,GAAA6C,EAAA7C,EAGA,OAAA6D,IAcAhL,EAAAG,MAAAkB,UAAAmJ,iBAAA,SAAAP,EAAAjH,EAAAqH,GACA,OAAApD,KAAAoD,GACApD,IAAAgD,GACAA,EAAAhD,GAAA/E,KAAAc,GAEAiH,EAAAhD,IAAAjE,IAiBAhD,EAAAG,MAAAkB,UAAA0J,UAAA,SAAAf,EAAAC,EAAAkB,GACA,OAAAlE,KAAA+C,GACA,GAAA/C,IAAAgD,GAAA,CACA,GAAA3G,GAAA2G,EAAAhD,GAAA1E,MACAyH,GAAA/C,GAAA+C,EAAA/C,GAAA3D,EAAA6H,EAGA,MAAAnB,IASAhK,EAAAG,MAAAkB,UAAAqE,OAAA,WACA,GAAA0F,KAKA,OAJAnK,MAAA0E,QAAA5D,QAAA,SAAAyE,GACA4E,EAAA5E,GAAAvF,KAAA8E,MAAAS,GAAAd,UACGzE,OAGHP,QAAAV,EAAAU,QACA4F,OAAArF,KAAA0E,QACAY,IAAAtF,KAAA2E,KACAC,cAAA5E,KAAA4E,cAAAH,SACAK,MAAAqF,EACAhL,SAAAa,KAAAb,SAAAsF,WA8BA1F,EAAAG,MAAAkB,UAAAgK,IAAA,SAAAC,GACA,GAAA/J,GAAAC,MAAAH,UAAAI,MAAAhB,KAAAiB,UAAA,EACAH,GAAAgK,QAAAtK,MACAqK,EAAA7I,MAAAxB,KAAAM,IAqBAvB,EAAA8F,cAAA,SAAAiB,GACA,OAAAA,GAAArE,SAAAqE,EACA9F,KAAAuK,OAAA,EAEAvK,KAAAuK,MAAAzE,EAGA9F,KAAAoJ,QACApJ,KAAAwK,WACAxK,KAAAsB,OAAA,GASAvC,EAAA8F,cAAAtB,KAAA,SAAA6B,GACA,GAAAqF,GAAA,GAAAzK,KAOA,OALAyK,GAAAnJ,OAAA8D,EAAA9D,OACAmJ,EAAArB,KAAAhE,EAAAgE,KACAqB,EAAAD,QAAApF,EAAAoF,QACAC,EAAAF,MAAAnF,EAAAU,KAEA2E,GAQA1L,EAAA8F,cAAAzE,UAAAwG,YAAA,WACA,MAAA5G,MAAAuK,OAYAxL,EAAA8F,cAAAzE,UAAA2F,OAAA,SAAAG,EAAAF,GACAhG,KAAA6G,OAAAX,IAAAlG,KAAAsB,SAEAtB,KAAAuK,SAAA,EACAvK,KAAAoJ,KAAAlD,GAAAzH,EAAAuH,GAEAhG,KAAAoJ,KAAAlD,GAAA,MAcAnH,EAAA8F,cAAAzE,UAAA0G,OAAA,SAAAZ,GACA,MAAAlG,MAAA6G,OAAAX,MAAA,OACAlG,KAAAoJ,KAAAlD,IAUAnH,EAAA8F,cAAAzE,UAAAyG,OAAA,SAAAX,GACA,MAAAA,KAAAlG,MAAAoJ,MASArK,EAAA8F,cAAAzE,UAAA2G,UAAA,SAAAb,GACAlG,KAAA6G,OAAAX,WAEAlG,MAAAoJ,KAAAlD,SACAlG,MAAAwK,QAAAtE,GACAlG,KAAAsB,WAWAvC,EAAA8F,cAAAzE,UAAAgG,eAAA,SAAAF,EAAAR,EAAApE,GACA,OAAA4E,GAAAzE,SAAAyE,GACA,GAAAlG,KAAA6G,OAAAX,KAEAlG,KAAAwK,QAAAtE,KAAAlG,KAAAwK,QAAAtE,OACAlG,KAAAwK,QAAAtE,GAAAR,GAAApE,IAWAvC,EAAA8F,cAAAzE,UAAAsK,kBAAA,SAAAxE,EAAAR,EAAApE,GACA,OAAA4E,GAAAzE,SAAAyE,GACA,GAAAlG,KAAA6G,OAAAX,IAEAlG,KAAAoG,eAAAF,EAAAR,EAAApE,IAUAvC,EAAA8F,cAAAzE,UAAAsJ,eAAA,SAAAxD,EAAAR,GACA,cAAAQ,GAAAzE,SAAAyE,EAAA,EAEAA,IAAAlG,MAAAoJ,MACA1D,IAAA1F,MAAAwK,QAAAtE,GACAlG,KAAAwK,QAAAtE,GAAAR,GAFA,GAWA3G,EAAA8F,cAAAzE,UAAAqE,OAAA,WACA,OACA2E,KAAApJ,KAAAoJ,KACAoB,QAAAxK,KAAAwK,QACAlJ,OAAAtB,KAAAsB,OACAwE,KAAA9F,KAAAuK,QAqCAxL,EAAAQ,QAAA,WACA,GAAAoL,IACAC,QAAA,MACAC,OAAA,OACAC,KAAA,OACAC,KAAA,OACAC,KAAA,MACAC,IAAA,MACAC,KAAA,KACAC,MAAA,MACAC,IAAA,IACAC,MAAA,MACAC,QAAA,MACAC,MAAA,MACAC,KAAA,MACAC,MAAA,KACAC,QAAA,MACAC,QAAA,MACAC,QAAA,MACAC,MAAA,KACAC,MAAA,MACAC,OAAA,MACAC,KAAA,OAGAC,GACAC,MAAA,KACAC,MAAA,GACAC,MAAA,KACAC,MAAA,KACAC,KAAA,KACAC,IAAA,GACAC,KAAA,IAGAC,EAAA,WACAC,EAAA,WACAC,EAAAF,EAAA,aACAG,EAAAF,EAAA,WAEAG,EAAA,KAAAF,EAAA,KAAAC,EAAAD,EACAG,EAAA,KAAAH,EAAA,KAAAC,EAAAD,EAAA,IAAAC,EAAA,MACAG,EAAA,KAAAJ,EAAA,KAAAC,EAAAD,EAAAC,EAAAD,EACAK,EAAA,KAAAL,EAAA,KAAAD,EAEAO,EAAA,GAAAC,QAAAL,GACAM,EAAA,GAAAD,QAAAH,GACAK,EAAA,GAAAF,QAAAJ,GACAO,EAAA,GAAAH,QAAAF,GAEAM,EAAA,kBACAC,EAAA,iBACAC,EAAA,aACAC,EAAA,kBACAC,EAAA,KACAC,EAAA,cACAC,EAAA,GAAAV,QAAA,sBACAW,EAAA,GAAAX,QAAA,IAAAP,EAAAD,EAAA,gBAEAoB,EAAA,mBACAC,EAAA,2IAEAC,EAAA,iDAEAC,EAAA,sFACAC,EAAA,oBAEAC,EAAA,WACAC,EAAA,MACAC,EAAA,GAAAnB,QAAA,IAAAP,EAAAD,EAAA,gBAEA4B,EAAA,SAAAC,GACA,GAAAC,GACAC,EACAC,EACAC,EACAC,EACAC,EACAC,CAEA,IAAAP,EAAAjN,OAAA,EAAuB,MAAAiN,EAiBvB,IAfAG,EAAAH,EAAAQ,OAAA,KACA,KAAAL,IACAH,EAAAG,EAAAM,cAAAT,EAAAQ,OAAA,IAIAJ,EAAArB,EACAsB,EAAArB,EAEAoB,EAAAM,KAAAV,GAAqBA,IAAAW,QAAAP,EAAA,QACrBC,EAAAK,KAAAV,KAA2BA,IAAAW,QAAAN,EAAA,SAG3BD,EAAAnB,EACAoB,EAAAnB,EACAkB,EAAAM,KAAAV,GAAA,CACA,GAAAY,GAAAR,EAAAS,KAAAb,EACAI,GAAA1B,EACA0B,EAAAM,KAAAE,EAAA,MACAR,EAAAjB,EACAa,IAAAW,QAAAP,EAAA,SAEK,IAAAC,EAAAK,KAAAV,GAAA,CACL,GAAAY,GAAAP,EAAAQ,KAAAb,EACAC,GAAAW,EAAA,GACAP,EAAAvB,EACAuB,EAAAK,KAAAT,KACAD,EAAAC,EACAI,EAAAjB,EACAkB,EAAAjB,EACAkB,EAAAjB,EACAe,EAAAK,KAAAV,GAA0BA,GAAA,IAC1BM,EAAAI,KAAAV,IAA+BI,EAAAjB,EAAca,IAAAW,QAAAP,EAAA,KAC7CG,EAAAG,KAAAV,KAA+BA,GAAA,MAM/B,GADAI,EAAAb,EACAa,EAAAM,KAAAV,GAAA,CACA,GAAAY,GAAAR,EAAAS,KAAAb,EACAC,GAAAW,EAAA,GACAZ,EAAAC,EAAA,IAKA,GADAG,EAAAZ,EACAY,EAAAM,KAAAV,GAAA,CACA,GAAAY,GAAAR,EAAAS,KAAAb,EACAC,GAAAW,EAAA,GACAV,EAAAU,EAAA,GACAR,EAAA1B,EACA0B,EAAAM,KAAAT,KACAD,EAAAC,EAAA7D,EAAA8D,IAMA,GADAE,EAAAX,EACAW,EAAAM,KAAAV,GAAA,CACA,GAAAY,GAAAR,EAAAS,KAAAb,EACAC,GAAAW,EAAA,GACAV,EAAAU,EAAA,GACAR,EAAA1B,EACA0B,EAAAM,KAAAT,KACAD,EAAAC,EAAAvC,EAAAwC,IAOA,GAFAE,EAAAV,EACAW,EAAAV,EACAS,EAAAM,KAAAV,GAAA,CACA,GAAAY,GAAAR,EAAAS,KAAAb,EACAC,GAAAW,EAAA,GACAR,EAAAxB,EACAwB,EAAAM,KAAAT,KACAD,EAAAC,OAEK,IAAAI,EAAAK,KAAAV,GAAA,CACL,GAAAY,GAAAP,EAAAQ,KAAAb,EACAC,GAAAW,EAAA,GAAAA,EAAA,GACAP,EAAAzB,EACAyB,EAAAK,KAAAT,KACAD,EAAAC,GAMA,GADAG,EAAAR,EACAQ,EAAAM,KAAAV,GAAA,CACA,GAAAY,GAAAR,EAAAS,KAAAb,EACAC,GAAAW,EAAA,GACAR,EAAAxB,EACAyB,EAAAxB,EACAyB,EAAAR,GACAM,EAAAM,KAAAT,IAAAI,EAAAK,KAAAT,KAAAK,EAAAI,KAAAT,MACAD,EAAAC,GAiBA,MAbAG,GAAAP,EACAQ,EAAAzB,EACAwB,EAAAM,KAAAV,IAAAK,EAAAK,KAAAV,KACAI,EAAAjB,EACAa,IAAAW,QAAAP,EAAA,KAKA,KAAAD,IACAH,EAAAG,EAAAxM,cAAAqM,EAAAQ,OAAA,IAGAR,EAGA,OAAAD,MAGAvP,EAAAgE,SAAAG,iBAAAnE,EAAAQ,QAAA,WAoBAR,EAAAO,eAAA,SAAAyC,GACA,GAAAA,GAAAhD,EAAAO,eAAA+P,UAAAtN,MAAA,EACA,MAAAA,IAWAhD,EAAAuQ,eAAA,WACAvQ,EAAAO,eAAA+P,cAUAtQ,EAAAwQ,aAAA,SAAAC,GACA,MAAAA,GAAAjP,MAAAqB,QAAA4N,MAAA,GAEAA,EAAA1O,QAAA,SAAA2O,GACA1Q,EAAAO,eAAA+P,UAAAI,IAAA,GACGzP,OASHjB,EAAA2Q,eAAA,WACA3Q,EAAAO,eAAA+P,UAAAtQ,EAAA4Q,kBAGA5Q,EAAA4Q,kBACAC,IAAA,EACAlH,GAAA,EACAmH,MAAA,EACAC,OAAA,EACAC,QAAA,EACAnM,OAAA,EACAoM,KAAA,EACAC,QAAA,EACAC,MAAA,EACAC,IAAA,EACAC,OAAA,EACAC,IAAA,EACAC,KAAA,EACAC,KAAA,EACAC,KAAA,EACAC,IAAA,EACAC,IAAA,EACAC,IAAA,EACAC,SAAA,EACAC,MAAA,EACAC,KAAA,EACAC,IAAA,EACAC,KAAA,EACAC,QAAA,EACAC,OAAA,EACAC,MAAA,EACAC,KAAA,EACAC,IAAA,EACAC,MAAA,EACAC,QAAA,EACAC,MAAA,EACAC,MAAA,EACAC,OAAA,EACAC,KAAA,EACAC,MAAA,EACApN,KAAA,EACAqN,KAAA,EACAC,KAAA,EACAC,KAAA,EACAC,MAAA,EACAC,IAAA,EACAC,KAAA,EACAC,MAAA,EACAC,KAAA,EACAC,KAAA,EACAC,KAAA,EACAC,SAAA,EACAlO,GAAA,EACAmO,IAAA,EACAC,IAAA,EACAC,MAAA,EACAC,IAAA,EACAC,IAAA,EACAC,KAAA,EACAC,MAAA,EACAC,OAAA,EACAC,KAAA,EACAC,MAAA,EACAC,QAAA,EACAC,KAAA,EACAC,IAAA,EACAC,OAAA,EACAC,MAAA,EACAC,MAAA,EACAC,IAAA,EACAC,SAAA,EACAC,IAAA,EACAC,KAAA,EACAC,KAAA,EACAC,IAAA,EACA1O,KAAA,EACA2O,OAAA,EACA7O,IAAA,EACA8O,MAAA,EACAC,IAAA,EACAC,OAAA,EACAC,KAAA,EACAC,KAAA,EACAC,QAAA,EACAC,MAAA,EACAC,KAAA,EACAC,MAAA,EACAC,KAAA,EACAC,QAAA,EACAC,OAAA,EACAC,IAAA,EACAC,MAAA,EACAC,MAAA,EACAC,MAAA,EACAC,KAAA,EACAC,OAAA,EACAC,MAAA,EACAC,MAAA,EACAC,OAAA,EACAC,OAAA,EACAC,MAAA,EACArV,MAAA,EACAsV,KAAA,EACAC,IAAA,EACAC,KAAA,EACAC,MAAA,EACAC,IAAA,EACAC,OAAA,EACAC,KAAA,EACAC,IAAA,EACAC,MAAA,EACAC,MAAA,EACAC,MAAA,EACAC,OAAA,EACAC,OAAA,EACAC,OAAA,EACAC,KAAA,EACAC,MAAA,EACAC,KAAA,EACAC,MAAA,EACAC,MAAA,EACAC,OAAA,EACAC,KAAA,EACAC,KAAA,EACAC,MAAA,GAGA7X,EAAAO,eAAA+P,UAAAtQ,EAAA4Q,iBAEA5Q,EAAAgE,SAAAG,iBAAAnE,EAAAO,eAAA,kBAqBAP,EAAAM,QAAA,SAAA0C,GACA,UAAAA,GAAAN,SAAAM,EACA,SAAA2B,OAAA,gCAGA,OAAA3B,GACAmN,QAAA,WACAA,QAAA,YAGAnQ,EAAAgE,SAAAG,iBAAAnE,EAAAM,QAAA,WAaAN,EAAAyG,cAAA,WACAxF,KAAA6W,MAAezN,QAAS9B,GAAA,IASxBvI,EAAAyG,cAAAjC,KAAA,SAAA6B,GACA,GAAAnG,GAAA,GAAAe,KAGA,OAFAf,GAAA4X,KAAAzR,EAAAyR,KAEA5X,GAqBAF,EAAAyG,cAAApF,UAAAqG,SAAA,SAAA1E,EAAA+U,EAAAD,GAIA,IAHA,GAAAA,MAAA7W,KAAA6W,KACA5X,EAAA,EAEAA,GAAA8C,EAAAT,OAAA,IACA,GAAA6H,GAAApH,EAAA9C,EAEAkK,KAAA0N,OAAA1N,IAAqCC,QAAQ9B,GAAA,IAC7CrI,GAAA,EACA4X,IAAA1N,GAGA,GAAAjD,GAAA4Q,EAAAxR,GACAuR,GAAAzN,KAAAlD,GAMA2Q,EAAAzN,KAAAlD,IAAyBQ,GAAAoQ,EAAApQ,KAJzBmQ,EAAAzN,KAAAlD,IAAyBQ,GAAAoQ,EAAApQ,IACzBmQ,EAAAvP,IAAA,IAeAvI,EAAAyG,cAAApF,UAAA2W,SAAA,SAAAhV,GACA,IAAAA,EAAA,QAIA,QAFAiV,GAAAhX,KAAA6W,KAEAxS,EAAA,EAAiBA,EAAAtC,EAAAT,OAAkB+C,IAAA,CACnC,IAAA2S,EAAAjV,EAAAsC,IAAA,QACA2S,KAAAjV,EAAAsC,IAGA,UAaAtF,EAAAyG,cAAApF,UAAA6W,QAAA,SAAAlV,GACA,IAAAA,EAAA,WAIA,QAFAiV,GAAAhX,KAAA6W,KAEAxS,EAAA,EAAiBA,EAAAtC,EAAAT,OAAkB+C,IAAA,CACnC,IAAA2S,EAAAjV,EAAAsC,IAAA,WACA2S,KAAAjV,EAAAsC,IAGA,MAAA2S,IAYAjY,EAAAyG,cAAApF,UAAAiJ,QAAA,SAAAtH,GACA,GAAAiV,GAAAhX,KAAAiX,QAAAlV,EACA,cAAAiV,KAIAA,EAAA5N,MAaArK,EAAAyG,cAAApF,UAAAoJ,iBAAA,SAAAzH,EAAAmE,GACA,GAAA8Q,GAAAhX,KAAAiX,QAAAlV,EAEA,cAAAiV,EACA,EAGA9Q,IAAA8Q,GAAA5N,KAIA4N,EAAA5N,KAAAlD,GAAAQ,GAHA,GAeA3H,EAAAyG,cAAApF,UAAAmH,WAAA,SAAAxF,GACA,GAAAiV,GAAAhX,KAAAiX,QAAAlV,EAEA,cAAAiV,EACA,EAGAA,EAAA1P,IAWAvI,EAAAyG,cAAApF,UAAA4G,YAAA,SAAAjF,EAAAuD,GACA,GAAAvD,EAAA,CACA,GAAAiV,GAAAhX,KAAAiX,QAAAlV,EAEA,OAAAiV,GAEA1R,IAAA0R,GAAA5N,aACA4N,GAAA5N,KAAA9D,GACA0R,EAAA1P,IAAA,KAYAvI,EAAAyG,cAAApF,UAAA6I,YAAA,SAAAlH,EAAAmV,EAAAL,GACA,SAAA9U,GAAA,IAAAA,EAAA,QACA,IAAAmV,QAEA,YAAAL,IACAA,EAAA7W,KAAAiX,QAAAlV,GACA,MAAA8U,GAAA,MAAAK,EAGAL,GAAAvP,GAAA,GAAA4P,EAAAjW,KAAAc,EAEA,QAAAoH,KAAA0N,GACA,SAAA1N,GACA,OAAAA,GACAnJ,KAAAiJ,YAAAlH,EAAAoH,EAAA+N,EAAAL,EAAA1N,GAGA,OAAA+N,IASAnY,EAAAyG,cAAApF,UAAAqE,OAAA,WACA,OACAoS,KAAA7W,KAAA6W,OAgFA9X,EAAAiJ,cAAA,SAAAhJ,EAAAqG,GACA,GAAArG,MAAA,EAEA,IAAAyC,QAAA4D,GAAA,MAAAA,EACA,SAAA3B,OAAA,4BAGA1D,MAAAhB,SAEA,IAAA4I,EACA,KACAA,EAAAE,KAAAqP,MAAAnY,GACAgB,KAAAoX,gBAAAxP,EAAAvC,GACG,MAAAgS,GACHtY,EAAAY,MAAAC,KAAA,mEACAI,KAAAsX,mBAAAjS,KASAtG,EAAAiJ,cAAA5H,UAAAkX,mBAAA,SAAAjS,GACArF,KAAAuE,QACAc,EAAAvE,QAAA,SAAAyE,GACAvF,KAAAhB,OAAAuG,IACA+C,MAAA,EACAO,KAAA,KACAC,QAAA,IAEG9I,OASHjB,EAAAiJ,cAAA5H,UAAAgX,gBAAA,SAAApY,EAAAqG,GACA,GAAAkS,GAAA,KACAC,GAAA,CAWA,IATAxX,KAAAuE,QACA,QAAAvF,KACAuY,EAAAvY,EAAA,MAAAuY,GAGA,UAAAvY,KACAwY,EAAAxY,EAAA,QAAAwY,GAGA,UAAAxY,GACA,OAAAuG,KAAAvG,GAAA,OACA,GAAAqG,EAAAjE,QAAAmE,IAAA,GACA,GAAAkS,GAAAzY,EAAA,OAAAuG,GACAmS,EAAAF,CACA/V,SAAAgW,EAAA3O,SACA4O,EAAAD,EAAA3O,QAGA9I,KAAAhB,OAAAuG,IACA+C,MAAAmP,EAAAnP,OAAA,IAAAmP,EAAAnP,MAAAmP,EAAAnP,MAAA,EACAO,KAAA4O,EAAA5O,MAAA0O,EACAzO,OAAA4O,OAGA3Y,GAAAY,MAAAC,KAAA,2EAIAI,MAAA2X,wBAAAJ,EAAAC,EAAAnS,IAWAtG,EAAAiJ,cAAA5H,UAAAuX,wBAAA,SAAA9O,EAAAC,EAAAzD,GACAA,EAAAvE,QAAA,SAAAyE,GACAvF,KAAAhB,OAAAuG,IACA+C,MAAA,EACAO,OACAC,WAEG9I,OAMHjB,EAAAiJ,cAAA5H,UAAAoE,IAAA,WACA,MAAAxE,MAAAhB,QAMAD,EAAAiJ,cAAA5H,UAAAmE,MAAA,WACAvE,KAAAhB,WAqBAU,KAAAkY,UAAA,WACA5X,KAAAsB,OAAA,EACAtB,KAAA6X,aAUAnY,KAAAkY,UAAArU,KAAA,SAAA6B,GACA,GAAA0S,GAAA,GAAA9X,KAKA,OAHA8X,GAAAD,SAAAzS,EACA0S,EAAAxW,OAAA8D,EAAA9D,OAEAwW,GAUApY,KAAAkY,UAAAxX,UAAAhB,IAAA,WACA,GAAAiF,GAAA0T,CAEA,KAAA1T,EAAA,EAAaA,EAAA5D,UAAAa,OAAsB+C,IACnC0T,EAAAtX,UAAA4D,IACArE,KAAAoB,QAAA2W,IACA/X,KAAA6X,SAAAxW,OAAArB,KAAAgY,YAAAD,GAAA,EAAAA,EAGA/X,MAAAsB,OAAAtB,KAAA6X,SAAAvW,QASA5B,KAAAkY,UAAAxX,UAAA6X,QAAA,WACA,MAAAjY,MAAA6X,SAAArX,SAgBAd,KAAAkY,UAAAxX,UAAA4B,IAAA,SAAAtB,EAAAwX,GACA,MAAAlY,MAAA6X,SAAA7V,IAAAtB,EAAAwX,IAcAxY,KAAAkY,UAAAxX,UAAAU,QAAA,SAAAJ,EAAAwX,GACA,MAAAlY,MAAA6X,SAAA/W,QAAAJ,EAAAwX,IAWAxY,KAAAkY,UAAAxX,UAAAgB,QAAA,SAAA+W,GAOA,IANA,GAAAC,GAAA,EACAC,EAAArY,KAAA6X,SAAAvW,OACAgX,EAAAD,EAAAD,EACAG,EAAAH,EAAA7R,KAAAiS,MAAAF,EAAA,GACAG,EAAAzY,KAAA6X,SAAAU,GAEAD,EAAA,IACA,GAAAG,IAAAN,EAAA,MAAAI,EAEAE,GAAAN,IAAAC,EAAAG,GACAE,EAAAN,IAAAE,EAAAE,GAEAD,EAAAD,EAAAD,EACAG,EAAAH,EAAA7R,KAAAiS,MAAAF,EAAA,GACAG,EAAAzY,KAAA6X,SAAAU,GAGA,MAAAE,KAAAN,EAAAI,GAEA,GAcA7Y,KAAAkY,UAAAxX,UAAA4X,YAAA,SAAAG,GAOA,IANA,GAAAC,GAAA,EACAC,EAAArY,KAAA6X,SAAAvW,OACAgX,EAAAD,EAAAD,EACAG,EAAAH,EAAA7R,KAAAiS,MAAAF,EAAA,GACAG,EAAAzY,KAAA6X,SAAAU,GAEAD,EAAA,GACAG,EAAAN,IAAAC,EAAAG,GACAE,EAAAN,IAAAE,EAAAE,GAEAD,EAAAD,EAAAD,EACAG,EAAAH,EAAA7R,KAAAiS,MAAAF,EAAA,GACAG,EAAAzY,KAAA6X,SAAAU,EAGA,OAAAE,GAAAN,EAAAI,EACAE,EAAAN,EAAAI,EAAA,UAWA7Y,KAAAkY,UAAAxX,UAAAsY,UAAA,SAAAC,GAMA,IALA,GAAAC,GAAA,GAAAlZ,MAAAkY,UACAvT,EAAA,EAAAC,EAAA,EACAuU,EAAA7Y,KAAAsB,OAAAwX,EAAAH,EAAArX,OACAoH,EAAA1I,KAAA6X,SAAAlP,EAAAgQ,EAAAd,WAEA,CACA,GAAAxT,EAAAwU,EAAA,GAAAvU,EAAAwU,EAAA,OAEApQ,GAAArE,KAAAsE,EAAArE,GAMAoE,EAAArE,GAAAsE,EAAArE,GACAD,IAIAqE,EAAArE,GAAAsE,EAAArE,IACAA,KAXAsU,EAAAxZ,IAAAsJ,EAAArE,IACAA,IAAAC,KAeA,MAAAsU,IASAlZ,KAAAkY,UAAAxX,UAAA3B,MAAA,WACA,GAAAA,GAAA,GAAAiB,MAAAkY,SAKA,OAHAnZ,GAAAoZ,SAAA7X,KAAAiY,UACAxZ,EAAA6C,OAAA7C,EAAAoZ,SAAAvW,OAEA7C,GAWAiB,KAAAkY,UAAAxX,UAAA2Y,MAAA,SAAAJ,GACA,GAAAK,GAAAC,EAAAC,CAEAlZ,MAAAsB,QAAAqX,EAAArX,QACA0X,EAAAhZ,KAAAiZ,EAAAN,IAEAK,EAAAL,EAAAM,EAAAjZ,MAGAkZ,EAAAF,EAAAva,OAEA,QAAA4F,GAAA,EAAA8U,EAAAF,EAAAhB,UAAuD5T,EAAA8U,EAAA7X,OAA6B+C,IACpF6U,EAAA9Z,IAAA+Z,EAAA9U,GAGA,OAAA6U,IASAxZ,KAAAkY,UAAAxX,UAAAqE,OAAA,WACA,MAAAzE,MAAAiY,WAMG,SAAApB,EAAAuC,GAGH7a,EAAA,EAAAC,EAAA,kBAAAD,KAAAiB,KAAAnB,EAAAC,EAAAD,EAAAD,GAAAG,IAAAkD,SAAAjD,IAAAJ,EAAAC,QAAAG,KAYGwB,KAAA,WAMH,MAAAjB,SDYMsa,GACA,SAAUjb,EAAQC,EAASC,GAEhC,YAWA,SAASgb,GAAuB5a,GAAO,MAAOA,IAAOA,EAAI6a,WAAa7a,GAAQ8a,QAAS9a,GAEvF,QAAS+a,GAAgBC,EAAUC,GAAe,KAAMD,YAAoBC,IAAgB,KAAM,IAAI9Y,WAAU,qCAEhH,QAAS+Y,GAA2BC,EAAMra,GAAQ,IAAKqa,EAAQ,KAAM,IAAIC,gBAAe,4DAAgE,QAAOta,GAAyB,gBAATA,IAAqC,kBAATA,GAA8Bqa,EAAPra,EAElO,QAASua,GAAUC,EAAUC,GAAc,GAA0B,kBAAfA,IAA4C,OAAfA,EAAuB,KAAM,IAAIpZ,WAAU,iEAAoEoZ,GAAeD,GAAS5Z,UAAYiH,OAAO6S,OAAOD,GAAcA,EAAW7Z,WAAaxB,aAAeub,MAAOH,EAAUI,YAAY,EAAOC,UAAU,EAAMC,cAAc,KAAeL,IAAY5S,OAAOkT,eAAiBlT,OAAOkT,eAAeP,EAAUC,GAAcD,EAASQ,UAAYP,GAfje5b,EAAQkb,YAAa,EACrBlb,EAAQsJ,MAAQlG,MEp8EjB,IAAAgZ,GAAAnc,EAAA,GFw8EKoc,EAAUpB,EAAuBmB,GEv8EtCE,EAAArc,EAAA,KAWqBsc,GARRjT,2CFq9EC,SAAUkT,GE58EpB,QAAAD,GAAYE,GAAOrB,EAAAzZ,KAAA4a,EAAA,IAAAG,GAAAnB,EAAA5Z,KACf6a,EAAArb,KAAAQ,KAAM8a,GADS,OAAAC,GAuBnBC,iBAAmB,iBAAMD,GAAKjW,MACxBiW,EAAKjW,MAEL5F,QAAMqE,KAAKwX,EAAKD,MAAMG,KAAKC,gBAAgBpW,QA1B9BiW,EA4BnBrT,OAAS,SAACyT,GACN,GAAMxT,GAAQwT,EAAIC,OAAOjB,KACzBY,GAAKjW,MAAQiW,EAAKC,mBAClBD,EAAKM,UACD1T,QAEAY,QAASwS,EAAKjW,MAAM4C,OAAOC,GAEtB3F,IAAI,SAAA2C,GAAA,GACLW,GADKX,EACLW,GADK,OAECyV,GAAKjW,MAAMF,cAAckC,OAAOxB,QApC9CyV,EAAKO,OACD3T,SACAY,YAJWwS,EFqgFlB,MAxDAhB,GAAUa,EAAQC,GAmClBD,EAAOxa,UEx+ERmb,OFw+E2B,WEv+EvB,MACIb,GAAAlB,QAAAgC,cAAA,WACId,EAAAlB,QAAAgC,cAAA,SAAOC,KAAK,OAAOC,UAAU,SAASvB,MAAOna,KAAKsb,MAAM3T,MAAOgU,SAAU3b,KAAK0H,SAC9EgT,EAAAlB,QAAAgC,cAAA,UACKxb,KAAKsb,MAAM/S,QAAQvG,IAAI,SAAA4Z,GAAA,MACpBlB,GAAAlB,QAAAgC,cAAA,UACKI,EAAKC,MADV,KACmBD,EAAKE,SAASC,KAAd,WFs/E/BnB,GEtgFwBoB,aFygFnC3d,GAAQmb,QEzgFYoB","file":"component---src-pages-search-js-899e2388c071b1605ac4.js","sourcesContent":["webpackJsonp([142807904292071],{\n\n/***/ 114:\n/***/ (function(module, exports, __webpack_require__) {\n\n\tvar __WEBPACK_AMD_DEFINE_FACTORY__, __WEBPACK_AMD_DEFINE_RESULT__;/**\n\t * elasticlunr - http://weixsong.github.io\n\t * Lightweight full-text search engine in Javascript for browser search and offline search. - 0.9.5\n\t *\n\t * Copyright (C) 2016 Oliver Nightingale\n\t * Copyright (C) 2016 Wei Song\n\t * MIT Licensed\n\t * @license\n\t */\n\t\n\t(function(){\n\t\n\t/*!\n\t * elasticlunr.js\n\t * Copyright (C) 2016 Oliver Nightingale\n\t * Copyright (C) 2016 Wei Song\n\t */\n\t\n\t/**\n\t * Convenience function for instantiating a new elasticlunr index and configuring it\n\t * with the default pipeline functions and the passed config function.\n\t *\n\t * When using this convenience function a new index will be created with the\n\t * following functions already in the pipeline:\n\t * \n\t * 1. elasticlunr.trimmer - trim non-word character\n\t * 2. elasticlunr.StopWordFilter - filters out any stop words before they enter the\n\t * index\n\t * 3. elasticlunr.stemmer - stems the tokens before entering the index.\n\t *\n\t *\n\t * Example:\n\t *\n\t *     var idx = elasticlunr(function () {\n\t *       this.addField('id');\n\t *       this.addField('title');\n\t *       this.addField('body');\n\t *       \n\t *       //this.setRef('id'); // default ref is 'id'\n\t *\n\t *       this.pipeline.add(function () {\n\t *         // some custom pipeline function\n\t *       });\n\t *     });\n\t * \n\t *    idx.addDoc({\n\t *      id: 1, \n\t *      title: 'Oracle released database 12g',\n\t *      body: 'Yestaday, Oracle has released their latest database, named 12g, more robust. this product will increase Oracle profit.'\n\t *    });\n\t * \n\t *    idx.addDoc({\n\t *      id: 2, \n\t *      title: 'Oracle released annual profit report',\n\t *      body: 'Yestaday, Oracle has released their annual profit report of 2015, total profit is 12.5 Billion.'\n\t *    });\n\t * \n\t *    # simple search\n\t *    idx.search('oracle database');\n\t * \n\t *    # search with query-time boosting\n\t *    idx.search('oracle database', {fields: {title: {boost: 2}, body: {boost: 1}}});\n\t *\n\t * @param {Function} config A function that will be called with the new instance\n\t * of the elasticlunr.Index as both its context and first parameter. It can be used to\n\t * customize the instance of new elasticlunr.Index.\n\t * @namespace\n\t * @module\n\t * @return {elasticlunr.Index}\n\t *\n\t */\n\tvar elasticlunr = function (config) {\n\t  var idx = new elasticlunr.Index;\n\t\n\t  idx.pipeline.add(\n\t    elasticlunr.trimmer,\n\t    elasticlunr.stopWordFilter,\n\t    elasticlunr.stemmer\n\t  );\n\t\n\t  if (config) config.call(idx, idx);\n\t\n\t  return idx;\n\t};\n\t\n\telasticlunr.version = \"0.9.5\";\n\t\n\t// only used this to make elasticlunr.js compatible with lunr-languages\n\t// this is a trick to define a global alias of elasticlunr\n\tlunr = elasticlunr;\n\t\n\t/*!\n\t * elasticlunr.utils\n\t * Copyright (C) 2016 Oliver Nightingale\n\t * Copyright (C) 2016 Wei Song\n\t */\n\t\n\t/**\n\t * A namespace containing utils for the rest of the elasticlunr library\n\t */\n\telasticlunr.utils = {};\n\t\n\t/**\n\t * Print a warning message to the console.\n\t *\n\t * @param {String} message The message to be printed.\n\t * @memberOf Utils\n\t */\n\telasticlunr.utils.warn = (function (global) {\n\t  return function (message) {\n\t    if (global.console && console.warn) {\n\t      console.warn(message);\n\t    }\n\t  };\n\t})(this);\n\t\n\t/**\n\t * Convert an object to string.\n\t *\n\t * In the case of `null` and `undefined` the function returns\n\t * an empty string, in all other cases the result of calling\n\t * `toString` on the passed object is returned.\n\t *\n\t * @param {object} obj The object to convert to a string.\n\t * @return {String} string representation of the passed object.\n\t * @memberOf Utils\n\t */\n\telasticlunr.utils.toString = function (obj) {\n\t  if (obj === void 0 || obj === null) {\n\t    return \"\";\n\t  }\n\t\n\t  return obj.toString();\n\t};\n\t/*!\n\t * elasticlunr.EventEmitter\n\t * Copyright (C) 2016 Oliver Nightingale\n\t * Copyright (C) 2016 Wei Song\n\t */\n\t\n\t/**\n\t * elasticlunr.EventEmitter is an event emitter for elasticlunr.\n\t * It manages adding and removing event handlers and triggering events and their handlers.\n\t *\n\t * Each event could has multiple corresponding functions,\n\t * these functions will be called as the sequence that they are added into the event.\n\t * \n\t * @constructor\n\t */\n\telasticlunr.EventEmitter = function () {\n\t  this.events = {};\n\t};\n\t\n\t/**\n\t * Binds a handler function to a specific event(s).\n\t *\n\t * Can bind a single function to many different events in one call.\n\t *\n\t * @param {String} [eventName] The name(s) of events to bind this function to.\n\t * @param {Function} fn The function to call when an event is fired.\n\t * @memberOf EventEmitter\n\t */\n\telasticlunr.EventEmitter.prototype.addListener = function () {\n\t  var args = Array.prototype.slice.call(arguments),\n\t      fn = args.pop(),\n\t      names = args;\n\t\n\t  if (typeof fn !== \"function\") throw new TypeError (\"last argument must be a function\");\n\t\n\t  names.forEach(function (name) {\n\t    if (!this.hasHandler(name)) this.events[name] = [];\n\t    this.events[name].push(fn);\n\t  }, this);\n\t};\n\t\n\t/**\n\t * Removes a handler function from a specific event.\n\t *\n\t * @param {String} eventName The name of the event to remove this function from.\n\t * @param {Function} fn The function to remove from an event.\n\t * @memberOf EventEmitter\n\t */\n\telasticlunr.EventEmitter.prototype.removeListener = function (name, fn) {\n\t  if (!this.hasHandler(name)) return;\n\t\n\t  var fnIndex = this.events[name].indexOf(fn);\n\t  if (fnIndex === -1) return;\n\t\n\t  this.events[name].splice(fnIndex, 1);\n\t\n\t  if (this.events[name].length == 0) delete this.events[name];\n\t};\n\t\n\t/**\n\t * Call all functions that bounded to the given event.\n\t *\n\t * Additional data can be passed to the event handler as arguments to `emit`\n\t * after the event name.\n\t *\n\t * @param {String} eventName The name of the event to emit.\n\t * @memberOf EventEmitter\n\t */\n\telasticlunr.EventEmitter.prototype.emit = function (name) {\n\t  if (!this.hasHandler(name)) return;\n\t\n\t  var args = Array.prototype.slice.call(arguments, 1);\n\t\n\t  this.events[name].forEach(function (fn) {\n\t    fn.apply(undefined, args);\n\t  }, this);\n\t};\n\t\n\t/**\n\t * Checks whether a handler has ever been stored against an event.\n\t *\n\t * @param {String} eventName The name of the event to check.\n\t * @private\n\t * @memberOf EventEmitter\n\t */\n\telasticlunr.EventEmitter.prototype.hasHandler = function (name) {\n\t  return name in this.events;\n\t};\n\t/*!\n\t * elasticlunr.tokenizer\n\t * Copyright (C) 2016 Oliver Nightingale\n\t * Copyright (C) 2016 Wei Song\n\t */\n\t\n\t/**\n\t * A function for splitting a string into tokens.\n\t * Currently English is supported as default.\n\t * Uses `elasticlunr.tokenizer.seperator` to split strings, you could change\n\t * the value of this property to set how you want strings are split into tokens.\n\t * IMPORTANT: use elasticlunr.tokenizer.seperator carefully, if you are not familiar with\n\t * text process, then you'd better not change it.\n\t *\n\t * @module\n\t * @param {String} str The string that you want to tokenize.\n\t * @see elasticlunr.tokenizer.seperator\n\t * @return {Array}\n\t */\n\telasticlunr.tokenizer = function (str) {\n\t  if (!arguments.length || str === null || str === undefined) return [];\n\t  if (Array.isArray(str)) {\n\t    var arr = str.filter(function(token) {\n\t      if (token === null || token === undefined) {\n\t        return false;\n\t      }\n\t\n\t      return true;\n\t    });\n\t\n\t    arr = arr.map(function (t) {\n\t      return elasticlunr.utils.toString(t).toLowerCase();\n\t    });\n\t\n\t    var out = [];\n\t    arr.forEach(function(item) {\n\t      var tokens = item.split(elasticlunr.tokenizer.seperator);\n\t      out = out.concat(tokens);\n\t    }, this);\n\t\n\t    return out;\n\t  }\n\t\n\t  return str.toString().trim().toLowerCase().split(elasticlunr.tokenizer.seperator);\n\t};\n\t\n\t/**\n\t * Default string seperator.\n\t */\n\telasticlunr.tokenizer.defaultSeperator = /[\\s\\-]+/;\n\t\n\t/**\n\t * The sperator used to split a string into tokens. Override this property to change the behaviour of\n\t * `elasticlunr.tokenizer` behaviour when tokenizing strings. By default this splits on whitespace and hyphens.\n\t *\n\t * @static\n\t * @see elasticlunr.tokenizer\n\t */\n\telasticlunr.tokenizer.seperator = elasticlunr.tokenizer.defaultSeperator;\n\t\n\t/**\n\t * Set up customized string seperator\n\t *\n\t * @param {Object} sep The customized seperator that you want to use to tokenize a string.\n\t */\n\telasticlunr.tokenizer.setSeperator = function(sep) {\n\t    if (sep !== null && sep !== undefined && typeof(sep) === 'object') {\n\t        elasticlunr.tokenizer.seperator = sep;\n\t    }\n\t}\n\t\n\t/**\n\t * Reset string seperator\n\t *\n\t */\n\telasticlunr.tokenizer.resetSeperator = function() {\n\t    elasticlunr.tokenizer.seperator = elasticlunr.tokenizer.defaultSeperator;\n\t}\n\t\n\t/**\n\t * Get string seperator\n\t *\n\t */\n\telasticlunr.tokenizer.getSeperator = function() {\n\t    return elasticlunr.tokenizer.seperator;\n\t}\n\t/*!\n\t * elasticlunr.Pipeline\n\t * Copyright (C) 2016 Oliver Nightingale\n\t * Copyright (C) 2016 Wei Song\n\t */\n\t\n\t/**\n\t * elasticlunr.Pipelines maintain an ordered list of functions to be applied to \n\t * both documents tokens and query tokens.\n\t *\n\t * An instance of elasticlunr.Index will contain a pipeline\n\t * with a trimmer, a stop word filter, an English stemmer. Extra\n\t * functions can be added before or after either of these functions or these\n\t * default functions can be removed.\n\t *\n\t * When run the pipeline, it will call each function in turn.\n\t *\n\t * The output of the functions in the pipeline will be passed to the next function\n\t * in the pipeline. To exclude a token from entering the index the function\n\t * should return undefined, the rest of the pipeline will not be called with\n\t * this token.\n\t *\n\t * For serialisation of pipelines to work, all functions used in an instance of\n\t * a pipeline should be registered with elasticlunr.Pipeline. Registered functions can\n\t * then be loaded. If trying to load a serialised pipeline that uses functions\n\t * that are not registered an error will be thrown.\n\t *\n\t * If not planning on serialising the pipeline then registering pipeline functions\n\t * is not necessary.\n\t *\n\t * @constructor\n\t */\n\telasticlunr.Pipeline = function () {\n\t  this._queue = [];\n\t};\n\t\n\telasticlunr.Pipeline.registeredFunctions = {};\n\t\n\t/**\n\t * Register a function in the pipeline.\n\t *\n\t * Functions that are used in the pipeline should be registered if the pipeline\n\t * needs to be serialised, or a serialised pipeline needs to be loaded.\n\t *\n\t * Registering a function does not add it to a pipeline, functions must still be\n\t * added to instances of the pipeline for them to be used when running a pipeline.\n\t *\n\t * @param {Function} fn The function to register.\n\t * @param {String} label The label to register this function with\n\t * @memberOf Pipeline\n\t */\n\telasticlunr.Pipeline.registerFunction = function (fn, label) {\n\t  if (label in elasticlunr.Pipeline.registeredFunctions) {\n\t    elasticlunr.utils.warn('Overwriting existing registered function: ' + label);\n\t  }\n\t\n\t  fn.label = label;\n\t  elasticlunr.Pipeline.registeredFunctions[label] = fn;\n\t};\n\t\n\t/**\n\t * Get a registered function in the pipeline.\n\t *\n\t * @param {String} label The label of registered function.\n\t * @return {Function}\n\t * @memberOf Pipeline\n\t */\n\telasticlunr.Pipeline.getRegisteredFunction = function (label) {\n\t  if ((label in elasticlunr.Pipeline.registeredFunctions) !== true) {\n\t    return null;\n\t  }\n\t\n\t  return elasticlunr.Pipeline.registeredFunctions[label];\n\t};\n\t\n\t/**\n\t * Warns if the function is not registered as a Pipeline function.\n\t *\n\t * @param {Function} fn The function to check for.\n\t * @private\n\t * @memberOf Pipeline\n\t */\n\telasticlunr.Pipeline.warnIfFunctionNotRegistered = function (fn) {\n\t  var isRegistered = fn.label && (fn.label in this.registeredFunctions);\n\t\n\t  if (!isRegistered) {\n\t    elasticlunr.utils.warn('Function is not registered with pipeline. This may cause problems when serialising the index.\\n', fn);\n\t  }\n\t};\n\t\n\t/**\n\t * Loads a previously serialised pipeline.\n\t *\n\t * All functions to be loaded must already be registered with elasticlunr.Pipeline.\n\t * If any function from the serialised data has not been registered then an\n\t * error will be thrown.\n\t *\n\t * @param {Object} serialised The serialised pipeline to load.\n\t * @return {elasticlunr.Pipeline}\n\t * @memberOf Pipeline\n\t */\n\telasticlunr.Pipeline.load = function (serialised) {\n\t  var pipeline = new elasticlunr.Pipeline;\n\t\n\t  serialised.forEach(function (fnName) {\n\t    var fn = elasticlunr.Pipeline.getRegisteredFunction(fnName);\n\t\n\t    if (fn) {\n\t      pipeline.add(fn);\n\t    } else {\n\t      throw new Error('Cannot load un-registered function: ' + fnName);\n\t    }\n\t  });\n\t\n\t  return pipeline;\n\t};\n\t\n\t/**\n\t * Adds new functions to the end of the pipeline.\n\t *\n\t * Logs a warning if the function has not been registered.\n\t *\n\t * @param {Function} functions Any number of functions to add to the pipeline.\n\t * @memberOf Pipeline\n\t */\n\telasticlunr.Pipeline.prototype.add = function () {\n\t  var fns = Array.prototype.slice.call(arguments);\n\t\n\t  fns.forEach(function (fn) {\n\t    elasticlunr.Pipeline.warnIfFunctionNotRegistered(fn);\n\t    this._queue.push(fn);\n\t  }, this);\n\t};\n\t\n\t/**\n\t * Adds a single function after a function that already exists in the\n\t * pipeline.\n\t *\n\t * Logs a warning if the function has not been registered.\n\t * If existingFn is not found, throw an Exception.\n\t *\n\t * @param {Function} existingFn A function that already exists in the pipeline.\n\t * @param {Function} newFn The new function to add to the pipeline.\n\t * @memberOf Pipeline\n\t */\n\telasticlunr.Pipeline.prototype.after = function (existingFn, newFn) {\n\t  elasticlunr.Pipeline.warnIfFunctionNotRegistered(newFn);\n\t\n\t  var pos = this._queue.indexOf(existingFn);\n\t  if (pos === -1) {\n\t    throw new Error('Cannot find existingFn');\n\t  }\n\t\n\t  this._queue.splice(pos + 1, 0, newFn);\n\t};\n\t\n\t/**\n\t * Adds a single function before a function that already exists in the\n\t * pipeline.\n\t *\n\t * Logs a warning if the function has not been registered.\n\t * If existingFn is not found, throw an Exception.\n\t *\n\t * @param {Function} existingFn A function that already exists in the pipeline.\n\t * @param {Function} newFn The new function to add to the pipeline.\n\t * @memberOf Pipeline\n\t */\n\telasticlunr.Pipeline.prototype.before = function (existingFn, newFn) {\n\t  elasticlunr.Pipeline.warnIfFunctionNotRegistered(newFn);\n\t\n\t  var pos = this._queue.indexOf(existingFn);\n\t  if (pos === -1) {\n\t    throw new Error('Cannot find existingFn');\n\t  }\n\t\n\t  this._queue.splice(pos, 0, newFn);\n\t};\n\t\n\t/**\n\t * Removes a function from the pipeline.\n\t *\n\t * @param {Function} fn The function to remove from the pipeline.\n\t * @memberOf Pipeline\n\t */\n\telasticlunr.Pipeline.prototype.remove = function (fn) {\n\t  var pos = this._queue.indexOf(fn);\n\t  if (pos === -1) {\n\t    return;\n\t  }\n\t\n\t  this._queue.splice(pos, 1);\n\t};\n\t\n\t/**\n\t * Runs the current list of functions that registered in the pipeline against the\n\t * input tokens.\n\t *\n\t * @param {Array} tokens The tokens to run through the pipeline.\n\t * @return {Array}\n\t * @memberOf Pipeline\n\t */\n\telasticlunr.Pipeline.prototype.run = function (tokens) {\n\t  var out = [],\n\t      tokenLength = tokens.length,\n\t      pipelineLength = this._queue.length;\n\t\n\t  for (var i = 0; i < tokenLength; i++) {\n\t    var token = tokens[i];\n\t\n\t    for (var j = 0; j < pipelineLength; j++) {\n\t      token = this._queue[j](token, i, tokens);\n\t      if (token === void 0 || token === null) break;\n\t    };\n\t\n\t    if (token !== void 0 && token !== null) out.push(token);\n\t  };\n\t\n\t  return out;\n\t};\n\t\n\t/**\n\t * Resets the pipeline by removing any existing processors.\n\t *\n\t * @memberOf Pipeline\n\t */\n\telasticlunr.Pipeline.prototype.reset = function () {\n\t  this._queue = [];\n\t};\n\t\n\t /**\n\t  * Get the pipeline if user want to check the pipeline.\n\t  *\n\t  * @memberOf Pipeline\n\t  */\n\t elasticlunr.Pipeline.prototype.get = function () {\n\t   return this._queue;\n\t };\n\t\n\t/**\n\t * Returns a representation of the pipeline ready for serialisation.\n\t * Only serialize pipeline function's name. Not storing function, so when\n\t * loading the archived JSON index file, corresponding pipeline function is \n\t * added by registered function of elasticlunr.Pipeline.registeredFunctions\n\t *\n\t * Logs a warning if the function has not been registered.\n\t *\n\t * @return {Array}\n\t * @memberOf Pipeline\n\t */\n\telasticlunr.Pipeline.prototype.toJSON = function () {\n\t  return this._queue.map(function (fn) {\n\t    elasticlunr.Pipeline.warnIfFunctionNotRegistered(fn);\n\t    return fn.label;\n\t  });\n\t};\n\t/*!\n\t * elasticlunr.Index\n\t * Copyright (C) 2016 Oliver Nightingale\n\t * Copyright (C) 2016 Wei Song\n\t */\n\t\n\t/**\n\t * elasticlunr.Index is object that manages a search index.  It contains the indexes\n\t * and stores all the tokens and document lookups.  It also provides the main\n\t * user facing API for the library.\n\t *\n\t * @constructor\n\t */\n\telasticlunr.Index = function () {\n\t  this._fields = [];\n\t  this._ref = 'id';\n\t  this.pipeline = new elasticlunr.Pipeline;\n\t  this.documentStore = new elasticlunr.DocumentStore;\n\t  this.index = {};\n\t  this.eventEmitter = new elasticlunr.EventEmitter;\n\t  this._idfCache = {};\n\t\n\t  this.on('add', 'remove', 'update', (function () {\n\t    this._idfCache = {};\n\t  }).bind(this));\n\t};\n\t\n\t/**\n\t * Bind a handler to events being emitted by the index.\n\t *\n\t * The handler can be bound to many events at the same time.\n\t *\n\t * @param {String} [eventName] The name(s) of events to bind the function to.\n\t * @param {Function} fn The serialised set to load.\n\t * @memberOf Index\n\t */\n\telasticlunr.Index.prototype.on = function () {\n\t  var args = Array.prototype.slice.call(arguments);\n\t  return this.eventEmitter.addListener.apply(this.eventEmitter, args);\n\t};\n\t\n\t/**\n\t * Removes a handler from an event being emitted by the index.\n\t *\n\t * @param {String} eventName The name of events to remove the function from.\n\t * @param {Function} fn The serialised set to load.\n\t * @memberOf Index\n\t */\n\telasticlunr.Index.prototype.off = function (name, fn) {\n\t  return this.eventEmitter.removeListener(name, fn);\n\t};\n\t\n\t/**\n\t * Loads a previously serialised index.\n\t *\n\t * Issues a warning if the index being imported was serialised\n\t * by a different version of elasticlunr.\n\t *\n\t * @param {Object} serialisedData The serialised set to load.\n\t * @return {elasticlunr.Index}\n\t * @memberOf Index\n\t */\n\telasticlunr.Index.load = function (serialisedData) {\n\t  if (serialisedData.version !== elasticlunr.version) {\n\t    elasticlunr.utils.warn('version mismatch: current '\n\t                    + elasticlunr.version + ' importing ' + serialisedData.version);\n\t  }\n\t\n\t  var idx = new this;\n\t\n\t  idx._fields = serialisedData.fields;\n\t  idx._ref = serialisedData.ref;\n\t  idx.documentStore = elasticlunr.DocumentStore.load(serialisedData.documentStore);\n\t  idx.pipeline = elasticlunr.Pipeline.load(serialisedData.pipeline);\n\t  idx.index = {};\n\t  for (var field in serialisedData.index) {\n\t    idx.index[field] = elasticlunr.InvertedIndex.load(serialisedData.index[field]);\n\t  }\n\t\n\t  return idx;\n\t};\n\t\n\t/**\n\t * Adds a field to the list of fields that will be searchable within documents in the index.\n\t *\n\t * Remember that inner index is build based on field, which means each field has one inverted index.\n\t *\n\t * Fields should be added before any documents are added to the index, fields\n\t * that are added after documents are added to the index will only apply to new\n\t * documents added to the index.\n\t *\n\t * @param {String} fieldName The name of the field within the document that should be indexed\n\t * @return {elasticlunr.Index}\n\t * @memberOf Index\n\t */\n\telasticlunr.Index.prototype.addField = function (fieldName) {\n\t  this._fields.push(fieldName);\n\t  this.index[fieldName] = new elasticlunr.InvertedIndex;\n\t  return this;\n\t};\n\t\n\t/**\n\t * Sets the property used to uniquely identify documents added to the index,\n\t * by default this property is 'id'.\n\t *\n\t * This should only be changed before adding documents to the index, changing\n\t * the ref property without resetting the index can lead to unexpected results.\n\t *\n\t * @param {String} refName The property to use to uniquely identify the\n\t * documents in the index.\n\t * @param {Boolean} emitEvent Whether to emit add events, defaults to true\n\t * @return {elasticlunr.Index}\n\t * @memberOf Index\n\t */\n\telasticlunr.Index.prototype.setRef = function (refName) {\n\t  this._ref = refName;\n\t  return this;\n\t};\n\t\n\t/**\n\t *\n\t * Set if the JSON format original documents are save into elasticlunr.DocumentStore\n\t *\n\t * Defaultly save all the original JSON documents.\n\t *\n\t * @param {Boolean} save Whether to save the original JSON documents.\n\t * @return {elasticlunr.Index}\n\t * @memberOf Index\n\t */\n\telasticlunr.Index.prototype.saveDocument = function (save) {\n\t  this.documentStore = new elasticlunr.DocumentStore(save);\n\t  return this;\n\t};\n\t\n\t/**\n\t * Add a JSON format document to the index.\n\t *\n\t * This is the way new documents enter the index, this function will run the\n\t * fields from the document through the index's pipeline and then add it to\n\t * the index, it will then show up in search results.\n\t *\n\t * An 'add' event is emitted with the document that has been added and the index\n\t * the document has been added to. This event can be silenced by passing false\n\t * as the second argument to add.\n\t *\n\t * @param {Object} doc The JSON format document to add to the index.\n\t * @param {Boolean} emitEvent Whether or not to emit events, default true.\n\t * @memberOf Index\n\t */\n\telasticlunr.Index.prototype.addDoc = function (doc, emitEvent) {\n\t  if (!doc) return;\n\t  var emitEvent = emitEvent === undefined ? true : emitEvent;\n\t\n\t  var docRef = doc[this._ref];\n\t\n\t  this.documentStore.addDoc(docRef, doc);\n\t  this._fields.forEach(function (field) {\n\t    var fieldTokens = this.pipeline.run(elasticlunr.tokenizer(doc[field]));\n\t    this.documentStore.addFieldLength(docRef, field, fieldTokens.length);\n\t\n\t    var tokenCount = {};\n\t    fieldTokens.forEach(function (token) {\n\t      if (token in tokenCount) tokenCount[token] += 1;\n\t      else tokenCount[token] = 1;\n\t    }, this);\n\t\n\t    for (var token in tokenCount) {\n\t      var termFrequency = tokenCount[token];\n\t      termFrequency = Math.sqrt(termFrequency);\n\t      this.index[field].addToken(token, { ref: docRef, tf: termFrequency });\n\t    }\n\t  }, this);\n\t\n\t  if (emitEvent) this.eventEmitter.emit('add', doc, this);\n\t};\n\t\n\t/**\n\t * Removes a document from the index by doc ref.\n\t *\n\t * To make sure documents no longer show up in search results they can be\n\t * removed from the index using this method.\n\t *\n\t * A 'remove' event is emitted with the document that has been removed and the index\n\t * the document has been removed from. This event can be silenced by passing false\n\t * as the second argument to remove.\n\t *\n\t * If user setting DocumentStore not storing the documents, then remove doc by docRef is not allowed.\n\t *\n\t * @param {String|Integer} docRef The document ref to remove from the index.\n\t * @param {Boolean} emitEvent Whether to emit remove events, defaults to true\n\t * @memberOf Index\n\t */\n\telasticlunr.Index.prototype.removeDocByRef = function (docRef, emitEvent) {\n\t  if (!docRef) return;\n\t  if (this.documentStore.isDocStored() === false) {\n\t    return;\n\t  }\n\t\n\t  if (!this.documentStore.hasDoc(docRef)) return;\n\t  var doc = this.documentStore.getDoc(docRef);\n\t  this.removeDoc(doc, false);\n\t};\n\t\n\t/**\n\t * Removes a document from the index.\n\t * This remove operation could work even the original doc is not store in the DocumentStore.\n\t *\n\t * To make sure documents no longer show up in search results they can be\n\t * removed from the index using this method.\n\t *\n\t * A 'remove' event is emitted with the document that has been removed and the index\n\t * the document has been removed from. This event can be silenced by passing false\n\t * as the second argument to remove.\n\t *\n\t *\n\t * @param {Object} doc The document ref to remove from the index.\n\t * @param {Boolean} emitEvent Whether to emit remove events, defaults to true\n\t * @memberOf Index\n\t */\n\telasticlunr.Index.prototype.removeDoc = function (doc, emitEvent) {\n\t  if (!doc) return;\n\t\n\t  var emitEvent = emitEvent === undefined ? true : emitEvent;\n\t\n\t  var docRef = doc[this._ref];\n\t  if (!this.documentStore.hasDoc(docRef)) return;\n\t\n\t  this.documentStore.removeDoc(docRef);\n\t\n\t  this._fields.forEach(function (field) {\n\t    var fieldTokens = this.pipeline.run(elasticlunr.tokenizer(doc[field]));\n\t    fieldTokens.forEach(function (token) {\n\t      this.index[field].removeToken(token, docRef);\n\t    }, this);\n\t  }, this);\n\t\n\t  if (emitEvent) this.eventEmitter.emit('remove', doc, this);\n\t};\n\t\n\t/**\n\t * Updates a document in the index.\n\t *\n\t * When a document contained within the index gets updated, fields changed,\n\t * added or removed, to make sure it correctly matched against search queries,\n\t * it should be updated in the index.\n\t *\n\t * This method is just a wrapper around `remove` and `add`\n\t *\n\t * An 'update' event is emitted with the document that has been updated and the index.\n\t * This event can be silenced by passing false as the second argument to update. Only\n\t * an update event will be fired, the 'add' and 'remove' events of the underlying calls\n\t * are silenced.\n\t *\n\t * @param {Object} doc The document to update in the index.\n\t * @param {Boolean} emitEvent Whether to emit update events, defaults to true\n\t * @see Index.prototype.remove\n\t * @see Index.prototype.add\n\t * @memberOf Index\n\t */\n\telasticlunr.Index.prototype.updateDoc = function (doc, emitEvent) {\n\t  var emitEvent = emitEvent === undefined ? true : emitEvent;\n\t\n\t  this.removeDocByRef(doc[this._ref], false);\n\t  this.addDoc(doc, false);\n\t\n\t  if (emitEvent) this.eventEmitter.emit('update', doc, this);\n\t};\n\t\n\t/**\n\t * Calculates the inverse document frequency for a token within the index of a field.\n\t *\n\t * @param {String} token The token to calculate the idf of.\n\t * @param {String} field The field to compute idf.\n\t * @see Index.prototype.idf\n\t * @private\n\t * @memberOf Index\n\t */\n\telasticlunr.Index.prototype.idf = function (term, field) {\n\t  var cacheKey = \"@\" + field + '/' + term;\n\t  if (Object.prototype.hasOwnProperty.call(this._idfCache, cacheKey)) return this._idfCache[cacheKey];\n\t\n\t  var df = this.index[field].getDocFreq(term);\n\t  var idf = 1 + Math.log(this.documentStore.length / (df + 1));\n\t  this._idfCache[cacheKey] = idf;\n\t\n\t  return idf;\n\t};\n\t\n\t/**\n\t * get fields of current index instance\n\t *\n\t * @return {Array}\n\t */\n\telasticlunr.Index.prototype.getFields = function () {\n\t  return this._fields.slice();\n\t};\n\t\n\t/**\n\t * Searches the index using the passed query.\n\t * Queries should be a string, multiple words are allowed.\n\t *\n\t * If config is null, will search all fields defaultly, and lead to OR based query.\n\t * If config is specified, will search specified with query time boosting.\n\t *\n\t * All query tokens are passed through the same pipeline that document tokens\n\t * are passed through, so any language processing involved will be run on every\n\t * query term.\n\t *\n\t * Each query term is expanded, so that the term 'he' might be expanded to\n\t * 'hello' and 'help' if those terms were already included in the index.\n\t *\n\t * Matching documents are returned as an array of objects, each object contains\n\t * the matching document ref, as set for this index, and the similarity score\n\t * for this document against the query.\n\t *\n\t * @param {String} query The query to search the index with.\n\t * @param {JSON} userConfig The user query config, JSON format.\n\t * @return {Object}\n\t * @see Index.prototype.idf\n\t * @see Index.prototype.documentVector\n\t * @memberOf Index\n\t */\n\telasticlunr.Index.prototype.search = function (query, userConfig) {\n\t  if (!query) return [];\n\t\n\t  var configStr = null;\n\t  if (userConfig != null) {\n\t    configStr = JSON.stringify(userConfig);\n\t  }\n\t\n\t  var config = new elasticlunr.Configuration(configStr, this.getFields()).get();\n\t\n\t  var queryTokens = this.pipeline.run(elasticlunr.tokenizer(query));\n\t\n\t  var queryResults = {};\n\t\n\t  for (var field in config) {\n\t    var fieldSearchResults = this.fieldSearch(queryTokens, field, config);\n\t    var fieldBoost = config[field].boost;\n\t\n\t    for (var docRef in fieldSearchResults) {\n\t      fieldSearchResults[docRef] = fieldSearchResults[docRef] * fieldBoost;\n\t    }\n\t\n\t    for (var docRef in fieldSearchResults) {\n\t      if (docRef in queryResults) {\n\t        queryResults[docRef] += fieldSearchResults[docRef];\n\t      } else {\n\t        queryResults[docRef] = fieldSearchResults[docRef];\n\t      }\n\t    }\n\t  }\n\t\n\t  var results = [];\n\t  for (var docRef in queryResults) {\n\t    results.push({ref: docRef, score: queryResults[docRef]});\n\t  }\n\t\n\t  results.sort(function (a, b) { return b.score - a.score; });\n\t  return results;\n\t};\n\t\n\t/**\n\t * search queryTokens in specified field.\n\t *\n\t * @param {Array} queryTokens The query tokens to query in this field.\n\t * @param {String} field Field to query in.\n\t * @param {elasticlunr.Configuration} config The user query config, JSON format.\n\t * @return {Object}\n\t */\n\telasticlunr.Index.prototype.fieldSearch = function (queryTokens, fieldName, config) {\n\t  var booleanType = config[fieldName].bool;\n\t  var expand = config[fieldName].expand;\n\t  var boost = config[fieldName].boost;\n\t  var scores = null;\n\t  var docTokens = {};\n\t\n\t  // Do nothing if the boost is 0\n\t  if (boost === 0) {\n\t    return;\n\t  }\n\t\n\t  queryTokens.forEach(function (token) {\n\t    var tokens = [token];\n\t    if (expand == true) {\n\t      tokens = this.index[fieldName].expandToken(token);\n\t    }\n\t    // Consider every query token in turn. If expanded, each query token\n\t    // corresponds to a set of tokens, which is all tokens in the \n\t    // index matching the pattern queryToken* .\n\t    // For the set of tokens corresponding to a query token, find and score\n\t    // all matching documents. Store those scores in queryTokenScores, \n\t    // keyed by docRef.\n\t    // Then, depending on the value of booleanType, combine the scores\n\t    // for this query token with previous scores.  If booleanType is OR,\n\t    // then merge the scores by summing into the accumulated total, adding\n\t    // new document scores are required (effectively a union operator). \n\t    // If booleanType is AND, accumulate scores only if the document \n\t    // has previously been scored by another query token (an intersection\n\t    // operation0. \n\t    // Furthermore, since when booleanType is AND, additional \n\t    // query tokens can't add new documents to the result set, use the\n\t    // current document set to limit the processing of each new query \n\t    // token for efficiency (i.e., incremental intersection).\n\t    \n\t    var queryTokenScores = {};\n\t    tokens.forEach(function (key) {\n\t      var docs = this.index[fieldName].getDocs(key);\n\t      var idf = this.idf(key, fieldName);\n\t      \n\t      if (scores && booleanType == 'AND') {\n\t          // special case, we can rule out documents that have been\n\t          // already been filtered out because they weren't scored\n\t          // by previous query token passes.\n\t          var filteredDocs = {};\n\t          for (var docRef in scores) {\n\t              if (docRef in docs) {\n\t                  filteredDocs[docRef] = docs[docRef];\n\t              }\n\t          }\n\t          docs = filteredDocs;\n\t      }\n\t      // only record appeared token for retrieved documents for the\n\t      // original token, not for expaned token.\n\t      // beause for doing coordNorm for a retrieved document, coordNorm only care how many\n\t      // query token appear in that document.\n\t      // so expanded token should not be added into docTokens, if added, this will pollute the\n\t      // coordNorm\n\t      if (key == token) {\n\t        this.fieldSearchStats(docTokens, key, docs);\n\t      }\n\t\n\t      for (var docRef in docs) {\n\t        var tf = this.index[fieldName].getTermFrequency(key, docRef);\n\t        var fieldLength = this.documentStore.getFieldLength(docRef, fieldName);\n\t        var fieldLengthNorm = 1;\n\t        if (fieldLength != 0) {\n\t          fieldLengthNorm = 1 / Math.sqrt(fieldLength);\n\t        }\n\t\n\t        var penality = 1;\n\t        if (key != token) {\n\t          // currently I'm not sure if this penality is enough,\n\t          // need to do verification\n\t          penality = (1 - (key.length - token.length) / key.length) * 0.15;\n\t        }\n\t\n\t        var score = tf * idf * fieldLengthNorm * penality;\n\t\n\t        if (docRef in queryTokenScores) {\n\t          queryTokenScores[docRef] += score;\n\t        } else {\n\t          queryTokenScores[docRef] = score;\n\t        }\n\t      }\n\t    }, this);\n\t    \n\t    scores = this.mergeScores(scores, queryTokenScores, booleanType);\n\t  }, this);\n\t\n\t  scores = this.coordNorm(scores, docTokens, queryTokens.length);\n\t  return scores;\n\t};\n\t\n\t/**\n\t * Merge the scores from one set of tokens into an accumulated score table.\n\t * Exact operation depends on the op parameter. If op is 'AND', then only the\n\t * intersection of the two score lists is retained. Otherwise, the union of\n\t * the two score lists is returned. For internal use only.\n\t *\n\t * @param {Object} bool accumulated scores. Should be null on first call.\n\t * @param {String} scores new scores to merge into accumScores.\n\t * @param {Object} op merge operation (should be 'AND' or 'OR').\n\t *\n\t */\n\t\n\telasticlunr.Index.prototype.mergeScores = function (accumScores, scores, op) {\n\t    if (!accumScores) {\n\t        return scores; \n\t    }\n\t    if (op == 'AND') {\n\t        var intersection = {};\n\t        for (var docRef in scores) {\n\t            if (docRef in accumScores) {\n\t                intersection[docRef] = accumScores[docRef] + scores[docRef];\n\t            }\n\t        }\n\t        return intersection;\n\t    } else {\n\t        for (var docRef in scores) {\n\t            if (docRef in accumScores) {\n\t                accumScores[docRef] += scores[docRef];\n\t            } else {\n\t                accumScores[docRef] = scores[docRef];\n\t            }\n\t        }\n\t        return accumScores;\n\t    }\n\t};\n\t\n\t\n\t/**\n\t * Record the occuring query token of retrieved doc specified by doc field.\n\t * Only for inner user.\n\t *\n\t * @param {Object} docTokens a data structure stores which token appears in the retrieved doc.\n\t * @param {String} token query token\n\t * @param {Object} docs the retrieved documents of the query token\n\t *\n\t */\n\telasticlunr.Index.prototype.fieldSearchStats = function (docTokens, token, docs) {\n\t  for (var doc in docs) {\n\t    if (doc in docTokens) {\n\t      docTokens[doc].push(token);\n\t    } else {\n\t      docTokens[doc] = [token];\n\t    }\n\t  }\n\t};\n\t\n\t/**\n\t * coord norm the score of a doc.\n\t * if a doc contain more query tokens, then the score will larger than the doc\n\t * contains less query tokens.\n\t *\n\t * only for inner use.\n\t *\n\t * @param {Object} results first results\n\t * @param {Object} docs field search results of a token\n\t * @param {Integer} n query token number\n\t * @return {Object}\n\t */\n\telasticlunr.Index.prototype.coordNorm = function (scores, docTokens, n) {\n\t  for (var doc in scores) {\n\t    if (!(doc in docTokens)) continue;\n\t    var tokens = docTokens[doc].length;\n\t    scores[doc] = scores[doc] * tokens / n;\n\t  }\n\t\n\t  return scores;\n\t};\n\t\n\t/**\n\t * Returns a representation of the index ready for serialisation.\n\t *\n\t * @return {Object}\n\t * @memberOf Index\n\t */\n\telasticlunr.Index.prototype.toJSON = function () {\n\t  var indexJson = {};\n\t  this._fields.forEach(function (field) {\n\t    indexJson[field] = this.index[field].toJSON();\n\t  }, this);\n\t\n\t  return {\n\t    version: elasticlunr.version,\n\t    fields: this._fields,\n\t    ref: this._ref,\n\t    documentStore: this.documentStore.toJSON(),\n\t    index: indexJson,\n\t    pipeline: this.pipeline.toJSON()\n\t  };\n\t};\n\t\n\t/**\n\t * Applies a plugin to the current index.\n\t *\n\t * A plugin is a function that is called with the index as its context.\n\t * Plugins can be used to customise or extend the behaviour the index\n\t * in some way. A plugin is just a function, that encapsulated the custom\n\t * behaviour that should be applied to the index.\n\t *\n\t * The plugin function will be called with the index as its argument, additional\n\t * arguments can also be passed when calling use. The function will be called\n\t * with the index as its context.\n\t *\n\t * Example:\n\t *\n\t *     var myPlugin = function (idx, arg1, arg2) {\n\t *       // `this` is the index to be extended\n\t *       // apply any extensions etc here.\n\t *     }\n\t *\n\t *     var idx = elasticlunr(function () {\n\t *       this.use(myPlugin, 'arg1', 'arg2')\n\t *     })\n\t *\n\t * @param {Function} plugin The plugin to apply.\n\t * @memberOf Index\n\t */\n\telasticlunr.Index.prototype.use = function (plugin) {\n\t  var args = Array.prototype.slice.call(arguments, 1);\n\t  args.unshift(this);\n\t  plugin.apply(this, args);\n\t};\n\t/*!\n\t * elasticlunr.DocumentStore\n\t * Copyright (C) 2016 Wei Song\n\t */\n\t\n\t/**\n\t * elasticlunr.DocumentStore is a simple key-value document store used for storing sets of tokens for\n\t * documents stored in index.\n\t *\n\t * elasticlunr.DocumentStore store original JSON format documents that you could build search snippet by this original JSON document.\n\t *\n\t * user could choose whether original JSON format document should be store, if no configuration then document will be stored defaultly.\n\t * If user care more about the index size, user could select not store JSON documents, then this will has some defects, such as user\n\t * could not use JSON document to generate snippets of search results.\n\t *\n\t * @param {Boolean} save If the original JSON document should be stored.\n\t * @constructor\n\t * @module\n\t */\n\telasticlunr.DocumentStore = function (save) {\n\t  if (save === null || save === undefined) {\n\t    this._save = true;\n\t  } else {\n\t    this._save = save;\n\t  }\n\t\n\t  this.docs = {};\n\t  this.docInfo = {};\n\t  this.length = 0;\n\t};\n\t\n\t/**\n\t * Loads a previously serialised document store\n\t *\n\t * @param {Object} serialisedData The serialised document store to load.\n\t * @return {elasticlunr.DocumentStore}\n\t */\n\telasticlunr.DocumentStore.load = function (serialisedData) {\n\t  var store = new this;\n\t\n\t  store.length = serialisedData.length;\n\t  store.docs = serialisedData.docs;\n\t  store.docInfo = serialisedData.docInfo;\n\t  store._save = serialisedData.save;\n\t\n\t  return store;\n\t};\n\t\n\t/**\n\t * check if current instance store the original doc\n\t *\n\t * @return {Boolean}\n\t */\n\telasticlunr.DocumentStore.prototype.isDocStored = function () {\n\t  return this._save;\n\t};\n\t\n\t/**\n\t * Stores the given doc in the document store against the given id.\n\t * If docRef already exist, then update doc.\n\t *\n\t * Document is store by original JSON format, then you could use original document to generate search snippets.\n\t *\n\t * @param {Integer|String} docRef The key used to store the JSON format doc.\n\t * @param {Object} doc The JSON format doc.\n\t */\n\telasticlunr.DocumentStore.prototype.addDoc = function (docRef, doc) {\n\t  if (!this.hasDoc(docRef)) this.length++;\n\t\n\t  if (this._save === true) {\n\t    this.docs[docRef] = clone(doc);\n\t  } else {\n\t    this.docs[docRef] = null;\n\t  }\n\t};\n\t\n\t/**\n\t * Retrieves the JSON doc from the document store for a given key.\n\t *\n\t * If docRef not found, return null.\n\t * If user set not storing the documents, return null.\n\t *\n\t * @param {Integer|String} docRef The key to lookup and retrieve from the document store.\n\t * @return {Object}\n\t * @memberOf DocumentStore\n\t */\n\telasticlunr.DocumentStore.prototype.getDoc = function (docRef) {\n\t  if (this.hasDoc(docRef) === false) return null;\n\t  return this.docs[docRef];\n\t};\n\t\n\t/**\n\t * Checks whether the document store contains a key (docRef).\n\t *\n\t * @param {Integer|String} docRef The id to look up in the document store.\n\t * @return {Boolean}\n\t * @memberOf DocumentStore\n\t */\n\telasticlunr.DocumentStore.prototype.hasDoc = function (docRef) {\n\t  return docRef in this.docs;\n\t};\n\t\n\t/**\n\t * Removes the value for a key in the document store.\n\t *\n\t * @param {Integer|String} docRef The id to remove from the document store.\n\t * @memberOf DocumentStore\n\t */\n\telasticlunr.DocumentStore.prototype.removeDoc = function (docRef) {\n\t  if (!this.hasDoc(docRef)) return;\n\t\n\t  delete this.docs[docRef];\n\t  delete this.docInfo[docRef];\n\t  this.length--;\n\t};\n\t\n\t/**\n\t * Add field length of a document's field tokens from pipeline results.\n\t * The field length of a document is used to do field length normalization even without the original JSON document stored.\n\t *\n\t * @param {Integer|String} docRef document's id or reference\n\t * @param {String} fieldName field name\n\t * @param {Integer} length field length\n\t */\n\telasticlunr.DocumentStore.prototype.addFieldLength = function (docRef, fieldName, length) {\n\t  if (docRef === null || docRef === undefined) return;\n\t  if (this.hasDoc(docRef) == false) return;\n\t\n\t  if (!this.docInfo[docRef]) this.docInfo[docRef] = {};\n\t  this.docInfo[docRef][fieldName] = length;\n\t};\n\t\n\t/**\n\t * Update field length of a document's field tokens from pipeline results.\n\t * The field length of a document is used to do field length normalization even without the original JSON document stored.\n\t *\n\t * @param {Integer|String} docRef document's id or reference\n\t * @param {String} fieldName field name\n\t * @param {Integer} length field length\n\t */\n\telasticlunr.DocumentStore.prototype.updateFieldLength = function (docRef, fieldName, length) {\n\t  if (docRef === null || docRef === undefined) return;\n\t  if (this.hasDoc(docRef) == false) return;\n\t\n\t  this.addFieldLength(docRef, fieldName, length);\n\t};\n\t\n\t/**\n\t * get field length of a document by docRef\n\t *\n\t * @param {Integer|String} docRef document id or reference\n\t * @param {String} fieldName field name\n\t * @return {Integer} field length\n\t */\n\telasticlunr.DocumentStore.prototype.getFieldLength = function (docRef, fieldName) {\n\t  if (docRef === null || docRef === undefined) return 0;\n\t\n\t  if (!(docRef in this.docs)) return 0;\n\t  if (!(fieldName in this.docInfo[docRef])) return 0;\n\t  return this.docInfo[docRef][fieldName];\n\t};\n\t\n\t/**\n\t * Returns a JSON representation of the document store used for serialisation.\n\t *\n\t * @return {Object} JSON format\n\t * @memberOf DocumentStore\n\t */\n\telasticlunr.DocumentStore.prototype.toJSON = function () {\n\t  return {\n\t    docs: this.docs,\n\t    docInfo: this.docInfo,\n\t    length: this.length,\n\t    save: this._save\n\t  };\n\t};\n\t\n\t/**\n\t * Cloning object\n\t *\n\t * @param {Object} object in JSON format\n\t * @return {Object} copied object\n\t */\n\tfunction clone(obj) {\n\t  if (null === obj || \"object\" !== typeof obj) return obj;\n\t\n\t  var copy = obj.constructor();\n\t\n\t  for (var attr in obj) {\n\t    if (obj.hasOwnProperty(attr)) copy[attr] = obj[attr];\n\t  }\n\t\n\t  return copy;\n\t}\n\t/*!\n\t * elasticlunr.stemmer\n\t * Copyright (C) 2016 Oliver Nightingale\n\t * Copyright (C) 2016 Wei Song\n\t * Includes code from - http://tartarus.org/~martin/PorterStemmer/js.txt\n\t */\n\t\n\t/**\n\t * elasticlunr.stemmer is an english language stemmer, this is a JavaScript\n\t * implementation of the PorterStemmer taken from http://tartarus.org/~martin\n\t *\n\t * @module\n\t * @param {String} str The string to stem\n\t * @return {String}\n\t * @see elasticlunr.Pipeline\n\t */\n\telasticlunr.stemmer = (function(){\n\t  var step2list = {\n\t      \"ational\" : \"ate\",\n\t      \"tional\" : \"tion\",\n\t      \"enci\" : \"ence\",\n\t      \"anci\" : \"ance\",\n\t      \"izer\" : \"ize\",\n\t      \"bli\" : \"ble\",\n\t      \"alli\" : \"al\",\n\t      \"entli\" : \"ent\",\n\t      \"eli\" : \"e\",\n\t      \"ousli\" : \"ous\",\n\t      \"ization\" : \"ize\",\n\t      \"ation\" : \"ate\",\n\t      \"ator\" : \"ate\",\n\t      \"alism\" : \"al\",\n\t      \"iveness\" : \"ive\",\n\t      \"fulness\" : \"ful\",\n\t      \"ousness\" : \"ous\",\n\t      \"aliti\" : \"al\",\n\t      \"iviti\" : \"ive\",\n\t      \"biliti\" : \"ble\",\n\t      \"logi\" : \"log\"\n\t    },\n\t\n\t    step3list = {\n\t      \"icate\" : \"ic\",\n\t      \"ative\" : \"\",\n\t      \"alize\" : \"al\",\n\t      \"iciti\" : \"ic\",\n\t      \"ical\" : \"ic\",\n\t      \"ful\" : \"\",\n\t      \"ness\" : \"\"\n\t    },\n\t\n\t    c = \"[^aeiou]\",          // consonant\n\t    v = \"[aeiouy]\",          // vowel\n\t    C = c + \"[^aeiouy]*\",    // consonant sequence\n\t    V = v + \"[aeiou]*\",      // vowel sequence\n\t\n\t    mgr0 = \"^(\" + C + \")?\" + V + C,               // [C]VC... is m>0\n\t    meq1 = \"^(\" + C + \")?\" + V + C + \"(\" + V + \")?$\",  // [C]VC[V] is m=1\n\t    mgr1 = \"^(\" + C + \")?\" + V + C + V + C,       // [C]VCVC... is m>1\n\t    s_v = \"^(\" + C + \")?\" + v;                   // vowel in stem\n\t\n\t  var re_mgr0 = new RegExp(mgr0);\n\t  var re_mgr1 = new RegExp(mgr1);\n\t  var re_meq1 = new RegExp(meq1);\n\t  var re_s_v = new RegExp(s_v);\n\t\n\t  var re_1a = /^(.+?)(ss|i)es$/;\n\t  var re2_1a = /^(.+?)([^s])s$/;\n\t  var re_1b = /^(.+?)eed$/;\n\t  var re2_1b = /^(.+?)(ed|ing)$/;\n\t  var re_1b_2 = /.$/;\n\t  var re2_1b_2 = /(at|bl|iz)$/;\n\t  var re3_1b_2 = new RegExp(\"([^aeiouylsz])\\\\1$\");\n\t  var re4_1b_2 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n\t\n\t  var re_1c = /^(.+?[^aeiou])y$/;\n\t  var re_2 = /^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/;\n\t\n\t  var re_3 = /^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/;\n\t\n\t  var re_4 = /^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/;\n\t  var re2_4 = /^(.+?)(s|t)(ion)$/;\n\t\n\t  var re_5 = /^(.+?)e$/;\n\t  var re_5_1 = /ll$/;\n\t  var re3_5 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n\t\n\t  var porterStemmer = function porterStemmer(w) {\n\t    var   stem,\n\t      suffix,\n\t      firstch,\n\t      re,\n\t      re2,\n\t      re3,\n\t      re4;\n\t\n\t    if (w.length < 3) { return w; }\n\t\n\t    firstch = w.substr(0,1);\n\t    if (firstch == \"y\") {\n\t      w = firstch.toUpperCase() + w.substr(1);\n\t    }\n\t\n\t    // Step 1a\n\t    re = re_1a\n\t    re2 = re2_1a;\n\t\n\t    if (re.test(w)) { w = w.replace(re,\"$1$2\"); }\n\t    else if (re2.test(w)) { w = w.replace(re2,\"$1$2\"); }\n\t\n\t    // Step 1b\n\t    re = re_1b;\n\t    re2 = re2_1b;\n\t    if (re.test(w)) {\n\t      var fp = re.exec(w);\n\t      re = re_mgr0;\n\t      if (re.test(fp[1])) {\n\t        re = re_1b_2;\n\t        w = w.replace(re,\"\");\n\t      }\n\t    } else if (re2.test(w)) {\n\t      var fp = re2.exec(w);\n\t      stem = fp[1];\n\t      re2 = re_s_v;\n\t      if (re2.test(stem)) {\n\t        w = stem;\n\t        re2 = re2_1b_2;\n\t        re3 = re3_1b_2;\n\t        re4 = re4_1b_2;\n\t        if (re2.test(w)) {  w = w + \"e\"; }\n\t        else if (re3.test(w)) { re = re_1b_2; w = w.replace(re,\"\"); }\n\t        else if (re4.test(w)) { w = w + \"e\"; }\n\t      }\n\t    }\n\t\n\t    // Step 1c - replace suffix y or Y by i if preceded by a non-vowel which is not the first letter of the word (so cry -> cri, by -> by, say -> say)\n\t    re = re_1c;\n\t    if (re.test(w)) {\n\t      var fp = re.exec(w);\n\t      stem = fp[1];\n\t      w = stem + \"i\";\n\t    }\n\t\n\t    // Step 2\n\t    re = re_2;\n\t    if (re.test(w)) {\n\t      var fp = re.exec(w);\n\t      stem = fp[1];\n\t      suffix = fp[2];\n\t      re = re_mgr0;\n\t      if (re.test(stem)) {\n\t        w = stem + step2list[suffix];\n\t      }\n\t    }\n\t\n\t    // Step 3\n\t    re = re_3;\n\t    if (re.test(w)) {\n\t      var fp = re.exec(w);\n\t      stem = fp[1];\n\t      suffix = fp[2];\n\t      re = re_mgr0;\n\t      if (re.test(stem)) {\n\t        w = stem + step3list[suffix];\n\t      }\n\t    }\n\t\n\t    // Step 4\n\t    re = re_4;\n\t    re2 = re2_4;\n\t    if (re.test(w)) {\n\t      var fp = re.exec(w);\n\t      stem = fp[1];\n\t      re = re_mgr1;\n\t      if (re.test(stem)) {\n\t        w = stem;\n\t      }\n\t    } else if (re2.test(w)) {\n\t      var fp = re2.exec(w);\n\t      stem = fp[1] + fp[2];\n\t      re2 = re_mgr1;\n\t      if (re2.test(stem)) {\n\t        w = stem;\n\t      }\n\t    }\n\t\n\t    // Step 5\n\t    re = re_5;\n\t    if (re.test(w)) {\n\t      var fp = re.exec(w);\n\t      stem = fp[1];\n\t      re = re_mgr1;\n\t      re2 = re_meq1;\n\t      re3 = re3_5;\n\t      if (re.test(stem) || (re2.test(stem) && !(re3.test(stem)))) {\n\t        w = stem;\n\t      }\n\t    }\n\t\n\t    re = re_5_1;\n\t    re2 = re_mgr1;\n\t    if (re.test(w) && re2.test(w)) {\n\t      re = re_1b_2;\n\t      w = w.replace(re,\"\");\n\t    }\n\t\n\t    // and turn initial Y back to y\n\t\n\t    if (firstch == \"y\") {\n\t      w = firstch.toLowerCase() + w.substr(1);\n\t    }\n\t\n\t    return w;\n\t  };\n\t\n\t  return porterStemmer;\n\t})();\n\t\n\telasticlunr.Pipeline.registerFunction(elasticlunr.stemmer, 'stemmer');\n\t/*!\n\t * elasticlunr.stopWordFilter\n\t * Copyright (C) 2016 Oliver Nightingale\n\t * Copyright (C) 2016 Wei Song\n\t */\n\t\n\t/**\n\t * elasticlunr.stopWordFilter is an English language stop words filter, any words\n\t * contained in the stop word list will not be passed through the filter.\n\t *\n\t * This is intended to be used in the Pipeline. If the token does not pass the\n\t * filter then undefined will be returned.\n\t * Currently this StopwordFilter using dictionary to do O(1) time complexity stop word filtering.\n\t *\n\t * @module\n\t * @param {String} token The token to pass through the filter\n\t * @return {String}\n\t * @see elasticlunr.Pipeline\n\t */\n\telasticlunr.stopWordFilter = function (token) {\n\t  if (token && elasticlunr.stopWordFilter.stopWords[token] !== true) {\n\t    return token;\n\t  }\n\t};\n\t\n\t/**\n\t * Remove predefined stop words\n\t * if user want to use customized stop words, user could use this function to delete\n\t * all predefined stopwords.\n\t *\n\t * @return {null}\n\t */\n\telasticlunr.clearStopWords = function () {\n\t  elasticlunr.stopWordFilter.stopWords = {};\n\t};\n\t\n\t/**\n\t * Add customized stop words\n\t * user could use this function to add customized stop words\n\t * \n\t * @params {Array} words customized stop words\n\t * @return {null}\n\t */\n\telasticlunr.addStopWords = function (words) {\n\t  if (words == null || Array.isArray(words) === false) return;\n\t\n\t  words.forEach(function (word) {\n\t    elasticlunr.stopWordFilter.stopWords[word] = true;\n\t  }, this);\n\t};\n\t\n\t/**\n\t * Reset to default stop words\n\t * user could use this function to restore default stop words\n\t *\n\t * @return {null}\n\t */\n\telasticlunr.resetStopWords = function () {\n\t  elasticlunr.stopWordFilter.stopWords = elasticlunr.defaultStopWords;\n\t};\n\t\n\telasticlunr.defaultStopWords = {\n\t  \"\": true,\n\t  \"a\": true,\n\t  \"able\": true,\n\t  \"about\": true,\n\t  \"across\": true,\n\t  \"after\": true,\n\t  \"all\": true,\n\t  \"almost\": true,\n\t  \"also\": true,\n\t  \"am\": true,\n\t  \"among\": true,\n\t  \"an\": true,\n\t  \"and\": true,\n\t  \"any\": true,\n\t  \"are\": true,\n\t  \"as\": true,\n\t  \"at\": true,\n\t  \"be\": true,\n\t  \"because\": true,\n\t  \"been\": true,\n\t  \"but\": true,\n\t  \"by\": true,\n\t  \"can\": true,\n\t  \"cannot\": true,\n\t  \"could\": true,\n\t  \"dear\": true,\n\t  \"did\": true,\n\t  \"do\": true,\n\t  \"does\": true,\n\t  \"either\": true,\n\t  \"else\": true,\n\t  \"ever\": true,\n\t  \"every\": true,\n\t  \"for\": true,\n\t  \"from\": true,\n\t  \"get\": true,\n\t  \"got\": true,\n\t  \"had\": true,\n\t  \"has\": true,\n\t  \"have\": true,\n\t  \"he\": true,\n\t  \"her\": true,\n\t  \"hers\": true,\n\t  \"him\": true,\n\t  \"his\": true,\n\t  \"how\": true,\n\t  \"however\": true,\n\t  \"i\": true,\n\t  \"if\": true,\n\t  \"in\": true,\n\t  \"into\": true,\n\t  \"is\": true,\n\t  \"it\": true,\n\t  \"its\": true,\n\t  \"just\": true,\n\t  \"least\": true,\n\t  \"let\": true,\n\t  \"like\": true,\n\t  \"likely\": true,\n\t  \"may\": true,\n\t  \"me\": true,\n\t  \"might\": true,\n\t  \"most\": true,\n\t  \"must\": true,\n\t  \"my\": true,\n\t  \"neither\": true,\n\t  \"no\": true,\n\t  \"nor\": true,\n\t  \"not\": true,\n\t  \"of\": true,\n\t  \"off\": true,\n\t  \"often\": true,\n\t  \"on\": true,\n\t  \"only\": true,\n\t  \"or\": true,\n\t  \"other\": true,\n\t  \"our\": true,\n\t  \"own\": true,\n\t  \"rather\": true,\n\t  \"said\": true,\n\t  \"say\": true,\n\t  \"says\": true,\n\t  \"she\": true,\n\t  \"should\": true,\n\t  \"since\": true,\n\t  \"so\": true,\n\t  \"some\": true,\n\t  \"than\": true,\n\t  \"that\": true,\n\t  \"the\": true,\n\t  \"their\": true,\n\t  \"them\": true,\n\t  \"then\": true,\n\t  \"there\": true,\n\t  \"these\": true,\n\t  \"they\": true,\n\t  \"this\": true,\n\t  \"tis\": true,\n\t  \"to\": true,\n\t  \"too\": true,\n\t  \"twas\": true,\n\t  \"us\": true,\n\t  \"wants\": true,\n\t  \"was\": true,\n\t  \"we\": true,\n\t  \"were\": true,\n\t  \"what\": true,\n\t  \"when\": true,\n\t  \"where\": true,\n\t  \"which\": true,\n\t  \"while\": true,\n\t  \"who\": true,\n\t  \"whom\": true,\n\t  \"why\": true,\n\t  \"will\": true,\n\t  \"with\": true,\n\t  \"would\": true,\n\t  \"yet\": true,\n\t  \"you\": true,\n\t  \"your\": true\n\t};\n\t\n\telasticlunr.stopWordFilter.stopWords = elasticlunr.defaultStopWords;\n\t\n\telasticlunr.Pipeline.registerFunction(elasticlunr.stopWordFilter, 'stopWordFilter');\n\t/*!\n\t * elasticlunr.trimmer\n\t * Copyright (C) 2016 Oliver Nightingale\n\t * Copyright (C) 2016 Wei Song\n\t */\n\t\n\t/**\n\t * elasticlunr.trimmer is a pipeline function for trimming non word\n\t * characters from the begining and end of tokens before they\n\t * enter the index.\n\t *\n\t * This implementation may not work correctly for non latin\n\t * characters and should either be removed or adapted for use\n\t * with languages with non-latin characters.\n\t *\n\t * @module\n\t * @param {String} token The token to pass through the filter\n\t * @return {String}\n\t * @see elasticlunr.Pipeline\n\t */\n\telasticlunr.trimmer = function (token) {\n\t  if (token === null || token === undefined) {\n\t    throw new Error('token should not be undefined');\n\t  }\n\t\n\t  return token\n\t    .replace(/^\\W+/, '')\n\t    .replace(/\\W+$/, '');\n\t};\n\t\n\telasticlunr.Pipeline.registerFunction(elasticlunr.trimmer, 'trimmer');\n\t/*!\n\t * elasticlunr.InvertedIndex\n\t * Copyright (C) 2016 Wei Song\n\t * Includes code from - http://tartarus.org/~martin/PorterStemmer/js.txt\n\t */\n\t\n\t/**\n\t * elasticlunr.InvertedIndex is used for efficiently storing and\n\t * lookup of documents that contain a given token.\n\t *\n\t * @constructor\n\t */\n\telasticlunr.InvertedIndex = function () {\n\t  this.root = { docs: {}, df: 0 };\n\t};\n\t\n\t/**\n\t * Loads a previously serialised inverted index.\n\t *\n\t * @param {Object} serialisedData The serialised inverted index to load.\n\t * @return {elasticlunr.InvertedIndex}\n\t */\n\telasticlunr.InvertedIndex.load = function (serialisedData) {\n\t  var idx = new this;\n\t  idx.root = serialisedData.root;\n\t\n\t  return idx;\n\t};\n\t\n\t/**\n\t * Adds a {token: tokenInfo} pair to the inverted index.\n\t * If the token already exist, then update the tokenInfo.\n\t *\n\t * tokenInfo format: { ref: 1, tf: 2}\n\t * tokenInfor should contains the document's ref and the tf(token frequency) of that token in\n\t * the document.\n\t *\n\t * By default this function starts at the root of the current inverted index, however\n\t * it can start at any node of the inverted index if required.\n\t *\n\t * @param {String} token \n\t * @param {Object} tokenInfo format: { ref: 1, tf: 2}\n\t * @param {Object} root An optional node at which to start looking for the\n\t * correct place to enter the doc, by default the root of this elasticlunr.InvertedIndex\n\t * is used.\n\t * @memberOf InvertedIndex\n\t */\n\telasticlunr.InvertedIndex.prototype.addToken = function (token, tokenInfo, root) {\n\t  var root = root || this.root,\n\t      idx = 0;\n\t\n\t  while (idx <= token.length - 1) {\n\t    var key = token[idx];\n\t\n\t    if (!(key in root)) root[key] = {docs: {}, df: 0};\n\t    idx += 1;\n\t    root = root[key];\n\t  }\n\t\n\t  var docRef = tokenInfo.ref;\n\t  if (!root.docs[docRef]) {\n\t    // if this doc not exist, then add this doc\n\t    root.docs[docRef] = {tf: tokenInfo.tf};\n\t    root.df += 1;\n\t  } else {\n\t    // if this doc already exist, then update tokenInfo\n\t    root.docs[docRef] = {tf: tokenInfo.tf};\n\t  }\n\t};\n\t\n\t/**\n\t * Checks whether a token is in this elasticlunr.InvertedIndex.\n\t * \n\t *\n\t * @param {String} token The token to be checked\n\t * @return {Boolean}\n\t * @memberOf InvertedIndex\n\t */\n\telasticlunr.InvertedIndex.prototype.hasToken = function (token) {\n\t  if (!token) return false;\n\t\n\t  var node = this.root;\n\t\n\t  for (var i = 0; i < token.length; i++) {\n\t    if (!node[token[i]]) return false;\n\t    node = node[token[i]];\n\t  }\n\t\n\t  return true;\n\t};\n\t\n\t/**\n\t * Retrieve a node from the inverted index for a given token.\n\t * If token not found in this InvertedIndex, return null.\n\t * \n\t *\n\t * @param {String} token The token to get the node for.\n\t * @return {Object}\n\t * @see InvertedIndex.prototype.get\n\t * @memberOf InvertedIndex\n\t */\n\telasticlunr.InvertedIndex.prototype.getNode = function (token) {\n\t  if (!token) return null;\n\t\n\t  var node = this.root;\n\t\n\t  for (var i = 0; i < token.length; i++) {\n\t    if (!node[token[i]]) return null;\n\t    node = node[token[i]];\n\t  }\n\t\n\t  return node;\n\t};\n\t\n\t/**\n\t * Retrieve the documents of a given token.\n\t * If token not found, return {}.\n\t *\n\t *\n\t * @param {String} token The token to get the documents for.\n\t * @return {Object}\n\t * @memberOf InvertedIndex\n\t */\n\telasticlunr.InvertedIndex.prototype.getDocs = function (token) {\n\t  var node = this.getNode(token);\n\t  if (node == null) {\n\t    return {};\n\t  }\n\t\n\t  return node.docs;\n\t};\n\t\n\t/**\n\t * Retrieve term frequency of given token in given docRef.\n\t * If token or docRef not found, return 0.\n\t *\n\t *\n\t * @param {String} token The token to get the documents for.\n\t * @param {String|Integer} docRef\n\t * @return {Integer}\n\t * @memberOf InvertedIndex\n\t */\n\telasticlunr.InvertedIndex.prototype.getTermFrequency = function (token, docRef) {\n\t  var node = this.getNode(token);\n\t\n\t  if (node == null) {\n\t    return 0;\n\t  }\n\t\n\t  if (!(docRef in node.docs)) {\n\t    return 0;\n\t  }\n\t\n\t  return node.docs[docRef].tf;\n\t};\n\t\n\t/**\n\t * Retrieve the document frequency of given token.\n\t * If token not found, return 0.\n\t *\n\t *\n\t * @param {String} token The token to get the documents for.\n\t * @return {Object}\n\t * @memberOf InvertedIndex\n\t */\n\telasticlunr.InvertedIndex.prototype.getDocFreq = function (token) {\n\t  var node = this.getNode(token);\n\t\n\t  if (node == null) {\n\t    return 0;\n\t  }\n\t\n\t  return node.df;\n\t};\n\t\n\t/**\n\t * Remove the document identified by document's ref from the token in the inverted index.\n\t *\n\t *\n\t * @param {String} token Remove the document from which token.\n\t * @param {String} ref The ref of the document to remove from given token.\n\t * @memberOf InvertedIndex\n\t */\n\telasticlunr.InvertedIndex.prototype.removeToken = function (token, ref) {\n\t  if (!token) return;\n\t  var node = this.getNode(token);\n\t\n\t  if (node == null) return;\n\t\n\t  if (ref in node.docs) {\n\t    delete node.docs[ref];\n\t    node.df -= 1;\n\t  }\n\t};\n\t\n\t/**\n\t * Find all the possible suffixes of given token using tokens currently in the inverted index.\n\t * If token not found, return empty Array.\n\t *\n\t * @param {String} token The token to expand.\n\t * @return {Array}\n\t * @memberOf InvertedIndex\n\t */\n\telasticlunr.InvertedIndex.prototype.expandToken = function (token, memo, root) {\n\t  if (token == null || token == '') return [];\n\t  var memo = memo || [];\n\t\n\t  if (root == void 0) {\n\t    root = this.getNode(token);\n\t    if (root == null) return memo;\n\t  }\n\t\n\t  if (root.df > 0) memo.push(token);\n\t\n\t  for (var key in root) {\n\t    if (key === 'docs') continue;\n\t    if (key === 'df') continue;\n\t    this.expandToken(token + key, memo, root[key]);\n\t  }\n\t\n\t  return memo;\n\t};\n\t\n\t/**\n\t * Returns a representation of the inverted index ready for serialisation.\n\t *\n\t * @return {Object}\n\t * @memberOf InvertedIndex\n\t */\n\telasticlunr.InvertedIndex.prototype.toJSON = function () {\n\t  return {\n\t    root: this.root\n\t  };\n\t};\n\t\n\t/*!\n\t * elasticlunr.Configuration\n\t * Copyright (C) 2016 Wei Song\n\t */\n\t \n\t /** \n\t  * elasticlunr.Configuration is used to analyze the user search configuration.\n\t  * \n\t  * By elasticlunr.Configuration user could set query-time boosting, boolean model in each field.\n\t  * \n\t  * Currently configuration supports:\n\t  * 1. query-time boosting, user could set how to boost each field.\n\t  * 2. boolean model chosing, user could choose which boolean model to use for each field.\n\t  * 3. token expandation, user could set token expand to True to improve Recall. Default is False.\n\t  * \n\t  * Query time boosting must be configured by field category, \"boolean\" model could be configured \n\t  * by both field category or globally as the following example. Field configuration for \"boolean\"\n\t  * will overwrite global configuration.\n\t  * Token expand could be configured both by field category or golbally. Local field configuration will\n\t  * overwrite global configuration.\n\t  * \n\t  * configuration example:\n\t  * {\n\t  *   fields:{ \n\t  *     title: {boost: 2},\n\t  *     body: {boost: 1}\n\t  *   },\n\t  *   bool: \"OR\"\n\t  * }\n\t  * \n\t  * \"bool\" field configuation overwrite global configuation example:\n\t  * {\n\t  *   fields:{ \n\t  *     title: {boost: 2, bool: \"AND\"},\n\t  *     body: {boost: 1}\n\t  *   },\n\t  *   bool: \"OR\"\n\t  * }\n\t  * \n\t  * \"expand\" example:\n\t  * {\n\t  *   fields:{ \n\t  *     title: {boost: 2, bool: \"AND\"},\n\t  *     body: {boost: 1}\n\t  *   },\n\t  *   bool: \"OR\",\n\t  *   expand: true\n\t  * }\n\t  * \n\t  * \"expand\" example for field category:\n\t  * {\n\t  *   fields:{ \n\t  *     title: {boost: 2, bool: \"AND\", expand: true},\n\t  *     body: {boost: 1}\n\t  *   },\n\t  *   bool: \"OR\"\n\t  * }\n\t  * \n\t  * setting the boost to 0 ignores the field (this will only search the title):\n\t  * {\n\t  *   fields:{\n\t  *     title: {boost: 1},\n\t  *     body: {boost: 0}\n\t  *   }\n\t  * }\n\t  *\n\t  * then, user could search with configuration to do query-time boosting.\n\t  * idx.search('oracle database', {fields: {title: {boost: 2}, body: {boost: 1}}});\n\t  * \n\t  * \n\t  * @constructor\n\t  * \n\t  * @param {String} config user configuration\n\t  * @param {Array} fields fields of index instance\n\t  * @module\n\t  */\n\telasticlunr.Configuration = function (config, fields) {\n\t  var config = config || '';\n\t\n\t  if (fields == undefined || fields == null) {\n\t    throw new Error('fields should not be null');\n\t  }\n\t\n\t  this.config = {};\n\t\n\t  var userConfig;\n\t  try {\n\t    userConfig = JSON.parse(config);\n\t    this.buildUserConfig(userConfig, fields);\n\t  } catch (error) {\n\t    elasticlunr.utils.warn('user configuration parse failed, will use default configuration');\n\t    this.buildDefaultConfig(fields);\n\t  }\n\t};\n\t\n\t/**\n\t * Build default search configuration.\n\t * \n\t * @param {Array} fields fields of index instance\n\t */\n\telasticlunr.Configuration.prototype.buildDefaultConfig = function (fields) {\n\t  this.reset();\n\t  fields.forEach(function (field) {\n\t    this.config[field] = {\n\t      boost: 1,\n\t      bool: \"OR\",\n\t      expand: false\n\t    };\n\t  }, this);\n\t};\n\t\n\t/**\n\t * Build user configuration.\n\t * \n\t * @param {JSON} config User JSON configuratoin\n\t * @param {Array} fields fields of index instance\n\t */\n\telasticlunr.Configuration.prototype.buildUserConfig = function (config, fields) {\n\t  var global_bool = \"OR\";\n\t  var global_expand = false;\n\t\n\t  this.reset();\n\t  if ('bool' in config) {\n\t    global_bool = config['bool'] || global_bool;\n\t  }\n\t\n\t  if ('expand' in config) {\n\t    global_expand = config['expand'] || global_expand;\n\t  }\n\t\n\t  if ('fields' in config) {\n\t    for (var field in config['fields']) {\n\t      if (fields.indexOf(field) > -1) {\n\t        var field_config = config['fields'][field];\n\t        var field_expand = global_expand;\n\t        if (field_config.expand != undefined) {\n\t          field_expand = field_config.expand;\n\t        }\n\t\n\t        this.config[field] = {\n\t          boost: (field_config.boost || field_config.boost === 0) ? field_config.boost : 1,\n\t          bool: field_config.bool || global_bool,\n\t          expand: field_expand\n\t        };\n\t      } else {\n\t        elasticlunr.utils.warn('field name in user configuration not found in index instance fields');\n\t      }\n\t    }\n\t  } else {\n\t    this.addAllFields2UserConfig(global_bool, global_expand, fields);\n\t  }\n\t};\n\t\n\t/**\n\t * Add all fields to user search configuration.\n\t * \n\t * @param {String} bool Boolean model\n\t * @param {String} expand Expand model\n\t * @param {Array} fields fields of index instance\n\t */\n\telasticlunr.Configuration.prototype.addAllFields2UserConfig = function (bool, expand, fields) {\n\t  fields.forEach(function (field) {\n\t    this.config[field] = {\n\t      boost: 1,\n\t      bool: bool,\n\t      expand: expand\n\t    };\n\t  }, this);\n\t};\n\t\n\t/**\n\t * get current user configuration\n\t */\n\telasticlunr.Configuration.prototype.get = function () {\n\t  return this.config;\n\t};\n\t\n\t/**\n\t * reset user search configuration.\n\t */\n\telasticlunr.Configuration.prototype.reset = function () {\n\t  this.config = {};\n\t};\n\t/**\n\t * sorted_set.js is added only to make elasticlunr.js compatible with lunr-languages.\n\t * if elasticlunr.js support different languages by default, this will make elasticlunr.js\n\t * much bigger that not good for browser usage.\n\t *\n\t */\n\t\n\t\n\t/*!\n\t * lunr.SortedSet\n\t * Copyright (C) 2016 Oliver Nightingale\n\t */\n\t\n\t/**\n\t * lunr.SortedSets are used to maintain an array of uniq values in a sorted\n\t * order.\n\t *\n\t * @constructor\n\t */\n\tlunr.SortedSet = function () {\n\t  this.length = 0\n\t  this.elements = []\n\t}\n\t\n\t/**\n\t * Loads a previously serialised sorted set.\n\t *\n\t * @param {Array} serialisedData The serialised set to load.\n\t * @returns {lunr.SortedSet}\n\t * @memberOf SortedSet\n\t */\n\tlunr.SortedSet.load = function (serialisedData) {\n\t  var set = new this\n\t\n\t  set.elements = serialisedData\n\t  set.length = serialisedData.length\n\t\n\t  return set\n\t}\n\t\n\t/**\n\t * Inserts new items into the set in the correct position to maintain the\n\t * order.\n\t *\n\t * @param {Object} The objects to add to this set.\n\t * @memberOf SortedSet\n\t */\n\tlunr.SortedSet.prototype.add = function () {\n\t  var i, element\n\t\n\t  for (i = 0; i < arguments.length; i++) {\n\t    element = arguments[i]\n\t    if (~this.indexOf(element)) continue\n\t    this.elements.splice(this.locationFor(element), 0, element)\n\t  }\n\t\n\t  this.length = this.elements.length\n\t}\n\t\n\t/**\n\t * Converts this sorted set into an array.\n\t *\n\t * @returns {Array}\n\t * @memberOf SortedSet\n\t */\n\tlunr.SortedSet.prototype.toArray = function () {\n\t  return this.elements.slice()\n\t}\n\t\n\t/**\n\t * Creates a new array with the results of calling a provided function on every\n\t * element in this sorted set.\n\t *\n\t * Delegates to Array.prototype.map and has the same signature.\n\t *\n\t * @param {Function} fn The function that is called on each element of the\n\t * set.\n\t * @param {Object} ctx An optional object that can be used as the context\n\t * for the function fn.\n\t * @returns {Array}\n\t * @memberOf SortedSet\n\t */\n\tlunr.SortedSet.prototype.map = function (fn, ctx) {\n\t  return this.elements.map(fn, ctx)\n\t}\n\t\n\t/**\n\t * Executes a provided function once per sorted set element.\n\t *\n\t * Delegates to Array.prototype.forEach and has the same signature.\n\t *\n\t * @param {Function} fn The function that is called on each element of the\n\t * set.\n\t * @param {Object} ctx An optional object that can be used as the context\n\t * @memberOf SortedSet\n\t * for the function fn.\n\t */\n\tlunr.SortedSet.prototype.forEach = function (fn, ctx) {\n\t  return this.elements.forEach(fn, ctx)\n\t}\n\t\n\t/**\n\t * Returns the index at which a given element can be found in the\n\t * sorted set, or -1 if it is not present.\n\t *\n\t * @param {Object} elem The object to locate in the sorted set.\n\t * @returns {Number}\n\t * @memberOf SortedSet\n\t */\n\tlunr.SortedSet.prototype.indexOf = function (elem) {\n\t  var start = 0,\n\t      end = this.elements.length,\n\t      sectionLength = end - start,\n\t      pivot = start + Math.floor(sectionLength / 2),\n\t      pivotElem = this.elements[pivot]\n\t\n\t  while (sectionLength > 1) {\n\t    if (pivotElem === elem) return pivot\n\t\n\t    if (pivotElem < elem) start = pivot\n\t    if (pivotElem > elem) end = pivot\n\t\n\t    sectionLength = end - start\n\t    pivot = start + Math.floor(sectionLength / 2)\n\t    pivotElem = this.elements[pivot]\n\t  }\n\t\n\t  if (pivotElem === elem) return pivot\n\t\n\t  return -1\n\t}\n\t\n\t/**\n\t * Returns the position within the sorted set that an element should be\n\t * inserted at to maintain the current order of the set.\n\t *\n\t * This function assumes that the element to search for does not already exist\n\t * in the sorted set.\n\t *\n\t * @param {Object} elem The elem to find the position for in the set\n\t * @returns {Number}\n\t * @memberOf SortedSet\n\t */\n\tlunr.SortedSet.prototype.locationFor = function (elem) {\n\t  var start = 0,\n\t      end = this.elements.length,\n\t      sectionLength = end - start,\n\t      pivot = start + Math.floor(sectionLength / 2),\n\t      pivotElem = this.elements[pivot]\n\t\n\t  while (sectionLength > 1) {\n\t    if (pivotElem < elem) start = pivot\n\t    if (pivotElem > elem) end = pivot\n\t\n\t    sectionLength = end - start\n\t    pivot = start + Math.floor(sectionLength / 2)\n\t    pivotElem = this.elements[pivot]\n\t  }\n\t\n\t  if (pivotElem > elem) return pivot\n\t  if (pivotElem < elem) return pivot + 1\n\t}\n\t\n\t/**\n\t * Creates a new lunr.SortedSet that contains the elements in the intersection\n\t * of this set and the passed set.\n\t *\n\t * @param {lunr.SortedSet} otherSet The set to intersect with this set.\n\t * @returns {lunr.SortedSet}\n\t * @memberOf SortedSet\n\t */\n\tlunr.SortedSet.prototype.intersect = function (otherSet) {\n\t  var intersectSet = new lunr.SortedSet,\n\t      i = 0, j = 0,\n\t      a_len = this.length, b_len = otherSet.length,\n\t      a = this.elements, b = otherSet.elements\n\t\n\t  while (true) {\n\t    if (i > a_len - 1 || j > b_len - 1) break\n\t\n\t    if (a[i] === b[j]) {\n\t      intersectSet.add(a[i])\n\t      i++, j++\n\t      continue\n\t    }\n\t\n\t    if (a[i] < b[j]) {\n\t      i++\n\t      continue\n\t    }\n\t\n\t    if (a[i] > b[j]) {\n\t      j++\n\t      continue\n\t    }\n\t  };\n\t\n\t  return intersectSet\n\t}\n\t\n\t/**\n\t * Makes a copy of this set\n\t *\n\t * @returns {lunr.SortedSet}\n\t * @memberOf SortedSet\n\t */\n\tlunr.SortedSet.prototype.clone = function () {\n\t  var clone = new lunr.SortedSet\n\t\n\t  clone.elements = this.toArray()\n\t  clone.length = clone.elements.length\n\t\n\t  return clone\n\t}\n\t\n\t/**\n\t * Creates a new lunr.SortedSet that contains the elements in the union\n\t * of this set and the passed set.\n\t *\n\t * @param {lunr.SortedSet} otherSet The set to union with this set.\n\t * @returns {lunr.SortedSet}\n\t * @memberOf SortedSet\n\t */\n\tlunr.SortedSet.prototype.union = function (otherSet) {\n\t  var longSet, shortSet, unionSet\n\t\n\t  if (this.length >= otherSet.length) {\n\t    longSet = this, shortSet = otherSet\n\t  } else {\n\t    longSet = otherSet, shortSet = this\n\t  }\n\t\n\t  unionSet = longSet.clone()\n\t\n\t  for(var i = 0, shortSetElements = shortSet.toArray(); i < shortSetElements.length; i++){\n\t    unionSet.add(shortSetElements[i])\n\t  }\n\t\n\t  return unionSet\n\t}\n\t\n\t/**\n\t * Returns a representation of the sorted set ready for serialisation.\n\t *\n\t * @returns {Array}\n\t * @memberOf SortedSet\n\t */\n\tlunr.SortedSet.prototype.toJSON = function () {\n\t  return this.toArray()\n\t}\n\t  /**\n\t   * export the module via AMD, CommonJS or as a browser global\n\t   * Export code from https://github.com/umdjs/umd/blob/master/returnExports.js\n\t   */\n\t  ;(function (root, factory) {\n\t    if (true) {\n\t      // AMD. Register as an anonymous module.\n\t      !(__WEBPACK_AMD_DEFINE_FACTORY__ = (factory), __WEBPACK_AMD_DEFINE_RESULT__ = (typeof __WEBPACK_AMD_DEFINE_FACTORY__ === 'function' ? (__WEBPACK_AMD_DEFINE_FACTORY__.call(exports, __webpack_require__, exports, module)) : __WEBPACK_AMD_DEFINE_FACTORY__), __WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__))\n\t    } else if (typeof exports === 'object') {\n\t      /**\n\t       * Node. Does not work with strict CommonJS, but\n\t       * only CommonJS-like enviroments that support module.exports,\n\t       * like Node.\n\t       */\n\t      module.exports = factory()\n\t    } else {\n\t      // Browser globals (root is window)\n\t      root.elasticlunr = factory()\n\t    }\n\t  }(this, function () {\n\t    /**\n\t     * Just return a value to define the module export.\n\t     * This example returns an object, but the module\n\t     * can return a function as the exported value.\n\t     */\n\t    return elasticlunr\n\t  }))\n\t})();\n\n\n/***/ }),\n\n/***/ 86:\n/***/ (function(module, exports, __webpack_require__) {\n\n\t'use strict';\n\t\n\texports.__esModule = true;\n\texports.query = undefined;\n\t\n\tvar _react = __webpack_require__(1);\n\t\n\tvar _react2 = _interopRequireDefault(_react);\n\t\n\tvar _elasticlunr = __webpack_require__(114);\n\t\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\t\n\tfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\t\n\tfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\t\n\tfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\t\n\t// Graphql query used to retrieve the serialized search index.\n\tvar query = exports.query = '** extracted graphql fragment **';\n\t\n\t// Search component\n\t\n\tvar Search = function (_Component) {\n\t    _inherits(Search, _Component);\n\t\n\t    function Search(props) {\n\t        _classCallCheck(this, Search);\n\t\n\t        var _this = _possibleConstructorReturn(this, _Component.call(this, props));\n\t\n\t        _this.getOrCreateIndex = function () {\n\t            return _this.index ? _this.index\n\t            // Create an elastic lunr index and hydrate with graphql query results\n\t            : _elasticlunr.Index.load(_this.props.data.siteSearchIndex.index);\n\t        };\n\t\n\t        _this.search = function (evt) {\n\t            var query = evt.target.value;\n\t            _this.index = _this.getOrCreateIndex();\n\t            _this.setState({\n\t                query: query,\n\t                // Query the index with search string to get an [] of IDs\n\t                results: _this.index.search(query)\n\t                // Map over each ID and return the full document\n\t                .map(function (_ref) {\n\t                    var ref = _ref.ref;\n\t                    return _this.index.documentStore.getDoc(ref);\n\t                })\n\t            });\n\t        };\n\t\n\t        _this.state = {\n\t            query: '',\n\t            results: []\n\t        };\n\t        return _this;\n\t    }\n\t\n\t    Search.prototype.render = function render() {\n\t        return _react2.default.createElement(\n\t            'div',\n\t            null,\n\t            _react2.default.createElement('input', { type: 'text', className: 'search', value: this.state.query, onChange: this.search }),\n\t            _react2.default.createElement(\n\t                'ul',\n\t                null,\n\t                this.state.results.map(function (page) {\n\t                    return _react2.default.createElement(\n\t                        'li',\n\t                        null,\n\t                        page.title,\n\t                        ': ',\n\t                        page.keywords.join(',')\n\t                    );\n\t                })\n\t            )\n\t        );\n\t    };\n\t\n\t    return Search;\n\t}(_react.Component);\n\t\n\texports.default = Search;\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// component---src-pages-search-js-899e2388c071b1605ac4.js","/**\n * elasticlunr - http://weixsong.github.io\n * Lightweight full-text search engine in Javascript for browser search and offline search. - 0.9.5\n *\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n * MIT Licensed\n * @license\n */\n\n(function(){\n\n/*!\n * elasticlunr.js\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * Convenience function for instantiating a new elasticlunr index and configuring it\n * with the default pipeline functions and the passed config function.\n *\n * When using this convenience function a new index will be created with the\n * following functions already in the pipeline:\n * \n * 1. elasticlunr.trimmer - trim non-word character\n * 2. elasticlunr.StopWordFilter - filters out any stop words before they enter the\n * index\n * 3. elasticlunr.stemmer - stems the tokens before entering the index.\n *\n *\n * Example:\n *\n *     var idx = elasticlunr(function () {\n *       this.addField('id');\n *       this.addField('title');\n *       this.addField('body');\n *       \n *       //this.setRef('id'); // default ref is 'id'\n *\n *       this.pipeline.add(function () {\n *         // some custom pipeline function\n *       });\n *     });\n * \n *    idx.addDoc({\n *      id: 1, \n *      title: 'Oracle released database 12g',\n *      body: 'Yestaday, Oracle has released their latest database, named 12g, more robust. this product will increase Oracle profit.'\n *    });\n * \n *    idx.addDoc({\n *      id: 2, \n *      title: 'Oracle released annual profit report',\n *      body: 'Yestaday, Oracle has released their annual profit report of 2015, total profit is 12.5 Billion.'\n *    });\n * \n *    # simple search\n *    idx.search('oracle database');\n * \n *    # search with query-time boosting\n *    idx.search('oracle database', {fields: {title: {boost: 2}, body: {boost: 1}}});\n *\n * @param {Function} config A function that will be called with the new instance\n * of the elasticlunr.Index as both its context and first parameter. It can be used to\n * customize the instance of new elasticlunr.Index.\n * @namespace\n * @module\n * @return {elasticlunr.Index}\n *\n */\nvar elasticlunr = function (config) {\n  var idx = new elasticlunr.Index;\n\n  idx.pipeline.add(\n    elasticlunr.trimmer,\n    elasticlunr.stopWordFilter,\n    elasticlunr.stemmer\n  );\n\n  if (config) config.call(idx, idx);\n\n  return idx;\n};\n\nelasticlunr.version = \"0.9.5\";\n\n// only used this to make elasticlunr.js compatible with lunr-languages\n// this is a trick to define a global alias of elasticlunr\nlunr = elasticlunr;\n\n/*!\n * elasticlunr.utils\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * A namespace containing utils for the rest of the elasticlunr library\n */\nelasticlunr.utils = {};\n\n/**\n * Print a warning message to the console.\n *\n * @param {String} message The message to be printed.\n * @memberOf Utils\n */\nelasticlunr.utils.warn = (function (global) {\n  return function (message) {\n    if (global.console && console.warn) {\n      console.warn(message);\n    }\n  };\n})(this);\n\n/**\n * Convert an object to string.\n *\n * In the case of `null` and `undefined` the function returns\n * an empty string, in all other cases the result of calling\n * `toString` on the passed object is returned.\n *\n * @param {object} obj The object to convert to a string.\n * @return {String} string representation of the passed object.\n * @memberOf Utils\n */\nelasticlunr.utils.toString = function (obj) {\n  if (obj === void 0 || obj === null) {\n    return \"\";\n  }\n\n  return obj.toString();\n};\n/*!\n * elasticlunr.EventEmitter\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * elasticlunr.EventEmitter is an event emitter for elasticlunr.\n * It manages adding and removing event handlers and triggering events and their handlers.\n *\n * Each event could has multiple corresponding functions,\n * these functions will be called as the sequence that they are added into the event.\n * \n * @constructor\n */\nelasticlunr.EventEmitter = function () {\n  this.events = {};\n};\n\n/**\n * Binds a handler function to a specific event(s).\n *\n * Can bind a single function to many different events in one call.\n *\n * @param {String} [eventName] The name(s) of events to bind this function to.\n * @param {Function} fn The function to call when an event is fired.\n * @memberOf EventEmitter\n */\nelasticlunr.EventEmitter.prototype.addListener = function () {\n  var args = Array.prototype.slice.call(arguments),\n      fn = args.pop(),\n      names = args;\n\n  if (typeof fn !== \"function\") throw new TypeError (\"last argument must be a function\");\n\n  names.forEach(function (name) {\n    if (!this.hasHandler(name)) this.events[name] = [];\n    this.events[name].push(fn);\n  }, this);\n};\n\n/**\n * Removes a handler function from a specific event.\n *\n * @param {String} eventName The name of the event to remove this function from.\n * @param {Function} fn The function to remove from an event.\n * @memberOf EventEmitter\n */\nelasticlunr.EventEmitter.prototype.removeListener = function (name, fn) {\n  if (!this.hasHandler(name)) return;\n\n  var fnIndex = this.events[name].indexOf(fn);\n  if (fnIndex === -1) return;\n\n  this.events[name].splice(fnIndex, 1);\n\n  if (this.events[name].length == 0) delete this.events[name];\n};\n\n/**\n * Call all functions that bounded to the given event.\n *\n * Additional data can be passed to the event handler as arguments to `emit`\n * after the event name.\n *\n * @param {String} eventName The name of the event to emit.\n * @memberOf EventEmitter\n */\nelasticlunr.EventEmitter.prototype.emit = function (name) {\n  if (!this.hasHandler(name)) return;\n\n  var args = Array.prototype.slice.call(arguments, 1);\n\n  this.events[name].forEach(function (fn) {\n    fn.apply(undefined, args);\n  }, this);\n};\n\n/**\n * Checks whether a handler has ever been stored against an event.\n *\n * @param {String} eventName The name of the event to check.\n * @private\n * @memberOf EventEmitter\n */\nelasticlunr.EventEmitter.prototype.hasHandler = function (name) {\n  return name in this.events;\n};\n/*!\n * elasticlunr.tokenizer\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * A function for splitting a string into tokens.\n * Currently English is supported as default.\n * Uses `elasticlunr.tokenizer.seperator` to split strings, you could change\n * the value of this property to set how you want strings are split into tokens.\n * IMPORTANT: use elasticlunr.tokenizer.seperator carefully, if you are not familiar with\n * text process, then you'd better not change it.\n *\n * @module\n * @param {String} str The string that you want to tokenize.\n * @see elasticlunr.tokenizer.seperator\n * @return {Array}\n */\nelasticlunr.tokenizer = function (str) {\n  if (!arguments.length || str === null || str === undefined) return [];\n  if (Array.isArray(str)) {\n    var arr = str.filter(function(token) {\n      if (token === null || token === undefined) {\n        return false;\n      }\n\n      return true;\n    });\n\n    arr = arr.map(function (t) {\n      return elasticlunr.utils.toString(t).toLowerCase();\n    });\n\n    var out = [];\n    arr.forEach(function(item) {\n      var tokens = item.split(elasticlunr.tokenizer.seperator);\n      out = out.concat(tokens);\n    }, this);\n\n    return out;\n  }\n\n  return str.toString().trim().toLowerCase().split(elasticlunr.tokenizer.seperator);\n};\n\n/**\n * Default string seperator.\n */\nelasticlunr.tokenizer.defaultSeperator = /[\\s\\-]+/;\n\n/**\n * The sperator used to split a string into tokens. Override this property to change the behaviour of\n * `elasticlunr.tokenizer` behaviour when tokenizing strings. By default this splits on whitespace and hyphens.\n *\n * @static\n * @see elasticlunr.tokenizer\n */\nelasticlunr.tokenizer.seperator = elasticlunr.tokenizer.defaultSeperator;\n\n/**\n * Set up customized string seperator\n *\n * @param {Object} sep The customized seperator that you want to use to tokenize a string.\n */\nelasticlunr.tokenizer.setSeperator = function(sep) {\n    if (sep !== null && sep !== undefined && typeof(sep) === 'object') {\n        elasticlunr.tokenizer.seperator = sep;\n    }\n}\n\n/**\n * Reset string seperator\n *\n */\nelasticlunr.tokenizer.resetSeperator = function() {\n    elasticlunr.tokenizer.seperator = elasticlunr.tokenizer.defaultSeperator;\n}\n\n/**\n * Get string seperator\n *\n */\nelasticlunr.tokenizer.getSeperator = function() {\n    return elasticlunr.tokenizer.seperator;\n}\n/*!\n * elasticlunr.Pipeline\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * elasticlunr.Pipelines maintain an ordered list of functions to be applied to \n * both documents tokens and query tokens.\n *\n * An instance of elasticlunr.Index will contain a pipeline\n * with a trimmer, a stop word filter, an English stemmer. Extra\n * functions can be added before or after either of these functions or these\n * default functions can be removed.\n *\n * When run the pipeline, it will call each function in turn.\n *\n * The output of the functions in the pipeline will be passed to the next function\n * in the pipeline. To exclude a token from entering the index the function\n * should return undefined, the rest of the pipeline will not be called with\n * this token.\n *\n * For serialisation of pipelines to work, all functions used in an instance of\n * a pipeline should be registered with elasticlunr.Pipeline. Registered functions can\n * then be loaded. If trying to load a serialised pipeline that uses functions\n * that are not registered an error will be thrown.\n *\n * If not planning on serialising the pipeline then registering pipeline functions\n * is not necessary.\n *\n * @constructor\n */\nelasticlunr.Pipeline = function () {\n  this._queue = [];\n};\n\nelasticlunr.Pipeline.registeredFunctions = {};\n\n/**\n * Register a function in the pipeline.\n *\n * Functions that are used in the pipeline should be registered if the pipeline\n * needs to be serialised, or a serialised pipeline needs to be loaded.\n *\n * Registering a function does not add it to a pipeline, functions must still be\n * added to instances of the pipeline for them to be used when running a pipeline.\n *\n * @param {Function} fn The function to register.\n * @param {String} label The label to register this function with\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.registerFunction = function (fn, label) {\n  if (label in elasticlunr.Pipeline.registeredFunctions) {\n    elasticlunr.utils.warn('Overwriting existing registered function: ' + label);\n  }\n\n  fn.label = label;\n  elasticlunr.Pipeline.registeredFunctions[label] = fn;\n};\n\n/**\n * Get a registered function in the pipeline.\n *\n * @param {String} label The label of registered function.\n * @return {Function}\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.getRegisteredFunction = function (label) {\n  if ((label in elasticlunr.Pipeline.registeredFunctions) !== true) {\n    return null;\n  }\n\n  return elasticlunr.Pipeline.registeredFunctions[label];\n};\n\n/**\n * Warns if the function is not registered as a Pipeline function.\n *\n * @param {Function} fn The function to check for.\n * @private\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.warnIfFunctionNotRegistered = function (fn) {\n  var isRegistered = fn.label && (fn.label in this.registeredFunctions);\n\n  if (!isRegistered) {\n    elasticlunr.utils.warn('Function is not registered with pipeline. This may cause problems when serialising the index.\\n', fn);\n  }\n};\n\n/**\n * Loads a previously serialised pipeline.\n *\n * All functions to be loaded must already be registered with elasticlunr.Pipeline.\n * If any function from the serialised data has not been registered then an\n * error will be thrown.\n *\n * @param {Object} serialised The serialised pipeline to load.\n * @return {elasticlunr.Pipeline}\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.load = function (serialised) {\n  var pipeline = new elasticlunr.Pipeline;\n\n  serialised.forEach(function (fnName) {\n    var fn = elasticlunr.Pipeline.getRegisteredFunction(fnName);\n\n    if (fn) {\n      pipeline.add(fn);\n    } else {\n      throw new Error('Cannot load un-registered function: ' + fnName);\n    }\n  });\n\n  return pipeline;\n};\n\n/**\n * Adds new functions to the end of the pipeline.\n *\n * Logs a warning if the function has not been registered.\n *\n * @param {Function} functions Any number of functions to add to the pipeline.\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.prototype.add = function () {\n  var fns = Array.prototype.slice.call(arguments);\n\n  fns.forEach(function (fn) {\n    elasticlunr.Pipeline.warnIfFunctionNotRegistered(fn);\n    this._queue.push(fn);\n  }, this);\n};\n\n/**\n * Adds a single function after a function that already exists in the\n * pipeline.\n *\n * Logs a warning if the function has not been registered.\n * If existingFn is not found, throw an Exception.\n *\n * @param {Function} existingFn A function that already exists in the pipeline.\n * @param {Function} newFn The new function to add to the pipeline.\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.prototype.after = function (existingFn, newFn) {\n  elasticlunr.Pipeline.warnIfFunctionNotRegistered(newFn);\n\n  var pos = this._queue.indexOf(existingFn);\n  if (pos === -1) {\n    throw new Error('Cannot find existingFn');\n  }\n\n  this._queue.splice(pos + 1, 0, newFn);\n};\n\n/**\n * Adds a single function before a function that already exists in the\n * pipeline.\n *\n * Logs a warning if the function has not been registered.\n * If existingFn is not found, throw an Exception.\n *\n * @param {Function} existingFn A function that already exists in the pipeline.\n * @param {Function} newFn The new function to add to the pipeline.\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.prototype.before = function (existingFn, newFn) {\n  elasticlunr.Pipeline.warnIfFunctionNotRegistered(newFn);\n\n  var pos = this._queue.indexOf(existingFn);\n  if (pos === -1) {\n    throw new Error('Cannot find existingFn');\n  }\n\n  this._queue.splice(pos, 0, newFn);\n};\n\n/**\n * Removes a function from the pipeline.\n *\n * @param {Function} fn The function to remove from the pipeline.\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.prototype.remove = function (fn) {\n  var pos = this._queue.indexOf(fn);\n  if (pos === -1) {\n    return;\n  }\n\n  this._queue.splice(pos, 1);\n};\n\n/**\n * Runs the current list of functions that registered in the pipeline against the\n * input tokens.\n *\n * @param {Array} tokens The tokens to run through the pipeline.\n * @return {Array}\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.prototype.run = function (tokens) {\n  var out = [],\n      tokenLength = tokens.length,\n      pipelineLength = this._queue.length;\n\n  for (var i = 0; i < tokenLength; i++) {\n    var token = tokens[i];\n\n    for (var j = 0; j < pipelineLength; j++) {\n      token = this._queue[j](token, i, tokens);\n      if (token === void 0 || token === null) break;\n    };\n\n    if (token !== void 0 && token !== null) out.push(token);\n  };\n\n  return out;\n};\n\n/**\n * Resets the pipeline by removing any existing processors.\n *\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.prototype.reset = function () {\n  this._queue = [];\n};\n\n /**\n  * Get the pipeline if user want to check the pipeline.\n  *\n  * @memberOf Pipeline\n  */\n elasticlunr.Pipeline.prototype.get = function () {\n   return this._queue;\n };\n\n/**\n * Returns a representation of the pipeline ready for serialisation.\n * Only serialize pipeline function's name. Not storing function, so when\n * loading the archived JSON index file, corresponding pipeline function is \n * added by registered function of elasticlunr.Pipeline.registeredFunctions\n *\n * Logs a warning if the function has not been registered.\n *\n * @return {Array}\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.prototype.toJSON = function () {\n  return this._queue.map(function (fn) {\n    elasticlunr.Pipeline.warnIfFunctionNotRegistered(fn);\n    return fn.label;\n  });\n};\n/*!\n * elasticlunr.Index\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * elasticlunr.Index is object that manages a search index.  It contains the indexes\n * and stores all the tokens and document lookups.  It also provides the main\n * user facing API for the library.\n *\n * @constructor\n */\nelasticlunr.Index = function () {\n  this._fields = [];\n  this._ref = 'id';\n  this.pipeline = new elasticlunr.Pipeline;\n  this.documentStore = new elasticlunr.DocumentStore;\n  this.index = {};\n  this.eventEmitter = new elasticlunr.EventEmitter;\n  this._idfCache = {};\n\n  this.on('add', 'remove', 'update', (function () {\n    this._idfCache = {};\n  }).bind(this));\n};\n\n/**\n * Bind a handler to events being emitted by the index.\n *\n * The handler can be bound to many events at the same time.\n *\n * @param {String} [eventName] The name(s) of events to bind the function to.\n * @param {Function} fn The serialised set to load.\n * @memberOf Index\n */\nelasticlunr.Index.prototype.on = function () {\n  var args = Array.prototype.slice.call(arguments);\n  return this.eventEmitter.addListener.apply(this.eventEmitter, args);\n};\n\n/**\n * Removes a handler from an event being emitted by the index.\n *\n * @param {String} eventName The name of events to remove the function from.\n * @param {Function} fn The serialised set to load.\n * @memberOf Index\n */\nelasticlunr.Index.prototype.off = function (name, fn) {\n  return this.eventEmitter.removeListener(name, fn);\n};\n\n/**\n * Loads a previously serialised index.\n *\n * Issues a warning if the index being imported was serialised\n * by a different version of elasticlunr.\n *\n * @param {Object} serialisedData The serialised set to load.\n * @return {elasticlunr.Index}\n * @memberOf Index\n */\nelasticlunr.Index.load = function (serialisedData) {\n  if (serialisedData.version !== elasticlunr.version) {\n    elasticlunr.utils.warn('version mismatch: current '\n                    + elasticlunr.version + ' importing ' + serialisedData.version);\n  }\n\n  var idx = new this;\n\n  idx._fields = serialisedData.fields;\n  idx._ref = serialisedData.ref;\n  idx.documentStore = elasticlunr.DocumentStore.load(serialisedData.documentStore);\n  idx.pipeline = elasticlunr.Pipeline.load(serialisedData.pipeline);\n  idx.index = {};\n  for (var field in serialisedData.index) {\n    idx.index[field] = elasticlunr.InvertedIndex.load(serialisedData.index[field]);\n  }\n\n  return idx;\n};\n\n/**\n * Adds a field to the list of fields that will be searchable within documents in the index.\n *\n * Remember that inner index is build based on field, which means each field has one inverted index.\n *\n * Fields should be added before any documents are added to the index, fields\n * that are added after documents are added to the index will only apply to new\n * documents added to the index.\n *\n * @param {String} fieldName The name of the field within the document that should be indexed\n * @return {elasticlunr.Index}\n * @memberOf Index\n */\nelasticlunr.Index.prototype.addField = function (fieldName) {\n  this._fields.push(fieldName);\n  this.index[fieldName] = new elasticlunr.InvertedIndex;\n  return this;\n};\n\n/**\n * Sets the property used to uniquely identify documents added to the index,\n * by default this property is 'id'.\n *\n * This should only be changed before adding documents to the index, changing\n * the ref property without resetting the index can lead to unexpected results.\n *\n * @param {String} refName The property to use to uniquely identify the\n * documents in the index.\n * @param {Boolean} emitEvent Whether to emit add events, defaults to true\n * @return {elasticlunr.Index}\n * @memberOf Index\n */\nelasticlunr.Index.prototype.setRef = function (refName) {\n  this._ref = refName;\n  return this;\n};\n\n/**\n *\n * Set if the JSON format original documents are save into elasticlunr.DocumentStore\n *\n * Defaultly save all the original JSON documents.\n *\n * @param {Boolean} save Whether to save the original JSON documents.\n * @return {elasticlunr.Index}\n * @memberOf Index\n */\nelasticlunr.Index.prototype.saveDocument = function (save) {\n  this.documentStore = new elasticlunr.DocumentStore(save);\n  return this;\n};\n\n/**\n * Add a JSON format document to the index.\n *\n * This is the way new documents enter the index, this function will run the\n * fields from the document through the index's pipeline and then add it to\n * the index, it will then show up in search results.\n *\n * An 'add' event is emitted with the document that has been added and the index\n * the document has been added to. This event can be silenced by passing false\n * as the second argument to add.\n *\n * @param {Object} doc The JSON format document to add to the index.\n * @param {Boolean} emitEvent Whether or not to emit events, default true.\n * @memberOf Index\n */\nelasticlunr.Index.prototype.addDoc = function (doc, emitEvent) {\n  if (!doc) return;\n  var emitEvent = emitEvent === undefined ? true : emitEvent;\n\n  var docRef = doc[this._ref];\n\n  this.documentStore.addDoc(docRef, doc);\n  this._fields.forEach(function (field) {\n    var fieldTokens = this.pipeline.run(elasticlunr.tokenizer(doc[field]));\n    this.documentStore.addFieldLength(docRef, field, fieldTokens.length);\n\n    var tokenCount = {};\n    fieldTokens.forEach(function (token) {\n      if (token in tokenCount) tokenCount[token] += 1;\n      else tokenCount[token] = 1;\n    }, this);\n\n    for (var token in tokenCount) {\n      var termFrequency = tokenCount[token];\n      termFrequency = Math.sqrt(termFrequency);\n      this.index[field].addToken(token, { ref: docRef, tf: termFrequency });\n    }\n  }, this);\n\n  if (emitEvent) this.eventEmitter.emit('add', doc, this);\n};\n\n/**\n * Removes a document from the index by doc ref.\n *\n * To make sure documents no longer show up in search results they can be\n * removed from the index using this method.\n *\n * A 'remove' event is emitted with the document that has been removed and the index\n * the document has been removed from. This event can be silenced by passing false\n * as the second argument to remove.\n *\n * If user setting DocumentStore not storing the documents, then remove doc by docRef is not allowed.\n *\n * @param {String|Integer} docRef The document ref to remove from the index.\n * @param {Boolean} emitEvent Whether to emit remove events, defaults to true\n * @memberOf Index\n */\nelasticlunr.Index.prototype.removeDocByRef = function (docRef, emitEvent) {\n  if (!docRef) return;\n  if (this.documentStore.isDocStored() === false) {\n    return;\n  }\n\n  if (!this.documentStore.hasDoc(docRef)) return;\n  var doc = this.documentStore.getDoc(docRef);\n  this.removeDoc(doc, false);\n};\n\n/**\n * Removes a document from the index.\n * This remove operation could work even the original doc is not store in the DocumentStore.\n *\n * To make sure documents no longer show up in search results they can be\n * removed from the index using this method.\n *\n * A 'remove' event is emitted with the document that has been removed and the index\n * the document has been removed from. This event can be silenced by passing false\n * as the second argument to remove.\n *\n *\n * @param {Object} doc The document ref to remove from the index.\n * @param {Boolean} emitEvent Whether to emit remove events, defaults to true\n * @memberOf Index\n */\nelasticlunr.Index.prototype.removeDoc = function (doc, emitEvent) {\n  if (!doc) return;\n\n  var emitEvent = emitEvent === undefined ? true : emitEvent;\n\n  var docRef = doc[this._ref];\n  if (!this.documentStore.hasDoc(docRef)) return;\n\n  this.documentStore.removeDoc(docRef);\n\n  this._fields.forEach(function (field) {\n    var fieldTokens = this.pipeline.run(elasticlunr.tokenizer(doc[field]));\n    fieldTokens.forEach(function (token) {\n      this.index[field].removeToken(token, docRef);\n    }, this);\n  }, this);\n\n  if (emitEvent) this.eventEmitter.emit('remove', doc, this);\n};\n\n/**\n * Updates a document in the index.\n *\n * When a document contained within the index gets updated, fields changed,\n * added or removed, to make sure it correctly matched against search queries,\n * it should be updated in the index.\n *\n * This method is just a wrapper around `remove` and `add`\n *\n * An 'update' event is emitted with the document that has been updated and the index.\n * This event can be silenced by passing false as the second argument to update. Only\n * an update event will be fired, the 'add' and 'remove' events of the underlying calls\n * are silenced.\n *\n * @param {Object} doc The document to update in the index.\n * @param {Boolean} emitEvent Whether to emit update events, defaults to true\n * @see Index.prototype.remove\n * @see Index.prototype.add\n * @memberOf Index\n */\nelasticlunr.Index.prototype.updateDoc = function (doc, emitEvent) {\n  var emitEvent = emitEvent === undefined ? true : emitEvent;\n\n  this.removeDocByRef(doc[this._ref], false);\n  this.addDoc(doc, false);\n\n  if (emitEvent) this.eventEmitter.emit('update', doc, this);\n};\n\n/**\n * Calculates the inverse document frequency for a token within the index of a field.\n *\n * @param {String} token The token to calculate the idf of.\n * @param {String} field The field to compute idf.\n * @see Index.prototype.idf\n * @private\n * @memberOf Index\n */\nelasticlunr.Index.prototype.idf = function (term, field) {\n  var cacheKey = \"@\" + field + '/' + term;\n  if (Object.prototype.hasOwnProperty.call(this._idfCache, cacheKey)) return this._idfCache[cacheKey];\n\n  var df = this.index[field].getDocFreq(term);\n  var idf = 1 + Math.log(this.documentStore.length / (df + 1));\n  this._idfCache[cacheKey] = idf;\n\n  return idf;\n};\n\n/**\n * get fields of current index instance\n *\n * @return {Array}\n */\nelasticlunr.Index.prototype.getFields = function () {\n  return this._fields.slice();\n};\n\n/**\n * Searches the index using the passed query.\n * Queries should be a string, multiple words are allowed.\n *\n * If config is null, will search all fields defaultly, and lead to OR based query.\n * If config is specified, will search specified with query time boosting.\n *\n * All query tokens are passed through the same pipeline that document tokens\n * are passed through, so any language processing involved will be run on every\n * query term.\n *\n * Each query term is expanded, so that the term 'he' might be expanded to\n * 'hello' and 'help' if those terms were already included in the index.\n *\n * Matching documents are returned as an array of objects, each object contains\n * the matching document ref, as set for this index, and the similarity score\n * for this document against the query.\n *\n * @param {String} query The query to search the index with.\n * @param {JSON} userConfig The user query config, JSON format.\n * @return {Object}\n * @see Index.prototype.idf\n * @see Index.prototype.documentVector\n * @memberOf Index\n */\nelasticlunr.Index.prototype.search = function (query, userConfig) {\n  if (!query) return [];\n\n  var configStr = null;\n  if (userConfig != null) {\n    configStr = JSON.stringify(userConfig);\n  }\n\n  var config = new elasticlunr.Configuration(configStr, this.getFields()).get();\n\n  var queryTokens = this.pipeline.run(elasticlunr.tokenizer(query));\n\n  var queryResults = {};\n\n  for (var field in config) {\n    var fieldSearchResults = this.fieldSearch(queryTokens, field, config);\n    var fieldBoost = config[field].boost;\n\n    for (var docRef in fieldSearchResults) {\n      fieldSearchResults[docRef] = fieldSearchResults[docRef] * fieldBoost;\n    }\n\n    for (var docRef in fieldSearchResults) {\n      if (docRef in queryResults) {\n        queryResults[docRef] += fieldSearchResults[docRef];\n      } else {\n        queryResults[docRef] = fieldSearchResults[docRef];\n      }\n    }\n  }\n\n  var results = [];\n  for (var docRef in queryResults) {\n    results.push({ref: docRef, score: queryResults[docRef]});\n  }\n\n  results.sort(function (a, b) { return b.score - a.score; });\n  return results;\n};\n\n/**\n * search queryTokens in specified field.\n *\n * @param {Array} queryTokens The query tokens to query in this field.\n * @param {String} field Field to query in.\n * @param {elasticlunr.Configuration} config The user query config, JSON format.\n * @return {Object}\n */\nelasticlunr.Index.prototype.fieldSearch = function (queryTokens, fieldName, config) {\n  var booleanType = config[fieldName].bool;\n  var expand = config[fieldName].expand;\n  var boost = config[fieldName].boost;\n  var scores = null;\n  var docTokens = {};\n\n  // Do nothing if the boost is 0\n  if (boost === 0) {\n    return;\n  }\n\n  queryTokens.forEach(function (token) {\n    var tokens = [token];\n    if (expand == true) {\n      tokens = this.index[fieldName].expandToken(token);\n    }\n    // Consider every query token in turn. If expanded, each query token\n    // corresponds to a set of tokens, which is all tokens in the \n    // index matching the pattern queryToken* .\n    // For the set of tokens corresponding to a query token, find and score\n    // all matching documents. Store those scores in queryTokenScores, \n    // keyed by docRef.\n    // Then, depending on the value of booleanType, combine the scores\n    // for this query token with previous scores.  If booleanType is OR,\n    // then merge the scores by summing into the accumulated total, adding\n    // new document scores are required (effectively a union operator). \n    // If booleanType is AND, accumulate scores only if the document \n    // has previously been scored by another query token (an intersection\n    // operation0. \n    // Furthermore, since when booleanType is AND, additional \n    // query tokens can't add new documents to the result set, use the\n    // current document set to limit the processing of each new query \n    // token for efficiency (i.e., incremental intersection).\n    \n    var queryTokenScores = {};\n    tokens.forEach(function (key) {\n      var docs = this.index[fieldName].getDocs(key);\n      var idf = this.idf(key, fieldName);\n      \n      if (scores && booleanType == 'AND') {\n          // special case, we can rule out documents that have been\n          // already been filtered out because they weren't scored\n          // by previous query token passes.\n          var filteredDocs = {};\n          for (var docRef in scores) {\n              if (docRef in docs) {\n                  filteredDocs[docRef] = docs[docRef];\n              }\n          }\n          docs = filteredDocs;\n      }\n      // only record appeared token for retrieved documents for the\n      // original token, not for expaned token.\n      // beause for doing coordNorm for a retrieved document, coordNorm only care how many\n      // query token appear in that document.\n      // so expanded token should not be added into docTokens, if added, this will pollute the\n      // coordNorm\n      if (key == token) {\n        this.fieldSearchStats(docTokens, key, docs);\n      }\n\n      for (var docRef in docs) {\n        var tf = this.index[fieldName].getTermFrequency(key, docRef);\n        var fieldLength = this.documentStore.getFieldLength(docRef, fieldName);\n        var fieldLengthNorm = 1;\n        if (fieldLength != 0) {\n          fieldLengthNorm = 1 / Math.sqrt(fieldLength);\n        }\n\n        var penality = 1;\n        if (key != token) {\n          // currently I'm not sure if this penality is enough,\n          // need to do verification\n          penality = (1 - (key.length - token.length) / key.length) * 0.15;\n        }\n\n        var score = tf * idf * fieldLengthNorm * penality;\n\n        if (docRef in queryTokenScores) {\n          queryTokenScores[docRef] += score;\n        } else {\n          queryTokenScores[docRef] = score;\n        }\n      }\n    }, this);\n    \n    scores = this.mergeScores(scores, queryTokenScores, booleanType);\n  }, this);\n\n  scores = this.coordNorm(scores, docTokens, queryTokens.length);\n  return scores;\n};\n\n/**\n * Merge the scores from one set of tokens into an accumulated score table.\n * Exact operation depends on the op parameter. If op is 'AND', then only the\n * intersection of the two score lists is retained. Otherwise, the union of\n * the two score lists is returned. For internal use only.\n *\n * @param {Object} bool accumulated scores. Should be null on first call.\n * @param {String} scores new scores to merge into accumScores.\n * @param {Object} op merge operation (should be 'AND' or 'OR').\n *\n */\n\nelasticlunr.Index.prototype.mergeScores = function (accumScores, scores, op) {\n    if (!accumScores) {\n        return scores; \n    }\n    if (op == 'AND') {\n        var intersection = {};\n        for (var docRef in scores) {\n            if (docRef in accumScores) {\n                intersection[docRef] = accumScores[docRef] + scores[docRef];\n            }\n        }\n        return intersection;\n    } else {\n        for (var docRef in scores) {\n            if (docRef in accumScores) {\n                accumScores[docRef] += scores[docRef];\n            } else {\n                accumScores[docRef] = scores[docRef];\n            }\n        }\n        return accumScores;\n    }\n};\n\n\n/**\n * Record the occuring query token of retrieved doc specified by doc field.\n * Only for inner user.\n *\n * @param {Object} docTokens a data structure stores which token appears in the retrieved doc.\n * @param {String} token query token\n * @param {Object} docs the retrieved documents of the query token\n *\n */\nelasticlunr.Index.prototype.fieldSearchStats = function (docTokens, token, docs) {\n  for (var doc in docs) {\n    if (doc in docTokens) {\n      docTokens[doc].push(token);\n    } else {\n      docTokens[doc] = [token];\n    }\n  }\n};\n\n/**\n * coord norm the score of a doc.\n * if a doc contain more query tokens, then the score will larger than the doc\n * contains less query tokens.\n *\n * only for inner use.\n *\n * @param {Object} results first results\n * @param {Object} docs field search results of a token\n * @param {Integer} n query token number\n * @return {Object}\n */\nelasticlunr.Index.prototype.coordNorm = function (scores, docTokens, n) {\n  for (var doc in scores) {\n    if (!(doc in docTokens)) continue;\n    var tokens = docTokens[doc].length;\n    scores[doc] = scores[doc] * tokens / n;\n  }\n\n  return scores;\n};\n\n/**\n * Returns a representation of the index ready for serialisation.\n *\n * @return {Object}\n * @memberOf Index\n */\nelasticlunr.Index.prototype.toJSON = function () {\n  var indexJson = {};\n  this._fields.forEach(function (field) {\n    indexJson[field] = this.index[field].toJSON();\n  }, this);\n\n  return {\n    version: elasticlunr.version,\n    fields: this._fields,\n    ref: this._ref,\n    documentStore: this.documentStore.toJSON(),\n    index: indexJson,\n    pipeline: this.pipeline.toJSON()\n  };\n};\n\n/**\n * Applies a plugin to the current index.\n *\n * A plugin is a function that is called with the index as its context.\n * Plugins can be used to customise or extend the behaviour the index\n * in some way. A plugin is just a function, that encapsulated the custom\n * behaviour that should be applied to the index.\n *\n * The plugin function will be called with the index as its argument, additional\n * arguments can also be passed when calling use. The function will be called\n * with the index as its context.\n *\n * Example:\n *\n *     var myPlugin = function (idx, arg1, arg2) {\n *       // `this` is the index to be extended\n *       // apply any extensions etc here.\n *     }\n *\n *     var idx = elasticlunr(function () {\n *       this.use(myPlugin, 'arg1', 'arg2')\n *     })\n *\n * @param {Function} plugin The plugin to apply.\n * @memberOf Index\n */\nelasticlunr.Index.prototype.use = function (plugin) {\n  var args = Array.prototype.slice.call(arguments, 1);\n  args.unshift(this);\n  plugin.apply(this, args);\n};\n/*!\n * elasticlunr.DocumentStore\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * elasticlunr.DocumentStore is a simple key-value document store used for storing sets of tokens for\n * documents stored in index.\n *\n * elasticlunr.DocumentStore store original JSON format documents that you could build search snippet by this original JSON document.\n *\n * user could choose whether original JSON format document should be store, if no configuration then document will be stored defaultly.\n * If user care more about the index size, user could select not store JSON documents, then this will has some defects, such as user\n * could not use JSON document to generate snippets of search results.\n *\n * @param {Boolean} save If the original JSON document should be stored.\n * @constructor\n * @module\n */\nelasticlunr.DocumentStore = function (save) {\n  if (save === null || save === undefined) {\n    this._save = true;\n  } else {\n    this._save = save;\n  }\n\n  this.docs = {};\n  this.docInfo = {};\n  this.length = 0;\n};\n\n/**\n * Loads a previously serialised document store\n *\n * @param {Object} serialisedData The serialised document store to load.\n * @return {elasticlunr.DocumentStore}\n */\nelasticlunr.DocumentStore.load = function (serialisedData) {\n  var store = new this;\n\n  store.length = serialisedData.length;\n  store.docs = serialisedData.docs;\n  store.docInfo = serialisedData.docInfo;\n  store._save = serialisedData.save;\n\n  return store;\n};\n\n/**\n * check if current instance store the original doc\n *\n * @return {Boolean}\n */\nelasticlunr.DocumentStore.prototype.isDocStored = function () {\n  return this._save;\n};\n\n/**\n * Stores the given doc in the document store against the given id.\n * If docRef already exist, then update doc.\n *\n * Document is store by original JSON format, then you could use original document to generate search snippets.\n *\n * @param {Integer|String} docRef The key used to store the JSON format doc.\n * @param {Object} doc The JSON format doc.\n */\nelasticlunr.DocumentStore.prototype.addDoc = function (docRef, doc) {\n  if (!this.hasDoc(docRef)) this.length++;\n\n  if (this._save === true) {\n    this.docs[docRef] = clone(doc);\n  } else {\n    this.docs[docRef] = null;\n  }\n};\n\n/**\n * Retrieves the JSON doc from the document store for a given key.\n *\n * If docRef not found, return null.\n * If user set not storing the documents, return null.\n *\n * @param {Integer|String} docRef The key to lookup and retrieve from the document store.\n * @return {Object}\n * @memberOf DocumentStore\n */\nelasticlunr.DocumentStore.prototype.getDoc = function (docRef) {\n  if (this.hasDoc(docRef) === false) return null;\n  return this.docs[docRef];\n};\n\n/**\n * Checks whether the document store contains a key (docRef).\n *\n * @param {Integer|String} docRef The id to look up in the document store.\n * @return {Boolean}\n * @memberOf DocumentStore\n */\nelasticlunr.DocumentStore.prototype.hasDoc = function (docRef) {\n  return docRef in this.docs;\n};\n\n/**\n * Removes the value for a key in the document store.\n *\n * @param {Integer|String} docRef The id to remove from the document store.\n * @memberOf DocumentStore\n */\nelasticlunr.DocumentStore.prototype.removeDoc = function (docRef) {\n  if (!this.hasDoc(docRef)) return;\n\n  delete this.docs[docRef];\n  delete this.docInfo[docRef];\n  this.length--;\n};\n\n/**\n * Add field length of a document's field tokens from pipeline results.\n * The field length of a document is used to do field length normalization even without the original JSON document stored.\n *\n * @param {Integer|String} docRef document's id or reference\n * @param {String} fieldName field name\n * @param {Integer} length field length\n */\nelasticlunr.DocumentStore.prototype.addFieldLength = function (docRef, fieldName, length) {\n  if (docRef === null || docRef === undefined) return;\n  if (this.hasDoc(docRef) == false) return;\n\n  if (!this.docInfo[docRef]) this.docInfo[docRef] = {};\n  this.docInfo[docRef][fieldName] = length;\n};\n\n/**\n * Update field length of a document's field tokens from pipeline results.\n * The field length of a document is used to do field length normalization even without the original JSON document stored.\n *\n * @param {Integer|String} docRef document's id or reference\n * @param {String} fieldName field name\n * @param {Integer} length field length\n */\nelasticlunr.DocumentStore.prototype.updateFieldLength = function (docRef, fieldName, length) {\n  if (docRef === null || docRef === undefined) return;\n  if (this.hasDoc(docRef) == false) return;\n\n  this.addFieldLength(docRef, fieldName, length);\n};\n\n/**\n * get field length of a document by docRef\n *\n * @param {Integer|String} docRef document id or reference\n * @param {String} fieldName field name\n * @return {Integer} field length\n */\nelasticlunr.DocumentStore.prototype.getFieldLength = function (docRef, fieldName) {\n  if (docRef === null || docRef === undefined) return 0;\n\n  if (!(docRef in this.docs)) return 0;\n  if (!(fieldName in this.docInfo[docRef])) return 0;\n  return this.docInfo[docRef][fieldName];\n};\n\n/**\n * Returns a JSON representation of the document store used for serialisation.\n *\n * @return {Object} JSON format\n * @memberOf DocumentStore\n */\nelasticlunr.DocumentStore.prototype.toJSON = function () {\n  return {\n    docs: this.docs,\n    docInfo: this.docInfo,\n    length: this.length,\n    save: this._save\n  };\n};\n\n/**\n * Cloning object\n *\n * @param {Object} object in JSON format\n * @return {Object} copied object\n */\nfunction clone(obj) {\n  if (null === obj || \"object\" !== typeof obj) return obj;\n\n  var copy = obj.constructor();\n\n  for (var attr in obj) {\n    if (obj.hasOwnProperty(attr)) copy[attr] = obj[attr];\n  }\n\n  return copy;\n}\n/*!\n * elasticlunr.stemmer\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n * Includes code from - http://tartarus.org/~martin/PorterStemmer/js.txt\n */\n\n/**\n * elasticlunr.stemmer is an english language stemmer, this is a JavaScript\n * implementation of the PorterStemmer taken from http://tartarus.org/~martin\n *\n * @module\n * @param {String} str The string to stem\n * @return {String}\n * @see elasticlunr.Pipeline\n */\nelasticlunr.stemmer = (function(){\n  var step2list = {\n      \"ational\" : \"ate\",\n      \"tional\" : \"tion\",\n      \"enci\" : \"ence\",\n      \"anci\" : \"ance\",\n      \"izer\" : \"ize\",\n      \"bli\" : \"ble\",\n      \"alli\" : \"al\",\n      \"entli\" : \"ent\",\n      \"eli\" : \"e\",\n      \"ousli\" : \"ous\",\n      \"ization\" : \"ize\",\n      \"ation\" : \"ate\",\n      \"ator\" : \"ate\",\n      \"alism\" : \"al\",\n      \"iveness\" : \"ive\",\n      \"fulness\" : \"ful\",\n      \"ousness\" : \"ous\",\n      \"aliti\" : \"al\",\n      \"iviti\" : \"ive\",\n      \"biliti\" : \"ble\",\n      \"logi\" : \"log\"\n    },\n\n    step3list = {\n      \"icate\" : \"ic\",\n      \"ative\" : \"\",\n      \"alize\" : \"al\",\n      \"iciti\" : \"ic\",\n      \"ical\" : \"ic\",\n      \"ful\" : \"\",\n      \"ness\" : \"\"\n    },\n\n    c = \"[^aeiou]\",          // consonant\n    v = \"[aeiouy]\",          // vowel\n    C = c + \"[^aeiouy]*\",    // consonant sequence\n    V = v + \"[aeiou]*\",      // vowel sequence\n\n    mgr0 = \"^(\" + C + \")?\" + V + C,               // [C]VC... is m>0\n    meq1 = \"^(\" + C + \")?\" + V + C + \"(\" + V + \")?$\",  // [C]VC[V] is m=1\n    mgr1 = \"^(\" + C + \")?\" + V + C + V + C,       // [C]VCVC... is m>1\n    s_v = \"^(\" + C + \")?\" + v;                   // vowel in stem\n\n  var re_mgr0 = new RegExp(mgr0);\n  var re_mgr1 = new RegExp(mgr1);\n  var re_meq1 = new RegExp(meq1);\n  var re_s_v = new RegExp(s_v);\n\n  var re_1a = /^(.+?)(ss|i)es$/;\n  var re2_1a = /^(.+?)([^s])s$/;\n  var re_1b = /^(.+?)eed$/;\n  var re2_1b = /^(.+?)(ed|ing)$/;\n  var re_1b_2 = /.$/;\n  var re2_1b_2 = /(at|bl|iz)$/;\n  var re3_1b_2 = new RegExp(\"([^aeiouylsz])\\\\1$\");\n  var re4_1b_2 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n\n  var re_1c = /^(.+?[^aeiou])y$/;\n  var re_2 = /^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/;\n\n  var re_3 = /^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/;\n\n  var re_4 = /^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/;\n  var re2_4 = /^(.+?)(s|t)(ion)$/;\n\n  var re_5 = /^(.+?)e$/;\n  var re_5_1 = /ll$/;\n  var re3_5 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n\n  var porterStemmer = function porterStemmer(w) {\n    var   stem,\n      suffix,\n      firstch,\n      re,\n      re2,\n      re3,\n      re4;\n\n    if (w.length < 3) { return w; }\n\n    firstch = w.substr(0,1);\n    if (firstch == \"y\") {\n      w = firstch.toUpperCase() + w.substr(1);\n    }\n\n    // Step 1a\n    re = re_1a\n    re2 = re2_1a;\n\n    if (re.test(w)) { w = w.replace(re,\"$1$2\"); }\n    else if (re2.test(w)) { w = w.replace(re2,\"$1$2\"); }\n\n    // Step 1b\n    re = re_1b;\n    re2 = re2_1b;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      re = re_mgr0;\n      if (re.test(fp[1])) {\n        re = re_1b_2;\n        w = w.replace(re,\"\");\n      }\n    } else if (re2.test(w)) {\n      var fp = re2.exec(w);\n      stem = fp[1];\n      re2 = re_s_v;\n      if (re2.test(stem)) {\n        w = stem;\n        re2 = re2_1b_2;\n        re3 = re3_1b_2;\n        re4 = re4_1b_2;\n        if (re2.test(w)) {  w = w + \"e\"; }\n        else if (re3.test(w)) { re = re_1b_2; w = w.replace(re,\"\"); }\n        else if (re4.test(w)) { w = w + \"e\"; }\n      }\n    }\n\n    // Step 1c - replace suffix y or Y by i if preceded by a non-vowel which is not the first letter of the word (so cry -> cri, by -> by, say -> say)\n    re = re_1c;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      stem = fp[1];\n      w = stem + \"i\";\n    }\n\n    // Step 2\n    re = re_2;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      stem = fp[1];\n      suffix = fp[2];\n      re = re_mgr0;\n      if (re.test(stem)) {\n        w = stem + step2list[suffix];\n      }\n    }\n\n    // Step 3\n    re = re_3;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      stem = fp[1];\n      suffix = fp[2];\n      re = re_mgr0;\n      if (re.test(stem)) {\n        w = stem + step3list[suffix];\n      }\n    }\n\n    // Step 4\n    re = re_4;\n    re2 = re2_4;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      stem = fp[1];\n      re = re_mgr1;\n      if (re.test(stem)) {\n        w = stem;\n      }\n    } else if (re2.test(w)) {\n      var fp = re2.exec(w);\n      stem = fp[1] + fp[2];\n      re2 = re_mgr1;\n      if (re2.test(stem)) {\n        w = stem;\n      }\n    }\n\n    // Step 5\n    re = re_5;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      stem = fp[1];\n      re = re_mgr1;\n      re2 = re_meq1;\n      re3 = re3_5;\n      if (re.test(stem) || (re2.test(stem) && !(re3.test(stem)))) {\n        w = stem;\n      }\n    }\n\n    re = re_5_1;\n    re2 = re_mgr1;\n    if (re.test(w) && re2.test(w)) {\n      re = re_1b_2;\n      w = w.replace(re,\"\");\n    }\n\n    // and turn initial Y back to y\n\n    if (firstch == \"y\") {\n      w = firstch.toLowerCase() + w.substr(1);\n    }\n\n    return w;\n  };\n\n  return porterStemmer;\n})();\n\nelasticlunr.Pipeline.registerFunction(elasticlunr.stemmer, 'stemmer');\n/*!\n * elasticlunr.stopWordFilter\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * elasticlunr.stopWordFilter is an English language stop words filter, any words\n * contained in the stop word list will not be passed through the filter.\n *\n * This is intended to be used in the Pipeline. If the token does not pass the\n * filter then undefined will be returned.\n * Currently this StopwordFilter using dictionary to do O(1) time complexity stop word filtering.\n *\n * @module\n * @param {String} token The token to pass through the filter\n * @return {String}\n * @see elasticlunr.Pipeline\n */\nelasticlunr.stopWordFilter = function (token) {\n  if (token && elasticlunr.stopWordFilter.stopWords[token] !== true) {\n    return token;\n  }\n};\n\n/**\n * Remove predefined stop words\n * if user want to use customized stop words, user could use this function to delete\n * all predefined stopwords.\n *\n * @return {null}\n */\nelasticlunr.clearStopWords = function () {\n  elasticlunr.stopWordFilter.stopWords = {};\n};\n\n/**\n * Add customized stop words\n * user could use this function to add customized stop words\n * \n * @params {Array} words customized stop words\n * @return {null}\n */\nelasticlunr.addStopWords = function (words) {\n  if (words == null || Array.isArray(words) === false) return;\n\n  words.forEach(function (word) {\n    elasticlunr.stopWordFilter.stopWords[word] = true;\n  }, this);\n};\n\n/**\n * Reset to default stop words\n * user could use this function to restore default stop words\n *\n * @return {null}\n */\nelasticlunr.resetStopWords = function () {\n  elasticlunr.stopWordFilter.stopWords = elasticlunr.defaultStopWords;\n};\n\nelasticlunr.defaultStopWords = {\n  \"\": true,\n  \"a\": true,\n  \"able\": true,\n  \"about\": true,\n  \"across\": true,\n  \"after\": true,\n  \"all\": true,\n  \"almost\": true,\n  \"also\": true,\n  \"am\": true,\n  \"among\": true,\n  \"an\": true,\n  \"and\": true,\n  \"any\": true,\n  \"are\": true,\n  \"as\": true,\n  \"at\": true,\n  \"be\": true,\n  \"because\": true,\n  \"been\": true,\n  \"but\": true,\n  \"by\": true,\n  \"can\": true,\n  \"cannot\": true,\n  \"could\": true,\n  \"dear\": true,\n  \"did\": true,\n  \"do\": true,\n  \"does\": true,\n  \"either\": true,\n  \"else\": true,\n  \"ever\": true,\n  \"every\": true,\n  \"for\": true,\n  \"from\": true,\n  \"get\": true,\n  \"got\": true,\n  \"had\": true,\n  \"has\": true,\n  \"have\": true,\n  \"he\": true,\n  \"her\": true,\n  \"hers\": true,\n  \"him\": true,\n  \"his\": true,\n  \"how\": true,\n  \"however\": true,\n  \"i\": true,\n  \"if\": true,\n  \"in\": true,\n  \"into\": true,\n  \"is\": true,\n  \"it\": true,\n  \"its\": true,\n  \"just\": true,\n  \"least\": true,\n  \"let\": true,\n  \"like\": true,\n  \"likely\": true,\n  \"may\": true,\n  \"me\": true,\n  \"might\": true,\n  \"most\": true,\n  \"must\": true,\n  \"my\": true,\n  \"neither\": true,\n  \"no\": true,\n  \"nor\": true,\n  \"not\": true,\n  \"of\": true,\n  \"off\": true,\n  \"often\": true,\n  \"on\": true,\n  \"only\": true,\n  \"or\": true,\n  \"other\": true,\n  \"our\": true,\n  \"own\": true,\n  \"rather\": true,\n  \"said\": true,\n  \"say\": true,\n  \"says\": true,\n  \"she\": true,\n  \"should\": true,\n  \"since\": true,\n  \"so\": true,\n  \"some\": true,\n  \"than\": true,\n  \"that\": true,\n  \"the\": true,\n  \"their\": true,\n  \"them\": true,\n  \"then\": true,\n  \"there\": true,\n  \"these\": true,\n  \"they\": true,\n  \"this\": true,\n  \"tis\": true,\n  \"to\": true,\n  \"too\": true,\n  \"twas\": true,\n  \"us\": true,\n  \"wants\": true,\n  \"was\": true,\n  \"we\": true,\n  \"were\": true,\n  \"what\": true,\n  \"when\": true,\n  \"where\": true,\n  \"which\": true,\n  \"while\": true,\n  \"who\": true,\n  \"whom\": true,\n  \"why\": true,\n  \"will\": true,\n  \"with\": true,\n  \"would\": true,\n  \"yet\": true,\n  \"you\": true,\n  \"your\": true\n};\n\nelasticlunr.stopWordFilter.stopWords = elasticlunr.defaultStopWords;\n\nelasticlunr.Pipeline.registerFunction(elasticlunr.stopWordFilter, 'stopWordFilter');\n/*!\n * elasticlunr.trimmer\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * elasticlunr.trimmer is a pipeline function for trimming non word\n * characters from the begining and end of tokens before they\n * enter the index.\n *\n * This implementation may not work correctly for non latin\n * characters and should either be removed or adapted for use\n * with languages with non-latin characters.\n *\n * @module\n * @param {String} token The token to pass through the filter\n * @return {String}\n * @see elasticlunr.Pipeline\n */\nelasticlunr.trimmer = function (token) {\n  if (token === null || token === undefined) {\n    throw new Error('token should not be undefined');\n  }\n\n  return token\n    .replace(/^\\W+/, '')\n    .replace(/\\W+$/, '');\n};\n\nelasticlunr.Pipeline.registerFunction(elasticlunr.trimmer, 'trimmer');\n/*!\n * elasticlunr.InvertedIndex\n * Copyright (C) 2016 Wei Song\n * Includes code from - http://tartarus.org/~martin/PorterStemmer/js.txt\n */\n\n/**\n * elasticlunr.InvertedIndex is used for efficiently storing and\n * lookup of documents that contain a given token.\n *\n * @constructor\n */\nelasticlunr.InvertedIndex = function () {\n  this.root = { docs: {}, df: 0 };\n};\n\n/**\n * Loads a previously serialised inverted index.\n *\n * @param {Object} serialisedData The serialised inverted index to load.\n * @return {elasticlunr.InvertedIndex}\n */\nelasticlunr.InvertedIndex.load = function (serialisedData) {\n  var idx = new this;\n  idx.root = serialisedData.root;\n\n  return idx;\n};\n\n/**\n * Adds a {token: tokenInfo} pair to the inverted index.\n * If the token already exist, then update the tokenInfo.\n *\n * tokenInfo format: { ref: 1, tf: 2}\n * tokenInfor should contains the document's ref and the tf(token frequency) of that token in\n * the document.\n *\n * By default this function starts at the root of the current inverted index, however\n * it can start at any node of the inverted index if required.\n *\n * @param {String} token \n * @param {Object} tokenInfo format: { ref: 1, tf: 2}\n * @param {Object} root An optional node at which to start looking for the\n * correct place to enter the doc, by default the root of this elasticlunr.InvertedIndex\n * is used.\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.addToken = function (token, tokenInfo, root) {\n  var root = root || this.root,\n      idx = 0;\n\n  while (idx <= token.length - 1) {\n    var key = token[idx];\n\n    if (!(key in root)) root[key] = {docs: {}, df: 0};\n    idx += 1;\n    root = root[key];\n  }\n\n  var docRef = tokenInfo.ref;\n  if (!root.docs[docRef]) {\n    // if this doc not exist, then add this doc\n    root.docs[docRef] = {tf: tokenInfo.tf};\n    root.df += 1;\n  } else {\n    // if this doc already exist, then update tokenInfo\n    root.docs[docRef] = {tf: tokenInfo.tf};\n  }\n};\n\n/**\n * Checks whether a token is in this elasticlunr.InvertedIndex.\n * \n *\n * @param {String} token The token to be checked\n * @return {Boolean}\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.hasToken = function (token) {\n  if (!token) return false;\n\n  var node = this.root;\n\n  for (var i = 0; i < token.length; i++) {\n    if (!node[token[i]]) return false;\n    node = node[token[i]];\n  }\n\n  return true;\n};\n\n/**\n * Retrieve a node from the inverted index for a given token.\n * If token not found in this InvertedIndex, return null.\n * \n *\n * @param {String} token The token to get the node for.\n * @return {Object}\n * @see InvertedIndex.prototype.get\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.getNode = function (token) {\n  if (!token) return null;\n\n  var node = this.root;\n\n  for (var i = 0; i < token.length; i++) {\n    if (!node[token[i]]) return null;\n    node = node[token[i]];\n  }\n\n  return node;\n};\n\n/**\n * Retrieve the documents of a given token.\n * If token not found, return {}.\n *\n *\n * @param {String} token The token to get the documents for.\n * @return {Object}\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.getDocs = function (token) {\n  var node = this.getNode(token);\n  if (node == null) {\n    return {};\n  }\n\n  return node.docs;\n};\n\n/**\n * Retrieve term frequency of given token in given docRef.\n * If token or docRef not found, return 0.\n *\n *\n * @param {String} token The token to get the documents for.\n * @param {String|Integer} docRef\n * @return {Integer}\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.getTermFrequency = function (token, docRef) {\n  var node = this.getNode(token);\n\n  if (node == null) {\n    return 0;\n  }\n\n  if (!(docRef in node.docs)) {\n    return 0;\n  }\n\n  return node.docs[docRef].tf;\n};\n\n/**\n * Retrieve the document frequency of given token.\n * If token not found, return 0.\n *\n *\n * @param {String} token The token to get the documents for.\n * @return {Object}\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.getDocFreq = function (token) {\n  var node = this.getNode(token);\n\n  if (node == null) {\n    return 0;\n  }\n\n  return node.df;\n};\n\n/**\n * Remove the document identified by document's ref from the token in the inverted index.\n *\n *\n * @param {String} token Remove the document from which token.\n * @param {String} ref The ref of the document to remove from given token.\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.removeToken = function (token, ref) {\n  if (!token) return;\n  var node = this.getNode(token);\n\n  if (node == null) return;\n\n  if (ref in node.docs) {\n    delete node.docs[ref];\n    node.df -= 1;\n  }\n};\n\n/**\n * Find all the possible suffixes of given token using tokens currently in the inverted index.\n * If token not found, return empty Array.\n *\n * @param {String} token The token to expand.\n * @return {Array}\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.expandToken = function (token, memo, root) {\n  if (token == null || token == '') return [];\n  var memo = memo || [];\n\n  if (root == void 0) {\n    root = this.getNode(token);\n    if (root == null) return memo;\n  }\n\n  if (root.df > 0) memo.push(token);\n\n  for (var key in root) {\n    if (key === 'docs') continue;\n    if (key === 'df') continue;\n    this.expandToken(token + key, memo, root[key]);\n  }\n\n  return memo;\n};\n\n/**\n * Returns a representation of the inverted index ready for serialisation.\n *\n * @return {Object}\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.toJSON = function () {\n  return {\n    root: this.root\n  };\n};\n\n/*!\n * elasticlunr.Configuration\n * Copyright (C) 2016 Wei Song\n */\n \n /** \n  * elasticlunr.Configuration is used to analyze the user search configuration.\n  * \n  * By elasticlunr.Configuration user could set query-time boosting, boolean model in each field.\n  * \n  * Currently configuration supports:\n  * 1. query-time boosting, user could set how to boost each field.\n  * 2. boolean model chosing, user could choose which boolean model to use for each field.\n  * 3. token expandation, user could set token expand to True to improve Recall. Default is False.\n  * \n  * Query time boosting must be configured by field category, \"boolean\" model could be configured \n  * by both field category or globally as the following example. Field configuration for \"boolean\"\n  * will overwrite global configuration.\n  * Token expand could be configured both by field category or golbally. Local field configuration will\n  * overwrite global configuration.\n  * \n  * configuration example:\n  * {\n  *   fields:{ \n  *     title: {boost: 2},\n  *     body: {boost: 1}\n  *   },\n  *   bool: \"OR\"\n  * }\n  * \n  * \"bool\" field configuation overwrite global configuation example:\n  * {\n  *   fields:{ \n  *     title: {boost: 2, bool: \"AND\"},\n  *     body: {boost: 1}\n  *   },\n  *   bool: \"OR\"\n  * }\n  * \n  * \"expand\" example:\n  * {\n  *   fields:{ \n  *     title: {boost: 2, bool: \"AND\"},\n  *     body: {boost: 1}\n  *   },\n  *   bool: \"OR\",\n  *   expand: true\n  * }\n  * \n  * \"expand\" example for field category:\n  * {\n  *   fields:{ \n  *     title: {boost: 2, bool: \"AND\", expand: true},\n  *     body: {boost: 1}\n  *   },\n  *   bool: \"OR\"\n  * }\n  * \n  * setting the boost to 0 ignores the field (this will only search the title):\n  * {\n  *   fields:{\n  *     title: {boost: 1},\n  *     body: {boost: 0}\n  *   }\n  * }\n  *\n  * then, user could search with configuration to do query-time boosting.\n  * idx.search('oracle database', {fields: {title: {boost: 2}, body: {boost: 1}}});\n  * \n  * \n  * @constructor\n  * \n  * @param {String} config user configuration\n  * @param {Array} fields fields of index instance\n  * @module\n  */\nelasticlunr.Configuration = function (config, fields) {\n  var config = config || '';\n\n  if (fields == undefined || fields == null) {\n    throw new Error('fields should not be null');\n  }\n\n  this.config = {};\n\n  var userConfig;\n  try {\n    userConfig = JSON.parse(config);\n    this.buildUserConfig(userConfig, fields);\n  } catch (error) {\n    elasticlunr.utils.warn('user configuration parse failed, will use default configuration');\n    this.buildDefaultConfig(fields);\n  }\n};\n\n/**\n * Build default search configuration.\n * \n * @param {Array} fields fields of index instance\n */\nelasticlunr.Configuration.prototype.buildDefaultConfig = function (fields) {\n  this.reset();\n  fields.forEach(function (field) {\n    this.config[field] = {\n      boost: 1,\n      bool: \"OR\",\n      expand: false\n    };\n  }, this);\n};\n\n/**\n * Build user configuration.\n * \n * @param {JSON} config User JSON configuratoin\n * @param {Array} fields fields of index instance\n */\nelasticlunr.Configuration.prototype.buildUserConfig = function (config, fields) {\n  var global_bool = \"OR\";\n  var global_expand = false;\n\n  this.reset();\n  if ('bool' in config) {\n    global_bool = config['bool'] || global_bool;\n  }\n\n  if ('expand' in config) {\n    global_expand = config['expand'] || global_expand;\n  }\n\n  if ('fields' in config) {\n    for (var field in config['fields']) {\n      if (fields.indexOf(field) > -1) {\n        var field_config = config['fields'][field];\n        var field_expand = global_expand;\n        if (field_config.expand != undefined) {\n          field_expand = field_config.expand;\n        }\n\n        this.config[field] = {\n          boost: (field_config.boost || field_config.boost === 0) ? field_config.boost : 1,\n          bool: field_config.bool || global_bool,\n          expand: field_expand\n        };\n      } else {\n        elasticlunr.utils.warn('field name in user configuration not found in index instance fields');\n      }\n    }\n  } else {\n    this.addAllFields2UserConfig(global_bool, global_expand, fields);\n  }\n};\n\n/**\n * Add all fields to user search configuration.\n * \n * @param {String} bool Boolean model\n * @param {String} expand Expand model\n * @param {Array} fields fields of index instance\n */\nelasticlunr.Configuration.prototype.addAllFields2UserConfig = function (bool, expand, fields) {\n  fields.forEach(function (field) {\n    this.config[field] = {\n      boost: 1,\n      bool: bool,\n      expand: expand\n    };\n  }, this);\n};\n\n/**\n * get current user configuration\n */\nelasticlunr.Configuration.prototype.get = function () {\n  return this.config;\n};\n\n/**\n * reset user search configuration.\n */\nelasticlunr.Configuration.prototype.reset = function () {\n  this.config = {};\n};\n/**\n * sorted_set.js is added only to make elasticlunr.js compatible with lunr-languages.\n * if elasticlunr.js support different languages by default, this will make elasticlunr.js\n * much bigger that not good for browser usage.\n *\n */\n\n\n/*!\n * lunr.SortedSet\n * Copyright (C) 2016 Oliver Nightingale\n */\n\n/**\n * lunr.SortedSets are used to maintain an array of uniq values in a sorted\n * order.\n *\n * @constructor\n */\nlunr.SortedSet = function () {\n  this.length = 0\n  this.elements = []\n}\n\n/**\n * Loads a previously serialised sorted set.\n *\n * @param {Array} serialisedData The serialised set to load.\n * @returns {lunr.SortedSet}\n * @memberOf SortedSet\n */\nlunr.SortedSet.load = function (serialisedData) {\n  var set = new this\n\n  set.elements = serialisedData\n  set.length = serialisedData.length\n\n  return set\n}\n\n/**\n * Inserts new items into the set in the correct position to maintain the\n * order.\n *\n * @param {Object} The objects to add to this set.\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.add = function () {\n  var i, element\n\n  for (i = 0; i < arguments.length; i++) {\n    element = arguments[i]\n    if (~this.indexOf(element)) continue\n    this.elements.splice(this.locationFor(element), 0, element)\n  }\n\n  this.length = this.elements.length\n}\n\n/**\n * Converts this sorted set into an array.\n *\n * @returns {Array}\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.toArray = function () {\n  return this.elements.slice()\n}\n\n/**\n * Creates a new array with the results of calling a provided function on every\n * element in this sorted set.\n *\n * Delegates to Array.prototype.map and has the same signature.\n *\n * @param {Function} fn The function that is called on each element of the\n * set.\n * @param {Object} ctx An optional object that can be used as the context\n * for the function fn.\n * @returns {Array}\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.map = function (fn, ctx) {\n  return this.elements.map(fn, ctx)\n}\n\n/**\n * Executes a provided function once per sorted set element.\n *\n * Delegates to Array.prototype.forEach and has the same signature.\n *\n * @param {Function} fn The function that is called on each element of the\n * set.\n * @param {Object} ctx An optional object that can be used as the context\n * @memberOf SortedSet\n * for the function fn.\n */\nlunr.SortedSet.prototype.forEach = function (fn, ctx) {\n  return this.elements.forEach(fn, ctx)\n}\n\n/**\n * Returns the index at which a given element can be found in the\n * sorted set, or -1 if it is not present.\n *\n * @param {Object} elem The object to locate in the sorted set.\n * @returns {Number}\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.indexOf = function (elem) {\n  var start = 0,\n      end = this.elements.length,\n      sectionLength = end - start,\n      pivot = start + Math.floor(sectionLength / 2),\n      pivotElem = this.elements[pivot]\n\n  while (sectionLength > 1) {\n    if (pivotElem === elem) return pivot\n\n    if (pivotElem < elem) start = pivot\n    if (pivotElem > elem) end = pivot\n\n    sectionLength = end - start\n    pivot = start + Math.floor(sectionLength / 2)\n    pivotElem = this.elements[pivot]\n  }\n\n  if (pivotElem === elem) return pivot\n\n  return -1\n}\n\n/**\n * Returns the position within the sorted set that an element should be\n * inserted at to maintain the current order of the set.\n *\n * This function assumes that the element to search for does not already exist\n * in the sorted set.\n *\n * @param {Object} elem The elem to find the position for in the set\n * @returns {Number}\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.locationFor = function (elem) {\n  var start = 0,\n      end = this.elements.length,\n      sectionLength = end - start,\n      pivot = start + Math.floor(sectionLength / 2),\n      pivotElem = this.elements[pivot]\n\n  while (sectionLength > 1) {\n    if (pivotElem < elem) start = pivot\n    if (pivotElem > elem) end = pivot\n\n    sectionLength = end - start\n    pivot = start + Math.floor(sectionLength / 2)\n    pivotElem = this.elements[pivot]\n  }\n\n  if (pivotElem > elem) return pivot\n  if (pivotElem < elem) return pivot + 1\n}\n\n/**\n * Creates a new lunr.SortedSet that contains the elements in the intersection\n * of this set and the passed set.\n *\n * @param {lunr.SortedSet} otherSet The set to intersect with this set.\n * @returns {lunr.SortedSet}\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.intersect = function (otherSet) {\n  var intersectSet = new lunr.SortedSet,\n      i = 0, j = 0,\n      a_len = this.length, b_len = otherSet.length,\n      a = this.elements, b = otherSet.elements\n\n  while (true) {\n    if (i > a_len - 1 || j > b_len - 1) break\n\n    if (a[i] === b[j]) {\n      intersectSet.add(a[i])\n      i++, j++\n      continue\n    }\n\n    if (a[i] < b[j]) {\n      i++\n      continue\n    }\n\n    if (a[i] > b[j]) {\n      j++\n      continue\n    }\n  };\n\n  return intersectSet\n}\n\n/**\n * Makes a copy of this set\n *\n * @returns {lunr.SortedSet}\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.clone = function () {\n  var clone = new lunr.SortedSet\n\n  clone.elements = this.toArray()\n  clone.length = clone.elements.length\n\n  return clone\n}\n\n/**\n * Creates a new lunr.SortedSet that contains the elements in the union\n * of this set and the passed set.\n *\n * @param {lunr.SortedSet} otherSet The set to union with this set.\n * @returns {lunr.SortedSet}\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.union = function (otherSet) {\n  var longSet, shortSet, unionSet\n\n  if (this.length >= otherSet.length) {\n    longSet = this, shortSet = otherSet\n  } else {\n    longSet = otherSet, shortSet = this\n  }\n\n  unionSet = longSet.clone()\n\n  for(var i = 0, shortSetElements = shortSet.toArray(); i < shortSetElements.length; i++){\n    unionSet.add(shortSetElements[i])\n  }\n\n  return unionSet\n}\n\n/**\n * Returns a representation of the sorted set ready for serialisation.\n *\n * @returns {Array}\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.toJSON = function () {\n  return this.toArray()\n}\n  /**\n   * export the module via AMD, CommonJS or as a browser global\n   * Export code from https://github.com/umdjs/umd/blob/master/returnExports.js\n   */\n  ;(function (root, factory) {\n    if (typeof define === 'function' && define.amd) {\n      // AMD. Register as an anonymous module.\n      define(factory)\n    } else if (typeof exports === 'object') {\n      /**\n       * Node. Does not work with strict CommonJS, but\n       * only CommonJS-like enviroments that support module.exports,\n       * like Node.\n       */\n      module.exports = factory()\n    } else {\n      // Browser globals (root is window)\n      root.elasticlunr = factory()\n    }\n  }(this, function () {\n    /**\n     * Just return a value to define the module export.\n     * This example returns an object, but the module\n     * can return a function as the exported value.\n     */\n    return elasticlunr\n  }))\n})();\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/elasticlunr/elasticlunr.js\n// module id = 114\n// module chunks = 114276838955818 142807904292071","import React, {Component} from 'react';\nimport {Index} from 'elasticlunr';\n\n// Graphql query used to retrieve the serialized search index.\nexport const query = graphql`query\nSearchIndexExampleQuery {\n    siteSearchIndex {\n      index\n    }\n}`;\n\n// Search component\nexport default class Search extends Component {\n    constructor(props) {\n        super(props);\n        this.state = {\n            query: ``,\n            results: [],\n        };\n    }\n\n    render() {\n        return (\n            <div>\n                <input type=\"text\" className=\"search\" value={this.state.query} onChange={this.search}/>\n                <ul>\n                    {this.state.results.map(page => (\n                        <li>\n                            {page.title}: {page.keywords.join(`,`)}\n                        </li>\n                    ))}\n                </ul>\n            </div>\n        );\n    }\n\n    getOrCreateIndex = () => this.index\n        ? this.index\n        // Create an elastic lunr index and hydrate with graphql query results\n        : Index.load(this.props.data.siteSearchIndex.index);\n\n    search = (evt) => {\n        const query = evt.target.value;\n        this.index = this.getOrCreateIndex();\n        this.setState({\n            query,\n            // Query the index with search string to get an [] of IDs\n            results: this.index.search(query)\n                // Map over each ID and return the full document\n                .map(({\n                ref,\n                }) => this.index.documentStore.getDoc(ref)),\n        });\n    }\n}\n\n\n// WEBPACK FOOTER //\n// ./src/pages/search.js"],"sourceRoot":""}